,job_title,job_company,job_location,job_seniority,job_category,job_employment_type,job_salary_range_from,job_salary_range_to,job_salary_type,job_details_url,job_description,job_requirements
0,Sr. Software engineer Data cap /  ICM,NIBAARA TECHNOLOGIES PTE. LTD.,Central,Professional,Information Technology,Full Time,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/sr-software-engineer-data-cap-icm-nibaara-technologies-c6571e2705e86e011dc5788a421ba8f7,"<ul>   <li>Ensure the timely completion of the tasks assigned</li>   <li>Ensure to follow the Technology and Process Standards, set for the project</li>   <li>Produce high quality technical documentation</li>   <li>Develop Low Level Design</li>   <li>Undertake development tasks with minimal supervision, including programming and testing</li>   <li>To monitor progress and provide timely updates to Lead</li>   <li>On need basis should able to work as back up lead</li>   <li>Technical Design documents</li>   <li>Developed Programs with high quality and as per the planned schedule</li>   <li>Developed Programs with high quality, with process standards and as per the planned schedule</li>   <li>Unit Test Cases</li>   <li>Interacts with Technical Lead, BAs and testers for the project during the project lifecycle</li>   <li>Interacts with the Client managers, for status review meetings</li>  </ul>","<ul> 	<li>Hands on experience in designing and developing applications using Datacap 9.1.</li> 	<li>5-8 years of development experience using Java/J2EE related technologies</li> 	<li>Should possess good communication and problem solving skills</li> 	<li>Should have Aptitude and Attitude of learning and mastering new technologies and tools</li> 	<li>Working in client facing environment is a plus</li> 	<li>Working in Agile Methodology is a plus</li> 	<li>Working experience in Banking Domain is an added advantage</li> 	<li>Profound insight of dojo, navigator, VB script and Java script.</li> 	<li>Working experience with Relational Databases, PL/SQL. Experience in Oracle preferred.</li> 	<li>Experience in Datacap solution deployment.</li> 	<li>Object oriented analysis and design using common design patterns.</li> 	<li>Good to have experience in installation of Datacap.</li> 	<li>Good to have experience in designing and developing applications using Datacap 8.1, ASP.net and VB script.</li> 	<li>Good to have knowledge of OCR (optical character recognition)</li> </ul>"
0,Data cap /  ICM Engineer,NIBAARA TECHNOLOGIES PTE. LTD.,Central,Professional,Information Technology,Full Time,"$4,500","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-cap-icm-engineer-nibaara-technologies-0d09301a6203fd87ee07e2051ebed23d,"<ul> 	<li>Hands on experience in designing and developing applications using Datacap 9.1.</li> 	<li>Profound insight of dojo, navigator, VB script and Java script.</li> 	<li>Working experience with Relational Databases, PL/SQL. Experience in Oracle preferred.</li> 	<li>Experience in Datacap solution deployment.</li> 	<li>Object oriented analysis and design using common design patterns.</li> 	<li>Good to have experience in designing and developing applications using Datacap 8.1, ASP.net and VB script.</li> 	<li>Good to have knowledge of OCR (optical character recognition)</li> 	<li>Technical Design documents</li> 	<li>Developed Programs with high quality and as per the planned schedule</li> 	<li>Developed Programs with high quality, with process standards and as per the planned schedule</li> 	<li>Unit Test Cases</li> </ul><p> </p>","<ul> 	<li>Atleast 2-4 years of development experience using Datacap 9.1, Java/J2EE related technologies</li> 	<li>Should possess good communication and problem solving skills</li> 	<li>Should have Aptitude and Attitude of learning and mastering new technologies and tools</li> 	<li>Working in client facing environment is a plus</li> 	<li>Working in Agile Methodology is a plus</li> 	<li>Working experience in Banking Domain is an added advantage</li> </ul>"
0,Data Engineer,Company Undisclosed,Central,Executive ...,Banking and Finance,Permanent,"$6,500","$13,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-e55a0043c39dedc544e29f9c2dc4ba5c,"<p>Position Purpose</p><p>The APAC GM &amp; ALMT IT TP Engineering group runs Trade Processing and Regulatory Projects for Global Market and ALMT business and operations.</p><p> </p><p><strong>Responsibilities</strong></p><ul> 	<li>Partner with senior business sponsors, platform supervision, compliance, and business management to enhance and augment the holistic supervisory and surveillance platform</li> 	<li>Investigate and analyze data on the surveillance platform as key input to enhance existing data strategy on multi-vector analysis using various natural language processing and machine learning techniques</li> 	<li>Primary focus is to investigate and analyze available structured and un-structured information, apply data mining techniques, perform statistical analysis, and provide methods (algorithmic and technical) to create actionable alerts and reduce false-positives</li> 	<li>Develop and enhance software solutions to meet business requirements</li> 	<li>Gather and document technical requirements and specifications</li> 	<li>Work with the project PM and BA’s on project planning and deliverable</li> 	<li>Work on multiple tasks and respect aggressive schedule</li> 	<li>Work in a fast paced environment.</li> </ul>","<p><strong>Technical and Behavioral Competencies / Specific Qualifications (if required)</strong></p><ul>  <li><strong>Technical Competencies</strong></li> </ul><ul>  <li>Implementation experience with of Big Data technologies including large data stores and Machine Learning</li>  <li>Knowledge of various Statistical Analysis, Probabilistic Analysis and Data Visualization techniques preferred</li>  <li>Advanced knowledge of SQL and/or NoSQL systems</li>  <li>Basic understanding of project lifecycle stages</li> </ul><p> </p><p><strong>Behavioral Competencies</strong></p><ul>  <li>Ability to manage conflicting requests on time in a continually fast moving environment and operating in a global team</li>  <li>Must be a self-starter with attention to detail and strong communications (written and oral) skills</li> </ul><p> </p><p><strong><u>Preferred qualifications: </u></strong></p><ul>  <li>Experience with Front Office traders, IT support and Operation teams in a Capital Markets domain.</li>  <li>Knowledge of JAVA, J2EE, JavaScript, JSON, Perl, SQL, and PL/SQL would be a plus</li>  <li>Experience with machine learning, natural language processing, AI, or robotics is a plus</li> </ul><p> </p><p><strong><u>Qualifications and Experience</u></strong></p><ul>  <li>Master’s degree in engineering, math, statistics, physics or other technical field</li> </ul><p> </p>"
0,"VP / AVP, Senior Data Engineer, Group Consumer Banking and Big Data Analytics Technology (180003L2)",DBS BANK LTD.,East,Middle Management ...,Banking and Finance,Permanent ...,"$7,000","$14,000",Monthly,https://www.mycareersfuture.sg/job/vp-avp-senior-data-engineer-group-consumer-banking-big-data-analytics-technology-dbs-bank-cfdc4e6ed7bf3ad8ab8448da8e2e552e,"<ul>   <li>Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud. </li>   <li>Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics. </li>   <li>Analyze source data and data flows, working with structured and unstructured data.</li>   <li>Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends</li>   <li>Analyze and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely.</li>   <li>Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms.</li>   <li>Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products.</li>   <li>Build and optimize classifiers using machine learning techniques and enhance data collection procedures that is relevant for building analytic systems.</li>   <li>Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL.</li>   <li>Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat.</li>   <li>Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders.</li>  </ul>","<ul>   <li>Experience in big data and machine learning</li>   <li>The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles.</li>   <li>Development experience in Java/Scala and pride in producing clean, maintainable code</li>   <li>Practical experience in clustering high dimensionality data using a variety of approaches</li>   <li>Real world experience in solving business problems by deploying one or more machine learning techniques</li>   <li>Experience creating pipelines to analyze data, extracted features and updated models in production.</li>   <li>Independence and self-reliance while being a pro-active team player with excellent communication skills.</li>   <li>Hands-on development with key technologies including Scala, Spark, and other relevant distributed computing languages, frameworks, and libraries. </li>   <li>Experience with distributed databases, such as Cassandra, and the key issues affecting their performance and reliability. </li>   <li>Experience using high-throughput, distributed message queueing systems such as Kafka.</li>   <li>Familiarity with operational technologies, including Docker (required), Chef, Puppet, ZooKeeper, Terraform, and Ansible (preferred). </li>   <li>An ability to periodically deploy systems to on-prem environments. </li>   <li>Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools. </li>   <li>Experience with Teradata SQL, Exadata SQL, T-SQL</li>   <li>Strong experience in graph and stream processing</li>   <li>Experience in migrating SQL from traditional RDBMS to Spark and BigData technologies</li>   <li>Experience in building language parsers using ANTLR, query optimizers and automatic code generation</li>   <li>In-depth knowledge of database internals and Spark SQL Catalyst engine</li>  </ul>"
0,Data Engineer,HYDROINFORMATICS INSTITUTE PTE. LTD.,West,Executive,Professional Services,Full Time,,,,https://www.mycareersfuture.sg/job/data-engineer-hydroinformatics-institute-40572a98b1b85dec99073a5c04ba22f9,"<p>Roles and Responsibilities:</p><ul>   <li>Implement data wrangling, preprocessing and preparation scripts for available raw environmental data</li>   <li>Implement statistical and machine learning algorithms for data analysis and knowledge derivation</li>   <li>Implement data visualization solutions for post processing and communication to internal and external teams</li>   <li>Create and maintain databases for different kinds of geo-spatiotemporal data</li>   <li>Monitor and manage data pipelines and test production codes</li>  </ul>","<ul>   <li>Masters or PhD in one of the mathematical sciences, or engineering</li>   <li>Programming capability the data science languages – Python, R, and preferably in core languages – C, C++</li>   <li>Understanding and ability to code algorithms related to multivariate statistics, spatio-temporal statistics and time series analysis, and common machine learning algorithms in clustering, dimensionality reduction, neural networks etc.</li>   <li>Familiarity with open source data visualization frameworks with D3.js is preferred</li>   <li>Understanding of database concepts and distributed processing systems and knowledge of one of the frameworks – Hadoop, Spark, NOSQL etc.</li>   <li>Excellent written and oral presentation skills</li>   <li>Interest in developing environmental solutions</li>  </ul>"
0,Cyber Security Big Data Engineer,Company Undisclosed,Central,Professional,Information Technology,Full Time,"$7,000","$12,000",Monthly,https://www.mycareersfuture.sg/job/cyber-security-big-data-engineer-2971a7516b523a443afe3df36cb834a9,"<p>Working in Cybersecurity takes pure passion for technology, speed, a constant desire to learn, and above all, vigilance in keeping every last asset safe and sound. You’ll be on the front lines of innovation, working with a highly-motivated team laser-focused on analyzing, designing, developing and delivering solutions built to stop adversaries and strengthen our operations. Your research and work will ensure stability, capacity and resiliency of our products in emerging industry trends. Working in tandem with your internal team, as well as technologists and innovators across our global network, your ability to identify threats, provide intelligent analysis and positive actions will stop adversaries and strengthen our products.</p><p> </p><p><strong>Responsibilities</strong></p><ol> 	<li>Focus on the development of tools and technologies that are at the core of the company’s capabilities to manage, monitor and hunt for cyber security incidents</li> 	<li>Architecture and development of large scale solution (big data) to be used in a very large production environment</li> 	<li>System, network and application troubleshooting</li> 	<li>Provide engineering support for cyber security products developed</li> </ol>","<ol> 	<li>Knowledge of Cybersecurity organization practices, operations, risk management processes, principles, architectural requirements, engineering and threats and vulnerabilities, including incident response methodologies</li> 	<li>Ability to collaborate with high-performing teams and individuals throughout taghe firm to accomplish common goals</li> 	<li>Proficiency in the use of skills tools, staying current with skills, participating in multiple forums</li> 	<li>Experience with Agile and can work with at least one of the common frameworks is highly desired</li> 	<li>Ability to analyze vulnerabilities, threats, designs, procedures and architectural design, producing reports and sharing intelligence</li> 	<li>Strong research, analytical and problem solving skills</li> 	<li>Independent problem-solving, highly motivated and self-directing</li> 	<li>Ability to write and debug administrative and reporting tools in some programming languages (Shell/Perl or Python, Scala/Java/R, C/C++, HTML5, or other experiences acceptable)</li> 	<li>Comfortable with most aspect of operating system administration such as tweaking, hardening and configuring services</li> 	<li>A solid understanding of Unix-based operating systems, including paging/swapping, IPC, drivers and filesystem (inode, partitions, etc.)</li> 	<li>Experience with host and network security (identity/password management, ACLs, file permissions and integrity)</li> 	<li>Strong interpersonal and communication skills; capable of writing documentation, training users in complex topics, making presentations to junior and very senior audience</li> 	<li>Ability to work under pressure in a fast-paced environment while remaining productive and professional; exercise patience and ability to multi task</li> </ol><p> </p><p><strong>Bonus Points</strong></p><ol> 	<li>Experience with hadoop ecosystem: Hadoop, Spark, Map/Reduce, Hive/Pig, Impala/Drill, etc.</li> 	<li>Experience with Data Science: MLlib, Scikit, h2o, TensorFlow, Pytorch, Caffe, Singa, etc.</li> 	<li>Experience with NoSQL stacks: Elasticsearch, MongoDB, etc.</li> 	<li>Experience with SIEM products: Qradar, Arcsight, Splunk, etc.</li> 	<li>Experience with messaging and data transport tools: Kafka, NiFi, LogStash, Syslog-ng, rsyslog, etc.</li> 	<li>Experience with Link Analysis tools and GraphDBs</li> 	<li>Experience with data visualization tools: Hue, Kibana, Qlikview, Tableau, etc.</li> 	<li>Knowledge in RIA: HTML5, node.js, bootstrap, angular, extJS, etc.</li> </ol>"
0,"VP / AVP, Machine Learning Engineer, Group Consumer Banking and Big Data Analytics Tech (180003YE)",DBS BANK LTD.,East,Middle Management ...,Banking and Finance,Permanent ...,"$7,000","$14,000",Monthly,https://www.mycareersfuture.sg/job/vp-avp-machine-learning-engineer-group-consumer-banking-big-data-analytics-tech-dbs-bank-7a573d994c956432080d35360d81d2ba,"<p><strong>Job Purpose </strong><br>  </p><p>Build and improve machine learning and analytics platform. Work with data scientists to create, optimize and productionize of machine learning models for various business units within the organization. Keep innovating and optimizing data and machine learning workflow to enable data-driven business activities at large scale. <br> <br> <br> <strong>Responsibilities </strong></p><ul>   <li>Build and improve machine learning and analytics platform.<br>      <ul>     <li>Apply cutting edge technologies and tool chain in big data and machine learning to build machine learning and analytics platform.</li>     <li>Keep innovating and optimizing the machine learning workflow, from data exploration, model experimentation/prototyping to production.</li>     <li>Provide engineering solution and framework to support machine learning and data-driven business activities at large scale.</li>     <li>Perform R&amp;D on new technologies and solutions to improve accessibility, scalability, efficiency and us abilities of machine learning and analytics platform.<br>  </li>    </ul> </li>   <li>Work with data scientists to build end-to-end machine learning and analytics solution to solve business challenges.<br>      <ul>     <li>Turn advanced machine learning models created by data scientists into end-to-end production grade system.</li>     <li>Build analytics platform components to support data collection, exploratory, and integration from various sources being data API, RDBMS, or big data platform.</li>     <li>Optimize efficiency of machine learning algorithm by applying state-of-the-art technologies, i.e. distributed computing, concurrent programming, or GPU parallel computing. <br>  </li>    </ul> </li>   <li>Establish, apply and maintain best practices and principles of machine learning engineering.<br>      <ul>     <li>Study and evaluate the state of the art technologies, tools, and frameworks of machine learning engineering.</li>     <li>Contribute in creation of blueprint and reference architecture for various machine learning use cases.</li>     <li>Support the organization in transformation towards a data driven business culture.</li>    </ul> </li>  </ul><p><br> <strong>Work Relationships</strong></p><ul>   <li>Internal <br>      <ul>     <li>Work closely with data scientists, business team, and project managers to provide machine learning and data-driven business solution. </li>     <li>Collaborate with other technology teams to build platform and framework to enable machine learning and data analytics activities at large scale<br>  </li>    </ul> </li>   <li>External <br>      <ul>     <li>Maintain engineering principles and best practices of machine learning framework and technologies.</li>    </ul> </li>  </ul>","<ul>   <li>PhD/Masters/Bachelors in Computer Science, Computer Engineering, Statistics, Applied Mathematics, or related disciplines. </li>   <li>Excellent understanding of software engineering principles and design patterns.</li>   <li>Excellent programming skills in either Python, Scala, or Java.</li>   <li>In-depth understanding of data science and machine learning technologies and methodologies.</li>   <li>Good working knowledge of high performance computing, parallel data processing, and big data stack, e.g. Spark and Hadoop/Yarn.</li>   <li>Experience to one or more commercial / open source data warehouses or data analytics systems, e.g. Teradata, is a big plus.</li>   <li>Experience to one or more NoSQL databases is a big plus.</li>   <li>Hands-on experience in Cloud platforms, e.g. AWS, or containerization/ virtualization platforms, e.g. Docker/Kubernetes, is a big plus.</li>   <li>Experience to any data science or machine learning platform, e.g. IBM Data Science Experience or Cloudera Data Science Workbench, is a big plus.</li>   <li>Exposure to mainframe system is a plus.</li>   <li>Passion about machine learning and data-driven intelligence system.</li>   <li>Excellent communication and presentation skills in English.</li>   <li>Team player, self-starter, ability to work on multiple projects in parallel is necessary.</li>   <li>2+ years of experience in machine learning system or data science research</li>   <li>5+ years of experience in software engineering or DevOps automation or data engineering</li>   <li>Experience working in multi-cultural environments</li>  </ul>"
0,Lead Data Engineer (Established FinTech Co / East),PEOPLE PROFILERS PTE. LTD.,Central,Senior Executive,Information Technology,Permanent,"$7,500","$10,000",Monthly,https://www.mycareersfuture.sg/job/lead-data-engineer-people-profilers-76998aeacd7bf851e1e784fe69b59afb,"<ul> 	<li><strong>Join a rapidly expanding and reputable company in FinTech industry </strong></li> 	<li><strong>Attractive remuneration package</strong></li> 	<li><strong>Great benefits (work-life balance, fun work environment, health insurance, dental plan)</strong></li> 	<li><strong>Junior &amp; senior positions available</strong></li> </ul><p> </p><p><strong>Position Overview:</strong></p><ul> 	<li>Support our team in developing cutting-edge solutions for the FinTech industry, keeping security standards in mind.</li> </ul><p> </p><p><strong>Responsibilities:</strong></p><ul> 	<li>Building robust batch and streaming data pipeline for production-grade data products/platforms (tools: Hadoop, Spark)</li> 	<li>Creating web services or APIs to connect analytical stacks to application layers</li> 	<li>Building and maintaining both cloud and on-premise data infrastructure</li> 	<li>Data cleaning, &amp; pre-processing (e.g. with images/text)</li> 	<li>Analyse requirements and deliver suitable solutions</li> 	<li>Write code according to best practices, and which meets security standards</li> 	<li>Keep up to date with new technologies</li> </ul>","<p><strong>Requirements:</strong></p><ul> 	<li>Preferably at least a Bachelor’s in a quantitative discipline (e.g. Computer Science, Engineering, or Mathematics)</li> 	<li>8 years related work experience, in building high scalability, low latency systems</li> 	<li><strong>Good knowledge &amp; hands-on skills in at least 2 of these: Python/Java/Scala</strong></li> 	<li><strong>Knowledge of machine learning techniques (e.g. Bayesian methods, regression techniques)</strong></li> 	<li><strong>Good knowledge of algorithm generation &amp; data structures.</strong></li> 	<li>Knowledge and interest in data mining, machine learning, natural language processing, or information retrieval</li> 	<li>Prior exposure to NoSQL databases (development). Familiar with SQL and database technologies.</li> 	<li>Preferably have knowledge/experience in cloud computing technologies (e.g. AWS/Azure)</li> 	<li>Familiar with Linux environment.</li> 	<li>Knowledge in use of <strong>Hadoop/Spark</strong></li> </ul><p>All Successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.<br> Interested applicants may wish to email your resume in a detailed Word format to <strong>ruth.gan@peopleprofilers.com. Please include last drawn and expected salaries and notice period.</strong><br> We regret that only shortlisted candidates will be notified.</p><p> </p><p>Gan Huiru  Recruitment Consultant<br> Tel: +65 6594 9897 Fax +65 6835 7890<br> Address: 100 Beach Road #33-06 Shaw Tower Singapore 189702<br> Email: ruth.gan@peopleprofilers.com<br> EA License Number: 02C4944<br> Registration Number: R1768917</p>"
0,Data Engineer,SANDBOX CONSULTING PTE. LTD.,Islandwide,Professional,Information Technology,Permanent ...,"$5,500","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-sandbox-consulting-25654d51fa59534e3ac5d5e283830ea1,"<p> Design, build, launch and maintain efficient and reliable large-scale batch and real-time data<br> pipelines with data processing frameworks<br>  Integrate and collate data silos in a manner which is both scalable and compliant<br>  Collaborate with Project Manager, Frontend Developers, UX Designers and Data Analyst to<br> build scalable data-driven products<br>  Responsible for developing backend APIs &amp; working on databases to support the<br> applications<br>  Working in an Agile Environment that practices Continuous Integration and Delivery<br>  Working closely with fellow developers through pair programming and code review process</p>","<p> Experience and passion for data engineering in a big data environment using Cloud<br> platforms - AWS, GCP or Azure<br>  Experience with building production-grade data pipelines, ETL/ELT data integration<br>  Interested in being the bridge between engineering and analytics<br>  Knowledgeable about system design, data structure and algorithms<br>  Familiar with data modelling, data access, and data storage infrastructure like Data Mart,<br> Data Lake, and Data Warehouse.</p>"
0,Data Engineer,Company Undisclosed,Islandwide,Executive,Information Technology,Contract ...,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-e7c30aceb1ee80d8f68c4ee5f5de9e98,"<ul> 	<li>Design, build, launch and maintain efficient and reliable large-scale batch and real-time data pipelines with data processing frameworks</li> 	<li>Integrate and collate data silos in a manner which is both scalable and compliant</li> 	<li>Collaborate with Project Manager, Frontend Developers, UX Designers and Data Analyst to build scalable data-driven products</li> 	<li>Responsible for developing backend APIs &amp; working on databases to support the applications</li> 	<li>Working in an Agile Environment that practices Continuous Integration and Delivery</li> 	<li>Working closely with fellow developers through pair programming and code review process</li> </ul>","<ul> 	<li>Experience and passion for data engineering in a big data environment using Cloud platforms - AWS, GCP or Azure</li> 	<li>Experience with building production-grade data pipelines, ETL/ELT data integration</li> 	<li>Interested in being the bridge between engineering and analytics</li> 	<li>Knowledgeable about system design, data structure and algorithms</li> 	<li>Familiar with data modelling, data access, and data storage infrastructure like Data Mart, Data Lake, and Data Warehouse.</li> </ul><p> </p>"
0,APAC Data Engineer,UPS ASIA GROUP PTE. LTD.,East,Senior Executive,Logistics / Supply Chain,Permanent,"$5,256","$7,008",Monthly,https://www.mycareersfuture.sg/job/apac-data-engineer-ups-asia-group-f570cad2f586ebfa9a8660768a61ee6c,"<p><strong>Summary</strong></p><p>The Data Engineer will be responsible for expanding and optimizing the data and data pipeline architecture, data flow and collection for the Data Science team and creating API’s to integrate the models with production systems. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support the data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.</p><p><strong>Responsibilities:</strong></p><ul>   <li>Create and maintain optimal data pipeline architecture.</li>   <li>Assemble large, complex data sets from multiple data sources that meet functional / nonfunctional business requirements.</li>   <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and no SQL technologies.</li>   <li>Develop data features that will serve as inputs to AI/Machine Learning/OR techniques.</li>   <li>Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics.</li>   <li>Develop data design based on exploratory data analysis to meet stated business need.</li>   <li>Develop procedures to monitor model and production system performance/integrity.</li>   <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li>   <li>Review and create repeatable solutions through written project documentation, process flowcharts, logs, and commented clean code to produce datasets that can be used in analytics and/or predictive modeling.</li>   <li>Act as subject matter expert with investigating and evaluating emerging technologies. Articulate potential competitive market benefits of new technologies to senior management. Maintain broad understanding of implementation, integration, and interconnectivity issues with emerging technologies.</li>  </ul>","<p><strong>Skills and Qualifications</strong></p><ul>   <li>Possess a Bachelor’s Degree or Master’s Degree in Computer Science, Information Systems or related discipline.</li>   <li>Minimum 2 years of relevant experience in similar capacity using software/tools for big data, SQL and NoSQL databases and object oriented/object function scripting languages.</li>   <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li>   <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li>   <li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li>   <li>Strong analytic skills related to working with structured and unstructured datasets.</li>   <li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li>   <li>Possess solid project management and organizational skills.</li>   <li>Prior experience in supporting and working with cross-functional teams in a dynamic environment.</li>  </ul>"
0,"AVP  /  Senior Associate, Data Engineer, IBG Digital, Institutional Banking Group (1800044U)",DBS BANK LTD.,East,Manager ...,Banking and Finance,Permanent ...,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/avp-senior-associate-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-633ccd170a9d6b8f860c413b264c49ab,"<p><strong>Job Purpose </strong></p><p>The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.</p><p><strong>Responsibilities</strong></p><ul>   <li>Create and maintain optimal data pipeline architecture;</li>   <li>Assemble large, complex data sets that meet functional / non-functional business requirements;</li>   <li>Identify, design, and implement internal process improvements: automating manual processes,</li>   <li>Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC);</li>   <li>Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs;</li>   <li>Build processes supporting data transformation, data structures, dependency and workload management</li>  </ul>","<ul>   <li>Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment</li>   <li>Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc)</li>   <li>Strong in transactional SQL, Enterprise Data Warehouse</li>   <li>Experience with Graph Database, NoSQL databases</li>   <li>Experience with Feature Engineering</li>   <li>Experience with Master Data Management</li>   <li>Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc</li>  </ul>"
0,"AVP  /  Senior Associate, Data Engineer, Analytic Center of Excellence, Transformation Grp (180003G6)",DBS BANK LTD.,East,Manager ...,Banking and Finance,Permanent ...,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/avp-senior-associate-data-engineer-analytic-center-excellence-transformation-grp-dbs-bank-72cb5c42cf6e21851cd857f8129b9c46,"<p><strong>Job Purpose</strong></p><p>The Data Engineer will provide big data engineering support to the Analytic Center of Excellence.  This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.  </p><p><strong>Responsibilities</strong></p><ul>   <li>Create and maintain optimal data pipeline architecture;</li>   <li>Assemble large, complex data sets that meet functional / non-functional business requirements;</li>   <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, designing infrastructure for greater scalability, etc.</li>   <li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ‘big data’ technologies;</li>   <li>Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs;</li>   <li>Build processes supporting data transformation, data structures, dependency and workload management</li>  </ul>","<ul>   <li>Degree in Computer Science with minimum 3 years data engineering work experience in big data analytics environment</li>   <li>Excellent data engineering skills with open source big data stack</li>   <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets</li>   <li>Strong analytic skills related to working with unstructured datasets</li>   <li>Experience with big data tools: Hadoop, Spark, Kafka, etc</li>   <li>Experience with relational SQL and NoSQL databases</li>   <li>Experience with object-oriented/object function scripting languages: Python, Scala, etc</li>   <li>Familiar with deployment and optimization of open source big data analytic stack on distributed environment</li>   <li>Familiar with compiling, deploying and configuring open source data science tools including Python, R, Spark, etc</li>   <li>Familiar with deploying analytic projects and data science products to production</li>   <li>Excellent programming skills</li>  </ul>"
0,Data Engineer,WORKATO PTE. LTD.,South,Executive,Engineering ...,Permanent ...,"$2,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-workato-ee0013cd49ea74c314c0cb339fdc5047,"<p><u><strong>Role</strong></u></p><p>We are seeking a talented, self-directed Data Engineer to design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for our business stakeholders. Implement data structures using best practices in data modeling and ETL/ELT processes. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Analyze source data systems and drive best practices in source teams. Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance. Produce comprehensive, usable dataset documentation and metadata. Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers. Evaluate and make decisions around the use of new or existing software products and tools. Mentor junior data engineers.</p><p><br> The ideal candidate relishes working with data, enjoys the challenge of highly complex technical contexts, and, above all else, is passionate about data and analytics. He/she is an expert with data modeling, ETL design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates outsized business impact. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail) and enjoys working in a fast-paced team. The ideal candidate needs to possess exceptional technical expertise in large scale data warehouse and BI systems with hands-on knowledge on SQL, Distributed/MPP data storage, and AWS services (S3, Redshift, EMR, RDS).</p><p> </p><p><u><strong>Responsibilities</strong></u></p><ul>   <li> <p>Design, implement, and support a platform providing ad hoc access to large datasets</p> </li>   <li> <p>Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL</p> </li>   <li> <p>Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL, and Redshift</p> </li>   <li> <p>Build robust and scalable data integration (ETL) pipelines using SQL, Python and Spark</p> </li>   <li> <p>Build and deliver high quality datasets to support business analysis and customer reporting needs</p> </li>   <li> <p>Interface with business customers, gathering requirements and delivering complete data structures</p> </li>  </ul>","<ul>   <li> <p>Bachelor's degree in Computer Science, Computer Engineering, Business Administration, Mathematics or a related field</p> </li>   <li> <p>3+ years of industry experience as a Data Engineer or related specialty (e.g., Business Intelligence Engineer, Data Scientist)</p> </li>   <li> <p>Experience in data modeling, ETL development, and Data warehousing.</p> </li>   <li> <p>Data Warehousing Experience with Oracle, Redshift, Teradata, etc.</p> </li>   <li> <p>Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space</p> </li>   <li> <p>Experience in continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers</p> </li>   <li> <p>Experience building data products incrementally and integrating and managing datasets from multiple sources</p> </li>   <li> <p>Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets</p> </li>  </ul><p> </p><p><u><strong>Bonus Points</strong></u></p><ul>   <li> <p>Experience leveraging Python, R or Matlab to manipulate data and set up automated processes as per business requirements</p> </li>   <li> <p>Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)</p> </li>   <li> <p>Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies</p> </li>   <li> <p>Strong ability to interact, communicate, present and influence within multiple levels of the organization</p> </li>   <li> <p>Track record of manipulating, processing, and extracting value from large datasets</p> </li>   <li> <p>Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions</p> </li>   <li> <p>Master's degree</p> </li>  </ul>"
0,Data Engineer,OBSERVATIONAL AND PRAGMATIC RESEARCH INSTITUTE PTE. LTD.,East,Junior Executive,Engineering ...,Permanent ...,"$3,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-observational-pragmatic-research-institute-45f497e183cb1bc7d03f42d025b40f60,"<p><strong>The Company</strong></p><p>OPRI is an academic research institution striving to improve the lives of patients through global research.</p><p>OPRI has been leading the paradigm shift in real world evidence for the past 12 years, by delivering pragmatic clinical trials, disease registries and database research.</p><p><strong>The Role</strong></p><p>We are looking for a Data Engineer to work alongside our research, statistical and database teams in the UK, Singapore and Australia (Brisbane). In this position you will gain invaluable experience within an internationally recognised research organisation involved in analysis and dissemination of data from large-scale observational studies and pragmatic randomised controlled trials.</p><p>The successful candidate will have high attention to detail, strong time management skills, and most importantly experience in the management and engineering of relational databases.</p><p><strong>Your responsibilities</strong></p><ul>   <li>Design, construct, install, test and maintain data collection and management systems:    <ul>     <li>Integrate data management technologies and software engineering tools for custom data collection applications</li>     <li>Programming knowledge: Employ a variety of languages and tools (e.g. scripting languages) to combine systems together</li>     <li>Ensure seamless integration of data across multiple databases      <ul>       <li>SQL, queries</li>      </ul> </li>     <li>Building APIs for data consumption</li>     <li>Integrating external or new datasets into existing data pipelines</li>     <li>Continuously monitoring and testing the system to ensure optimized performance</li>    </ul> </li>   <li>Build and maintain data collection platforms for specific organisational projects    <ul>     <li>Set up automated integration processes for Patient Reported Outcomes into various data collection platforms</li>    </ul> </li>   <li>EMR/EDC integration with Registry Database    <ul>     <li>Data collected via Registry EDCs to be uploaded into EMRs</li>     <li>Data collected via site specific EMRs/EDCs to be uploaded into Registry EDCs</li>    </ul> </li>  </ul><p>The role is for a permanent full-time position. Salary is dependent on qualifications and experience. Immediate start is available.</p>","<p><strong>Qualifications</strong></p><ul>   <li>Bachelor degree in Computer Science, Engineering, Maths or equivalent qualification</li>  </ul><p><strong>Required Experience</strong></p><ul>   <li>Strong working knowledge of SQL (Essential)</li>   <li>Experience working with large databases</li>  </ul><p><strong>Preferred Experience</strong></p><ul>   <li>Experience of developing and maintaining data dictionaries for databases</li>   <li>Knowledge of statistical analysis tools (e.g. R, STATA, SPSS, SAS)</li>   <li>Interest and knowledge of epidemiology, public health and clinical research</li>  </ul>"
0,Big Data Engineer,SCHELLDEN GLOBAL PTE. LTD.,Islandwide,Middle Management,Information Technology,Full Time,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/big-data-engineer-schellden-global-6fdb5be88c9cb16e84d51c2f07f72b40,"<p>Massive data: You will source / examine, analyze, engineer data pipelines for<br> gigabytes/terabytes of structured and unstructured data with our platform to create<br> value for customers.<br>  Pushing the limits: This role will be on the cutting edge of our Data / Machine Learning<br> platform. As we push to solve more of our customer challenges, you will be prototyping<br> new features, tools and ideas. Innovate at a very fast pace to maintain our competitive<br> edge.<br>  Linux hacking: You will be masterfully using the command line, including tools like<br> vi/emacs and understanding beyond basics of grep, bash, awk, sed, etc to aggressively<br> dive into data, systems, and compute platforms to get the results you are seeking.<br>  Production deployment: You will be responsible for integration and deployment of the<br> machine learning pipelines into production where your ideas can come to life.<br>  Coordinate and work with cross functional teams, sometimes located at different geo<br> locations.</p>","<p>Commercial software engineering: You have 3+ years of professional software<br> development experience with languages and systems such as Java, Python (PySpark),<br> and version control (git), with good analytical &amp; debugging skills.<br>  Big data: You have extensive experience with data analytics and working knowledge of<br> big data infrastructure such as Hadoop Eco System, HDFS, Spark, Google Cloud, Big<br> Query, Data Flow (nice to have). You've routinely built data pipelines with<br> gigabytes/terabytes of data and understand the challenges of manipulating such large<br> datasets.<br>  Data Modeling: Flair for data, schema, data model, PL/SQL, Star &amp; snow flake schema,<br> how to bring efficiency in data modeling for efficient querying data for analysis,<br> understands criticality TDD and develops data validation techniques.<br>  Real Time Systems: Understands evolution of databases for in-memory, NoSQL &amp;<br> indexing technologies along with experience on real-time &amp; stream processing systems<br> like kafka, Storm.<br>  Project management: You demonstrate excellent project and time management skills,<br> exposure to scrum or other agile practices in JIRA.</p>"
0,Data Engineer,PERX TECHNOLOGIES PTE. LTD.,Central,Executive,Information Technology,Permanent,"$5,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-perx-technologies-3ab22f9fa73f55baa27382245369a2e5,"<p><strong>What You’ll Do</strong>:</p><p> </p><p>As a Data Engineer on the Analytics team, you will be the “source of truth” for Perx’s most fundamental data - such as end-customer engagement and client usage data - along with core metrics such as daily (DAU) and monthly active users (MAU).</p><p>Alongside designing &amp; implementing the plumbing &amp; infrastructure that will power the Analytics frameworks, you will also help lead the company’s decision to use bleeding-edge data technologies and features, working directly with our infrastructure team to integrate them into the services you design at scale.</p><p>In doing so, you will help empower the Engineering department, tens of co-workers, thousands of marketing analysts and millions of end customers to dream of new insights and new possibilities.</p><p> </p><p><strong>Who You Are</strong>:</p><p>You are a go-getter &amp; dreamer, wanting to join a community of extremely talented, forward-thinking &amp; diverse engineers in the industry &amp; region. You gain happiness in building &amp; scaling resilient, robust, well performing, and end-to-end tested distributed systems that can power the most business-critical applications. You want to learn, work with, and leverage on cutting-edge open-source technologies. The ideal candidate has experience with and/or history of contributions to Python, Hadoop, Spark, Redshift, Cassandra, PostGREs, Ruby (on Rails) or similar technologies. You have experience in distributed systems, database internals, or performance analysis.</p>","<p>MS in computer science or a related field OR BS in computer science and 3 years of experience in software engineering.</p><p>Backend development experience with a solid foundation in data pipelines, distributed<br> systems, large-scale data processing.<br> Experience with DBs like AWS Redshift, PostGREs, MySQL.</p><p>Experience with ETL and query language.<br> Proficiency with Python, Scala or Java.<br> Experience with Ruby is a plus.<br> Experience with Linux/Unix systems and AWS / cloud environments.<br> Working knowledge of MapReduce, Hadoop, HDFS.<br> Experience with Spark is a big plus!</p><p> </p>"
0,Big Data Engineer,6ESTATES PTE. LTD.,South,Professional,Information Technology,Full Time,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/big-data-engineer-6estates-a22e4c3b90cea5bc9767d75c5f0bb827,"<p>We are looking for the right individual who has the passion and desire to crack the code for this very hot field in AI and Big Data.</p><p>6Estates engineers build tools and solutions that ensure the delivery of high quality software for our stakeholders. For someone who wants to learn and grow, this role provides you the unique opportunity to work along with all the experts of different fields.</p><p>As a Big Data Engineer, you will work with a team of talents to design, architect, and develop on the big data analytics platform. You will also touch on researching, introducing modern technologies and integrating your amazing innovations and ideas into our production systems.</p>","<p>1. Minimum Bachelor’s degree in Computer Science and 3+ years of experience in administration/architecture in the field of big data specific to Hadoop, HBase</p><p>2. Excellent implementation skills in Java or Scala.</p><p>3. Expert knowledge of Linux/Unix programming.</p><p>4. Experience in Apache Hadoop, Spark, Zookeeper, Elasticsearch, etc.</p><p>5. Strong knowledge of distributed system architecture and implementation.</p><p>6. Knowledge of Information Retrieval / NLP / Data Mining is a plus.</p><p>7. Fluent in English and Chinese to liaise with Chinese speaking associates</p>"
0,"AVP / Senior Associate, Lead Development Engineer, Grp Consumer Banking & Big Data Analytics (180002YV",DBS BANK LTD.,East,Manager ...,Banking and Finance,Permanent ...,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/avp-senior-associate-lead-development-engineer-grp-consumer-banking-big-data-analytics-180002yv-dbs-bank-1e4f251f52dccafe737359d25ed7c91a,"<ul>   <li>Manage the Avaloq Configuration / Release Management tasks and work on the BAU tasks in non-production environments</li>   <li>Env Planning (DB, application), Avaloq ICE Streaming, Release calendars preparation and communicate with all stakeholders</li>   <li>Definition of Connect Direct (NDM), IBM MQ, Avaloq Tools Upgrade, TWS Definition and Batch support, and FIX Platform interface setup Projects and Enhancement requests.</li>   <li>Plan and manage the end-to-end deployment and delivery of IT infrastructure for Bank’s project from deployment planning, setup &amp; testing, pre-production readiness to production cutover.</li>   <li>Collaborate with Architecture and Engineering team, Application teams, Infrastructure teams, and service providers in delivering quality IT solutions and services to meet business objectives. Ensure the project meet schedule and within the allocated budget and resources.</li>   <li>Adhere to the bank's Project Management, Deployment and Change management process. </li>   <li>Prepare and submit the necessary change requests and requisition forms for the deployment of infrastructure for the project, such as facility request, IP/DNS/Hostname request, SAN requisition, etc.</li>   <li>Conduct proper transition from Project to Operations before project closure.</li>   <li>Prepare all project documentation such as SOM and status reports, assure report accuracy and timeliness. e.g. Weekly Project Status report, etc.</li>   <li>Work collaboratively with technology team and vendors, provide single point of contact and drive resolution of issues that arise in projects.</li>   <li>Maintain business partnership with Line of Business (LOBs) and constantly collect and manage user’s demands and applications’ infra requirements.</li>   <li>Coordinate with DBA, Solaris, Linux, Windows, Network, ID Mgmt and other Infra admin teams on the system issue related tasks</li>   <li>Co-ordinate with various Infra teams to apply the OS / DB / MQ patches </li>   <li>Apply the innovative thinking to automate the manual tasks, provide infrastructure services effortlessly, improve performance and resilience of the systems.</li>  </ul>","<ul>   <li>The candidate need to have minimum of 5 years IT experience with Avaloq Release Management and infrastructure project delivery.</li>   <li>The candidate should have strong infrastructure technical background with hands on Open Systems platform such as Solaris, Linux, virtualization, network, and storage. Moderate information security knowledge</li>   <li>Have a good understanding of ITIL processes and project management processes.</li>   <li>Development experience in SQL &amp; PL/SQL, preferably in Oracle 11g / 12c environment</li>   <li>Must have hands-on experience in IBM MQ series, Connect Direct and SSH such as file transfer tools</li>   <li>Good to have knowledge on the Micro services and cloud services</li>   <li>A Bachelor’s degree in Computer Science (or equivalent experience)</li>   <li>5 -8 years of development and delivery experience</li>   <li>Able to perform Unix / Linux scripting.</li>   <li>Monitor and address issues relating to capacity constraints and performance related items.</li>   <li>Analyze and perform database performance tuning.</li>   <li>Develop and maintain high-performance, scalable utilities to support technology research and data transformation.</li>   <li>Contribute to the establishment and maintenance of distributed computing platform / Messaging services</li>   <li>Good leadership skills in working with Application teams and service providers in defining and executing infrastructure deployment plan, coordination of all infrastructure required activities, cutover/migration strategy and test plan.</li>   <li>Good in documentation, tracking, form submission, raising change request and project status reports. </li>   <li>Should be an effective communicator with good people management skills to handle diverse groups/teams in the project.</li>   <li>Should be a proactive self-starter with strong analytical skill, team-player, independent, pro-active, resourceful. </li>  </ul>"
0,"VP / AVP, Development Engineer,  Group Consumer Banking & Big Data Analytics Tech, T&O (180001ZC)",DBS BANK LTD.,East,Manager,Banking and Finance,Permanent ...,"$6,500","$13,000",Monthly,https://www.mycareersfuture.sg/job/vp-avp-development-engineer-group-consumer-banking-big-data-analytics-tech-to-dbs-bank-3754b22e68f3171e65628771aa1eef42,"<ul>   <li>Develop world-class solution/application for your team</li>   <li>Be up to date of the market landscape for solution/application insights, direction, vendors, and methods</li>   <li>Provides expertise to identify and translate system requirements into software design artefacts</li>   <li>Provide input during the business development life cycle</li>   <li>Participate in experimentation to assess new solution/application paths</li>   <li>Identify challenges to help the development of formalized solution methodologies</li>   <li>Contribute to a repository for solution/application artefacts</li>   <li>Interface and coordinate tasks with internal and external technical resources. Collaborate to provision estimates, develop overall implementation solution/application plan, and serve as a lead as required, to implement the installation, customization, and integration efforts</li>   <li>Actively contribute to the quality assurance for services within the solution/application area</li>   <li>Provide relevant and timely project information to senior management</li>   <li>Actively contribute to the change in delivery and deployment strategy for all applications to a total replacement for applications at the end of their technology or functionality lifecycle</li>   <li>Maintain and monitor all aspects for the proper running of the application</li>   <li>Understand the system process flow of the primary business processes. Provide a clear picture of the functionality map and the applications footprint of various applications across the map</li>  </ul>","<ul>   <li>Solid experience in Java, JavaScript, IBM MQ &amp; JMS, Spring boot, Hibernate, Eclipse, JUnit, Apache, etc.</li>   <li>Hands-on Design, Development, Deployment, Configuration &amp; Support of various Integration platform components</li>   <li>10 + years of experience in the Technology field including hands on in both development and support of SOA or Microservices</li>   <li>Proven experience in design and development of APIs using API Gateways including Gateway deployment, configuration, policy development, migration, debugging and troubleshooting</li>   <li>Working knowledge of Web API, REST, XML, JSON, Security (OAuth, OpenID Connect) </li>   <li>Ability to work with Linux OS to deploy and configure AXWAY gateway and other components </li>   <li>Solid hands-on design and development experience in TIBCO suite of BW, BPM, BE, EMS, Hawk, and Adapters etc. </li>   <li>Track record in providing application and technical assistance on multiple systems and platforms</li>   <li>Understanding of XML file format, hashing and encryption, and transfer protocols (SFTP, NDM, etc.)</li>   <li>Experience of Cloud based architecture and development</li>   <li>Experience in Software delivery frameworks such as agile, waterfall</li>   <li>Experience of CI/CD</li>   <li>Core Competencies</li>   <li>Solid software engineering experience</li>   <li>Strong analytical and problem solving skills</li>   <li>Technical depth across a number of technologies (languages, OS, Databases)</li>   <li>Excellent written and verbal reasoning and communication skills</li>   <li>Ability to lead technical solutions end to end</li>   <li>Ability to work across organizational boundaries and build networks to deliver solutions</li>  </ul>"
0,"AVP  /  Senior Associate, Data Analyst, Analytic Center of Excellence, Transformation Grp (180003G5)",DBS BANK LTD.,East,Manager ...,Banking and Finance,Permanent ...,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/avp-senior-associate-data-analyst-analytic-center-excellence-transformation-grp-dbs-bank-b914690e3a0a71debdbac82d7ff29f2b,"<p><strong>Job Purpose</strong></p><p>The data analyst will provide the big data analytic support to the Analytic Center of Excellence. He will partner with business and project leader to discover, analyse and process the data to develop analytic and data science solutions. This position allows those with strong data analytic skill and theoretical understanding of advanced analytic algorithms but lack of hands on experience in advanced analytics to learn and prepare for the role of data scientist - advanced analytics in the future.</p><p><strong>Responsibilities </strong></p><ul>   <li>Identify, profile, analyze and present the data discovery output for analytic projects</li>   <li>Develop data ingestion pipeline and create the analytic data assets for analytic projects</li>   <li>Work with data engineer to enhance the analytic data infrastructure and develop enterprise analytic data mart</li>   <li>Perform data wrangling and feature engineering for machine learning</li>   <li>Create helper functions to automate frequently encountered wrangling and feature engineering tasks</li>  </ul>","<ul>   <li>Bachelors/Masters in Computer Science, Statistics, Mathematics and other highly quantitative fields such as bio-informatics</li>   <li>Minimum 3 years of industry experience in data analytics working in a big data environment, preferably in financial services industry</li>   <li>Highly proficient with data wrangling, analytic, transformation and feature engineering using programming tools such as Spark, Python or R. Excellent knowledge of SQL.</li>   <li>Excellent visualization and communication skills.</li>  </ul>"
0,DATA ENGINEER,CHARLES & KEITH (SINGAPORE) PTE. LTD.,Central,Executive,Information Technology,Full Time,"$5,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-charles-keith-9f7e01404a2633eb48701a27a119b430,"<p>We are looking for a savvy Software turned Data Engineer to join our growing Data Engineering team. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.</p><p>He/She will be responsible for designing, expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.</p><p>Supporting our software developers, data architect, data analysts and data scientists on organisation wide data initiatives, he/she will ensure optimal data delivery that is consistent throughout ongoing projects.</p><p>Self-directed and comfortable supporting the data needs of multiple teams, systems and products, he/she will be excited by the prospect of optimizing or even re-designing our organisation’s data architecture with architect to support our next generation of products and data initiatives.</p><p><strong>Roles &amp; Responsibilities</strong></p><ul>   <li>Create and maintain optimal data pipeline architecture</li>   <li>Assemble large, complex data sets that meet functional / non-functional business requirements</li>   <li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, collaborate with infra team to re-designing infrastructure for greater scalability and stability</li>   <li>Collaborate with infrastructure team for provisioning required infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies</li>   <li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data needs</li>   <li>Keep our data separated and secure across national boundaries through multiple data centres and AWS regions</li>   <li>Create data tools for analytics and data scientist team members that assist them in building and optimizing models which enables us as an innovative industry leader.</li>   <li>Work with data and analytics experts to strive for greater functionality in our data systems</li>   <li>Build tools from ground up that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics</li>  </ul><p> </p><p> </p>","<p>We are looking for a candidate with 5+ years of experience in a Software Engineer role who wants to move into Data Engineering or is currently working as Data Engineer. He/She should have attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field and also have experience using the following software/tools:</p><ul>   <li>Experience with object-oriented/object function scripting languages: Python and/or Java, C++, Scala, etc.</li>   <li>Experience with big data tools: Hadoop, Spark, Kafka, NiFi, sqoop, etc.</li>   <li>Experience with relational SQL and NoSQL databases.</li>   <li>Experience with data pipeline and workflow management tools: Luigi, Airflow, etc.</li>   <li>Experience with AWS cloud services: EC2, EMR, Kenesis, Firehose</li>   <li>Experience with stream-processing systems: Storm, Spark-Streaming, etc. ​</li>  </ul><p> </p><p><strong>Additional Requirements</strong></p><ul>   <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with widely used RDBMS</li>   <li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets</li>   <li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement</li>   <li>Strong analytic skills related to working with unstructured datasets.</li>   <li>Build processes supporting data transformation, data structures, metadata, dependency and workload management</li>   <li>A successful history of manipulating, processing and extracting value from large disconnected datasets</li>   <li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores</li>   <li>Strong project management and organizational skills.</li>   <li>Experience supporting and working with cross-functional teams in a dynamic environment</li>  </ul><p> </p>"
0,Data Engineer (Fin-Tech),MATCHMOVE PAY PTE. LTD.,Central,Manager ...,Banking and Finance,Full Time,"$3,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-matchmove-pay-ee36e0dd15c8ef67e0d43751479bbbbf,"<p><strong>Are you the One?</strong><br> <br> MatchMove Pay, one of the fastest, award-winning Fin-Tech company, is looking for a couple of experienced Data Engineers to work on in-house data warehouse projects and data modelling.<br> <br> <strong>Job Responsibilities :</strong></p><ul> 	<li>Build the data warehouse infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources on AWS technologies.</li> 	<li>Maintain compliance of the data warehouse with MatchMove data architecture policy.</li> 	<li>Responsible for data modelling and validation of master data with original data sources.</li> 	<li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability</li> 	<li>Work with stakeholders including the Executive,  Finance, Product and Engineering teams to assist with data-related technical issues and support their data infrastructure needs.<br> 	 </li> </ul>","<ul> 	<li>Good programming experience in Python</li> 	<li>Knowledge of information retrieval using SQL, java or C++</li> 	<li>Experience with AWS data technologies such as Redshift, Glue, Spectrum, Quicksight.</li> 	<li>Well versed with data modelling and data warehousing.</li> 	<li>Working knowledge of message queuing, stream processing, and highly scalable data stores.</li> 	<li>Knowledge about Apache Spark or Hadoop would be an advantage.</li> 	<li>Self-starter and committed to working in fast paced environment<br> 	 </li> </ul><p><strong>Culture in MatchMove : </strong></p><p><br> - To work in a fast-moving startup, fun and yet professional environment that recognizes and rewards individual contributions and also team success. <br> - To work with highly motivated people who are totally focused on winning by combining great teamwork, rapid execution and an uncompromising approach to quality and customer satisfaction. <br> - We strongly encourage Innovation, Collaboration, Creativity, and Initiative. <br> - We work in a collaborative environment where you can talk to the CEO anytime! <br> - Be A Part of the MatchMove Family! Check us out our Facebook page</p><p> </p><p>Personal Data Protection Act :</p><p>By submitting your application for this job, you are authorizing MatchMove to:</p><p>a) Collect and use your personal data, and to disclose such data to any third party with whom MatchMove or any of its related corporation has service arrangements, in each case for all purposes in connection with your job application, and employment with MatchMove; and</p><p>b) Retain your personal data for 1 year for consideration of future job opportunities (where applicable for relevant unsuccessful job applicants).</p>"
0,Data Security Network Engineer,EIRE SYSTEMS SINGAPORE PTE. LTD.,East,Professional,Information Technology,Full Time,"$7,000","$9,000",Monthly,https://www.mycareersfuture.sg/job/data-security-network-engineer-eire-systems-singapore-5ed1b7c270b5037308ec75adb5edd638,"<p>The role of an Implementation Services Data Security Engineer is to interpret a customer request and then transform that request into a successful project.  This includes project management, solution design, security solution implementation as well as act as Tier 3 escalation technical support when called upon.  The role is required to act as liaisons to engineers in the Client Architecture and Engineering department in ensuring that global engineering standards and guidelines are adhered to.</p><ul> </ul><p><u>Responsibilities include:</u></p><p><strong>Requirements verification:</strong></p><ul> 	<li>Meeting with Business Clients, Systems Integration, and other IT departments to gather technical requirements, business justification for projects</li> 	<li>Verify technical requirements for large projects</li> 	<li>Quickly estimate high-level costs and resource requirements</li> </ul><p><strong>Solution design:</strong></p><ul> 	<li>Evaluating technology options and presenting those that best suit customer requirements.</li> 	<li>Produce the technical design in the format specified by Client standards.  This requires excellent technical writing skills and proficiency with office automation tools.  Many technical designs will be in excess of 100+ pages and integrate various items including Visio Diagrams, Tables, Charts, and links.</li> 	<li>Ensure Compliance with all Client Standards for Data and Voice Networks.</li> 	<li>Assist junior engineers with project costing estimates</li> 	<li>Generally the first to use new solutions provided by Network Technology engineering team</li> </ul><p> </p><p><strong>Project Management</strong></p><ul> 	<li>Develop a High-level plan at project initialization that will guide the project through the requirements and pre-sales stage</li> 	<li>Develop a Detailed project plan that will guide the project through the solution design, procurement, and delivery stages.</li> 	<li>Hold regular meeting with stake holders to track progress and communicate issues, and delegate tasks</li> 	<li>Provide Project reporting as required by the Client Minimal Grid Guidelines for Complex and Medium Service Requests</li> </ul><p><strong>Implementation:</strong></p><ul> 	<li>Determining implementation time frames and risks - Coordinating and gaining consensus on change windows with change management and other IT teams and LBM’s</li> 	<li>Submission and tracking of Change Management tickets for implementation</li> 	<li>Coordinating the installation of equipment and connections with Move/Add/Change team</li> 	<li>Testing of network connectivity post implementations</li> 	<li>Ensuring Compliance of all Changes with Client standards</li> 	<li>Completing the Acceptance into Service (AIS) Process for all projects.</li> 	<li>Delivering all Projects and Changes “Right the First Time” as most of our SLA for service uptime are 99.999% and greater.  Failure to deliver right the first time has significant financial penalties.</li> 	<li>Travel to various customer sites within the Asia Pacific theater is required</li> </ul><p> </p><p><strong>General Support:</strong></p><ul> 	<li>Provide Tier 3 Technical Support during major incidents and troubleshooting assistance for complex long term issues impacting network performance.</li> 	<li>Provide Technical consultation as requested by the customer</li> 	<li>Assist with internal and external audit requests</li> </ul><p> </p>",<p>Experience in the below Technology</p><p>The primary technology areas covered by the Data Security Engineer are:</p><ul> 	<li>Juniper Netscreen Firewalls and Netscreen Security Manager</li> 	<li>Palo Alto Firewalls and Panorama CM</li> 	<li>Cisco Routing and Switching (Cisco Nexus)</li> 	<li>Multicast</li> 	<li>EIGRP and BGP Routing Protocols</li> 	<li>Lucent Vital QIP/Run IP (DNS/DHCP); N3K RunIP</li> 	<li>F5 Load Balancers</li> 	<li>Bluecoat Proxy Devices</li> 	<li>Rebasoft Network Access Control</li> </ul><p>The preferred candidate should have worked in a System Integrator/ large enterprise managed service environment preferably in the financial industry or have similar experience with the banking sector.</p>
0,Data Quality Engineer,ALPHATECH BUSINESS SOLUTIONS PTE. LTD.,East,Senior Executive,Information Technology,Permanent,"$6,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-quality-engineer-alphatech-business-solutions-b75cf372b356ef87217a54dfc56506da,<ul>   <li>Evaluate and recommend solutions via data analysis regarding issues related to the improvement of product qua;oty and resolving of customer feedback</li>   <li>Apply software and programming abilities to manage and analyse data from a variety of sources</li>  </ul>,"<p> </p><ul>   <li>Must know JAVA8 and SPARK</li>   <li>Experience in distributed data architecture</li>   <li>Have working knowledge of SQL, Python, Airflow Scala, Hadoop, SPARK</li>   <li>Good to know CI/CD Experience (Jenkins Github), AWS, Kubernetes, Docker</li>   <li>Preferred to have banking domain experience</li>  </ul>"
0,"VP, Lead DevOps Engineer, Group Consumer Banking and Big Data Analytics Technology, T&O (180001X5)",DBS BANK LTD.,East,Senior Management,Engineering,Full Time,"$9,500","$15,000",Monthly,https://www.mycareersfuture.sg/job/vp-lead-devops-engineer-group-consumer-banking-big-data-analytics-technology-to-dbs-bank-2f9b305f1df117c8ae8ee02746fd5a62,"<p><strong>Business Function</strong><br> <br> Group Technology and Operations (T&amp;O) enables and empowers the bank with an efficient, nimble and resilient infrastructure through a strategic focus on productivity, quality &amp; control, technology, people capability and innovation. In Group T&amp;O, we manage the majority of the Bank's operational processes and inspire to delight our business partners through our multiple banking delivery channels.<br> <br> <br> <strong>Key Accountabilities</strong></p><ul> 	<li>Manage the development of the internal engineering productivity tools and environments.</li> 	<li>Providing DevOps architecture implementation and operational support</li> 	<li>Architecture and planning for cloud deployments (Private and Public cloud); </li> 	<li>Be an innovative and hands-on DevOps engineer capable of looking at both the technology and strategy around the platform.</li> 	<li>Future-proofing the technical environments and ensuring extreme high levels of automation, availability, scalability and resilience.</li> </ul><p><strong>Responsibilities </strong></p><ul> 	<li>Manage the development of the internal engineering productivity tools and environments.</li> 	<li>Manage processes, automation, best practices, documentation.</li> 	<li>Development and operation of continuous integration and deployment pipelines.</li> 	<li>Monitoring automation to effectively detect/predict/prevent issues in the environment and code base.</li> 	<li>Ability to conduct research into software issues and products as required</li> 	<li>Working with the latest tools and techniques </li> 	<li>Hands-on coding and mentoring, usually in a pair programming environment </li> 	<li>Working in highly collaborative teams and building quality environments.</li> 	<li>Ability to effectively prioritize and execute tasks in a high-pressure, fast paced, global environment</li> 	<li>Knowledge in lots of different open source technologies and configurations.</li> </ul>","<ul> 	<li>More than 3 years of experience as a Developer</li> 	<li>Excellent problem solving skills</li> 	<li>Excellent communication skills in order to facilitate workshops</li> 	<li>Strong knowledge and experience in Devops automation, containerisation and orchestration using tools such as Mesos Chef, Ansible, Docker, Jenkins, SonarQube Kubernetes etc.</li> 	<li>Experience with highly scalable distributed systems</li> 	<li>Hands on in depth experience in some of the following technologies:</li> 	<li>Jenkins/Maven/Git/SonarQube/Fortify/Confluence/Jira/Artifactory</li> 	<li>Cloud Foundry, OpenShift or other PaaS technologies.</li> 	<li>Public clouds such as AWS, Google Cloud or Azure.</li> 	<li>Dockers, Garden, Kubernetes, Mesos.</li> 	<li>Strong understanding of virtualization and networking.</li> 	<li>Strong understanding of Linux.</li> 	<li>Familiarity with relational databases, preferably MySQL, NoSQL, MariaDB, PostgreSQL.</li> 	<li>Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum </li> 	<li>Knowledge of software best practices, like Test-Driven Development (TDD).</li> </ul>"
0,"Vice President, Data Engineering",LAZADA SERVICES SOUTH EAST ASIA PTE. LTD.,Central,Senior Management ...,Information Technology ...,Permanent,"$13,000","$17,000",Monthly,https://www.mycareersfuture.sg/job/vice-president-data-engineering-lazada-services-south-east-asia-ebc128c9a6c0b3cbc735091d6728c537,"<p><strong>Story of Lazada Group:</strong></p><p>Launched in 2012, Lazada has grown rapidly to include over 4.900 full-time employees in the region, with eCommerce operations in Indonesia, Malaysia, Philippines, Singapore, Thailand, Vietnam and a sourcing center in Hong Kong that drives cross-border marketplace activities as well as an R&amp;D TechHub in Russia.</p><p>Revolutionizing the way customers shop in Southeast Asia and perform online transactions across the region, Lazada has reached an online footprint of approximately 9 million unique daily visits to its websites, and the largest Facebook community in Southeast Asia with over 16.5 million fans.</p><p>Lazada Group owns the biggest and the most efficient technology driven logistics and fulfilment ecosystem in the region – Lazada eLogistics. With 11 own warehouses, 5 sorting centers, 78 last-mile hubs we are ensuring 48 hours delivery of more than 6 million orders every month. Our warehouses cover more than 115 thousands of square miles and it takes less than 2 hours to process every order even during massive sales campaigns. Having our own cross-border operator helps us connect more than 100 million of customers and businesses from all over Asia. Our transportation is driven by our own LEL Express delivery fleet which, together with more than 80 third-party logistics, guarantees high quality 48 hours delivery. All of that would be impossible without sophisticated IT systems, which are being developed and expanded in-house by one of the most experienced and agile tech teams in Southeast Asia!</p><p>As a Lead Data Engineer in Lazada eLogistics Tech Team, you'll be part of an extremely motivated and experienced group of people. You'll help drive LEL business and be a key contributor. You will also become a mentor for other developers and business members.</p><p>Does the real-time challenge of dealing with massive datasets (billions of transactions a day) get you excited? If yes, then we would like to speak with you. Lazada eLogistics is using a mix of cutting edge and proven technologies to build new data products that aim to change the E-Logistics landscape. You will be the tech leader of a data engineering team that primarily focuses on productionalizing data pipelines that drive our most critical applications. The tech lead position is the a critical layer that makes sure projects get done.</p><p><strong>Your daily duties will be:</strong></p><ul> 	<li> 	<p>Drive development of real-time data ingestion pipelines and batch data ingestion pipelines for analysis, machine learning, dashboards, alerts and visualizations.</p> 	</li> 	<li> 	<p>Drive development of new systems and tools to enable data scientists to consume and analyse data faster and more efficiently.</p> 	</li> 	<li> 	<p>Design data warehouse and data pipelines ensuring data integrity between systems are maintained.</p> 	</li> 	<li> 	<p>Architect, build, and launch new data models.</p> 	</li> 	<li> 	<p>Execute code review of data engineers.</p> 	</li> 	<li> 	<p>Mentor data engineers in the team.</p> 	</li> 	<li> 	<p>Convert specs into to working code.</p> 	</li> 	<li> 	<p>Work and tune data warehousing and data ingest environments.</p> 	</li> 	<li> 	<p>Script programs and APIs in Python/Go.</p> 	</li> 	<li> 	<p>Create, monitor and manage low latency ETL and Data pipelines.</p> 	</li> </ul><p><strong>Your future benefits will be: </strong></p><ul> 	<li> 	<p>Class ""A” office with the best view on business district of Singapore.</p> 	</li> 	<li> 	<p>Official employment and relocation coverage.</p> 	</li> 	<li> 	<p>Medical insurance from the first day.</p> 	</li> 	<li> 	<p>Comfortable working hours in the office.</p> 	</li> 	<li> 	<p>Caring and respectful HR team.</p> 	</li> 	<li> 	<p>Powerful workstations and various software licenses (Mac / Winbook + HD displays to your liking).</p> 	</li> 	<li> 	<p>Daily snacks, chill-out on Friday and of course high quality coffee.</p> 	</li> 	<li> 	<p>Personal development system for both specialists and managers.</p> 	</li> 	<li> 	<p>Choice of hackathons, meetups and other entertainment activities.</p> 	</li> 	<li> 	<p>Opportunity to become public speaker in technology and take part in industry conferences – for top performers.</p> 	</li> 	<li> 	<p>Exciting international business travels.</p> 	</li> 	<li> 	<p>No dress code.</p> 	</li> </ul>","<ul> 	<li> 	<p>Minimum 5 years of data engineering experience.</p> 	</li> 	<li> 	<p>Experience in leading more than 2 people in team.</p> 	</li> 	<li> 	<p>Expert/Advanced level experience with Python.</p> 	</li> 	<li> 	<p>Expert Level experience with PostgreSQL, Hadoop.</p> 	</li> 	<li> 	<p>Deep experience in SQL tuning, tuning ETL solutions, physical optimization of databases.</p> 	</li> 	<li> 	<p>Experience or understanding of Big Data Platforms.</p> 	</li> 	<li> 	<p>eCommerce industry knowledge is a plus.</p> 	</li> 	<li> 	<p>Great experience building production applications in a heterogeneous environment.</p> 	</li> 	<li> 	<p>Experience with Multithreaded and Concurrent programming.</p> 	</li> 	<li> 	<p>Creative and nimble with ability to overcome obstacles to solve the hardest problems</p> 	</li> 	<li> 	<p>Ability to write well-abstracted, reusable code components (TDD / Git / Jenkins / Ansible as plus).</p> 	</li> 	<li> 	<p>Experience in cloud computing services, relational, and non relational databases for business intelligence and analytics.</p> 	</li> </ul>"
0,Data Engineer (Big Data),Company Undisclosed,South,Executive,Engineering ...,Full Time,"$6,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-154eb447d815b4ca348b1540b6893368,"<ul> 	<li>Being part of the Data Engineering Team to conceptualise, build and maintain the Data Infrastructure for relational as well as Big Data Infrastructure in order to deliver a high performanc Data Environment to process Retail and Shopper Data from various partners.</li> 	<li>Being responsible for Data Warehousing Design, Data Integration Processes, Database Ressource Planning, Infrastructure Performance, Data Governance and Security Management as well as design, architecture, implementation and documentation of new, scalable ETL processes, pipelines, pathways and dimensional data models.</li> 	<li>Audit and QA data and processes to ensure data quality and integrity throughout the data ecosystem</li> 	<li>Work with Data Scientist, Business Consultant and Frontend Developer to build scalable Data Analytics Apps using advanced analytics.</li> </ul><p> </p><p> </p>","<ul> 	<li>You have 10+ years hands-on experience and a passion for data engineering in a big data envrionment, ETL Processes and related services as well as experience and a very good understanding of AWS Big Data Cloud Infrastructure.</li> 	<li>You have very good experience in relational Database Technologies (ideally MS SQL) and Big Data Technologies and Database Performance Tuning .</li> 	<li>You are a highly motivated, challenge-taking Personality with a positive attitude. Team-oriented with an international mindset.</li> 	<li>You like to work in a dynamic Start-Up Environment and build exciting new Data Products within a motivated team.</li> 	<li>Fluent in English written and oral and ready to travel.</li> 	<li>You feel comfortable in developing on your own but also in working with a team of developers</li> </ul><p> </p>"
0,Data Engineer,ZALORA SOUTH EAST ASIA PTE. LTD.,Central,Professional,Engineering,Full Time,"$4,500","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-zalora-south-east-asia-149994bf19ff2eef0bba260147f76d2d,"<p>We are looking for a Big Data Engineer happy to design, build, maintain and automate big data environments (datalake, etc…) and the associated data to enable the teams to make use of the high volume of data available from our e-commerce activities.</p><p>You should be proficient in:</p><p><strong>- Technical background:</strong></p><ul> 	<li>Linux</li> 	<li>Big Data technologies (Redshift, BigQuery, Spark, Glue, Parquet…)</li> 	<li>Industrialization (Ansible..), Orchestration (Kubernetes…), containers in cloud (Docker, AWS…)</li> 	<li>Strong experience in resilient architecture (high availability, scalability)</li> 	<li>Data management: you have experience in integrating and managing large volumes of Data while taking into account performance issues</li> 	<li>Coding skills: skills in one or more scripting languages (Perl, Ruby…) as well as one or more development languages (Python, Java…)</li> </ul><p>Soft skills: while being a tech automation enthusiast with a passion for building tools to make developers' lives easier, you also want and know how to share your expertise with other people to empower them.</p><p>Agile and DevOps approach, with an operational experience as an Ops in a demanding environment. You know what it’s like to manage in production critical systems and you have experience in sharing this knowledge to the teams to enable a “you build it / you run it” mindset.</p>","<ul>   <li>BS in Computer Science or related technical discipline or equivalent practical experience</li>   <li>3-4+ years of experience with high-traffic, high volume, high scalable distributed systems and client-server architectures (clustering, partitioning, sharding, etc)</li>   <li>Some experience working with Data Scientists and finding solutions for them to work efficiently while manipulating high volume of data and be able to work with them and the teams to bring their algorithms at scale</li>   <li>Strong operational experience with AWS, container approaches.</li>  </ul>"
0,senior Big data Engineer,SMARTSOFT PTE. LTD.,Islandwide,Senior Executive,Information Technology,Full Time,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/senior-big-data-engineer-smartsoft-89a30bf67f8015341e9fea060c98f0c0,"<ul>   <li><strong>Massive data</strong>: You will source / examine, analyze, engineer data pipelines for gigabytes/terabytes of structured and unstructured data with our platform to create value for customers.</li>   <li><strong>Pushing the limits</strong>: This role will be on the cutting edge of our Data / Machine Learning platform. As we push to solve more of our customer challenges, you will be prototyping new features, tools and ideas. Innovate at a very fast pace to maintain our competitive edge.</li>   <li><strong>Linux hacking:</strong> You will be masterfully using the command line, including tools like vi/emacs and understanding beyond basics of grep, bash, awk, sed, etc to aggressively dive into data, systems, and compute platforms to get the results you are seeking.</li>   <li><strong>Production deployment</strong>: You will be responsible for integration and deployment of the machine learning pipelines into production where your ideas can come to life.</li>   <li>Coordinate and work with cross functional teams, sometimes located at different geo locations.</li>  </ul>","<ul>   <li><strong>Commercial software engineering:</strong> You have 3+ years of professional software development experience with languages and systems such as Java, Python (PySpark), and version control (git), with good analytical &amp; debugging skills.</li>   <li><strong>Big data:</strong> You have extensive experience with data analytics and working knowledge of big data infrastructure such as Hadoop Eco System, HDFS, Spark, Google Cloud, Big Query, Data Flow (nice to have). You've routinely built data pipelines with gigabytes/terabytes of data and understand the challenges of manipulating such large datasets.</li>   <li><strong>Data Modeling</strong>: Flair for data, schema, data model, PL/SQL, Star &amp; snow flake schema, how to bring efficiency in data modeling for efficient querying data for analysis, understands criticality TDD and develops data validation techniques.</li>   <li><strong>Real Time Systems</strong>: Understands evolution of databases for in-memory, NoSQL &amp; indexing technologies along with experience on real-time &amp; stream processing systems like kafka, Storm.</li>   <li><strong>P</strong>r<strong>oject management:</strong> You demonstrate excellent project and time management skills, exposure to scrum or other agile practices in JIRA.</li>  </ul>"
0,Data Engineer - SQL  /  Big Data  /  Java,DENODO TECHNOLOGIES PTE. LTD.,Central,Professional,Engineering,Full Time,,,,https://www.mycareersfuture.sg/job/data-engineer-sql-big-data-java-denodo-technologies-cfe51cc03bee7d249ecf83fde7a21e8d,"<p><strong><u>Your Opportunity</u></strong></p><p>Denodo is always looking for technical, passionate people to join our Services Engineering team. We want a professional who will travel, consult, develop, train and troubleshoot to enhance our clients’ journey around Data Virtualization.</p><p>Your mission: to help people realize their full potential through accelerated adoption and productive use of Denodo solutions.</p><p>In this role you will successfully employ a combination of high technical expertise and client management skills to conduct on-site and off-site consulting, product implementation and solutions development in either short or long-term engagements being critical point of contact for getting things done among Denodo, partners and client teams.</p><p><strong><u>Duties &amp; Responsibilities</u></strong></p><ul>   <li>Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.</li>   <li>Constantly learn new things and maintain an overview of modern technologies.</li>   <li>Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.</li>   <li>Capable of building and/or leading the development of custom deployments based and beyond client’s requirements.</li>   <li>Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.</li>   <li>Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.</li>   <li>Promote knowledge and best practices while managing deliverables and client expectations.</li>   <li>Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.</li>   <li>Provide technical consulting, training and support.</li>   <li>Develop white papers, presentations, training materials or documentation on related topics</li>  </ul>","<p><strong>Qualifications</strong></p><p><strong><u>Required Skills</u></strong></p><ul>   <li>BS or higher degree in Computer Science.</li>   <li>Solid understanding of SQL and good grasp of relational and analytical database management theory and practice.</li>   <li>Knowledge in Java software development, especially in the database field.</li>   <li>Good knowledge of JDBC, XML and Web Services APIs.</li>   <li>Excellent verbal and written communication skills to be able to interact with technical and business counterparts.</li>   <li>Active listener.</li>   <li>Strong analytical and problem solving abilities.</li>   <li>Lots of curiosity. You never stop learning new things.</li>   <li>Creativity. We love to be surprised with innovative solutions.</li>   <li>Willingness to travel around 50%.</li>   <li>Be a team worker with positive attitude.</li>  </ul><p><strong><u>We Value</u></strong></p><ul>   <li>Experience working with Java frameworks.</li>   <li>Experience working with GIT or other version control systems.</li>   <li>Experience working with BigData and/or noSQL environments like Hadoop, mongoDB, ...</li>   <li>Experience working with caching approaches and technologies such as JCS.</li>   <li>Experience in Windows &amp; Linux (and UNIX) operating systems in server environments.</li>   <li>Business software implementation and integration projects (e.g. ETL/Data Warehouse architectures, CEP, BPM).</li>   <li>Integration with packaged applications (e.g. relational databases, SAP, Siebel, Oracle Financials, Business Intelligence tools, …).</li>   <li>Industry experience in supporting mission critical software components.</li>   <li>Experience in attending customer meetings and writing technical documentation.</li>   <li>Foreign language skills are a plus.</li>  </ul><p><strong>Additional Information</strong></p><p><strong><u>Employment Practices</u></strong></p><ul>   <li>We are committed to equal employment opportunity.</li>   <li>We respect, value and welcome diversity in our workforce.</li>   <li>We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.</li>  </ul>"
0,Senior Database Consultant - Big Data Engineer,PALO IT SINGAPORE PTE. LTD.,Central,Professional,Information Technology,Permanent ...,"$6,000","$12,000",Monthly,https://www.mycareersfuture.sg/job/senior-database-consultant-big-data-engineer-palo-singapore-c1782f4017dc58c1308f3816b938ef0b,"<p>Your profile &amp; role on the project<br> YOU:</p><ul>   <li>Thrive on challenge. When was the last time you failed?</li>   <li>Are curious &amp; always learning. What are you up to right now?</li>   <li>Can deal with constant change. When were you last surprised?</li>   <li>Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?</li>  </ul><p>YOU AGAIN:<br> The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure<br> and apply DevOps practices and solutions. The person will also implement cloud-related and<br> DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond<br> to consultant requests when required will be expected.</p><ul>   <li>Install, maintain, and support on-premises and off-premises cloud stack.</li>   <li>Configure, maintain, and support the cloud-related infrastructures.</li>   <li>Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud.</li>   <li>Ability to develop solutions and self-learn new tools and technologies.</li>   <li>Document, and share knowledge on developed DevOps solutions.</li>  </ul><p>STILL YOU:</p><ul>   <li>Unix / Linux / Bash knowledge</li>   <li>Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.)</li>   <li>Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.)</li>   <li>2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.)</li>   <li>1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner)</li>   <li>1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.)</li>   <li>1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.)</li>   <li>1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk)</li>   <li>Experience with developing and implementing processes to handle releases from</li>   <li>Development to Operations while respecting internal rules, and offering solutions for rollback)</li>   <li>Experience with designing an architecture to implement development-to-production workflows.</li>   <li>Knowledge of SRE, Containers, Kubernetes, Openshift is a plus.</li>   <li>Good understanding of microservice architecture and DevOps practices that support.</li>   <li>Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.</li>  </ul><p>Your role at PALO IT<br> You will be invited to take part in R&amp;D works done within our Practices. You will have the<br> chance to assist or be a speaker at must-attend international IT conferences. You will have the<br> opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT,<br> you will present our offers and take an active role in the development of the company.<br> <br> Your technical environment<br> # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud)<br> # DevOps practices<br> # Linux OS, Shell Scripting, SQL<br> # Agile and scrum environment</p>","<p>✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science</p><p>✔     You are just graduated or have less than 3 years of working experience</p><p>✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing</p><p>✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR)</p><p>✔     Experience with batch &amp; ETL jobs to ingest and process data from multiple data sources</p><p>✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch)</p><p>✔     Experience with querying tools (e.g Hive, Spark SQL, Impala)</p><p>✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming</p><p>✔     You are passionate about technology and continuous learning comes naturally to you</p><p> </p>"
0,"Manager, Data Engineer",AVIVA ASIA PTE LTD,Central,Manager,Information Technology,Permanent,"$10,000","$12,000",Monthly,https://www.mycareersfuture.sg/job/manager-data-engineer-aviva-asia-a5f03c8482421ffd8fcfa6757d53a231,"<p>PURPOSE AND CONTEXT OF THE ROLE</p><p>Taking leadership in:</p><ul>  <li>Design and develop architecture for data services ecosystem spanning Relational and Big Data technologies</li>  <li>Design data models for mission critical and high volume data management, real-time and distributed data process aligning with the business requirements.</li>  <li>Work with business units on their analytics initiatives, supply and/or source analytics expertise and resources.</li>  <li>Ensure the appropriate technology resourcing and support for the Data Engineering and analytics team.</li> </ul><p> </p><p>Lead projects involving high level of coordination among departments and business areas.</p><p> </p><p>OUTCOMES</p><ul>  <li>Produce optimal solutions in the receipt and delivery of data sets to desired destinations</li>  <li>Alignment to Data Strategy, Digital Strategy, IT Strategy, Architecture and Transformation roadmap</li>  <li>Maintain IT Applications Development Excellence amongst IT Development community through detailed development and training and the conduct of Knowledge transfer for completed tasks</li>  <li>Produce Optimal solutions, through detailed Impact Analysis, Technical Solutions, Technical Specifications and provide Leadership in Projects, Change Initiatives and Solution Delivery.</li>  <li>Supervise IT teams to produce and complete assigned tasks for Strategic, Mandatory and Tactical Change Request, within budget and within projected Scope of work.</li> </ul><p> </p>","<p>QUALIFICATIONS</p><ul> 	<li>Bachelor degree or above</li> 	<li>Masters (preferred)</li> </ul><p>KNOWLEDGE/EXPERIENCE</p><p>·A deep understanding of Data Modelling best practices</p><ul> 	<li>Good understanding of  tools and use in a commercial environment</li> 	<li>Preferably of 2-5 years of experience working in Hadoop/ Big Data related field</li> 	<li>Must possess working experience on Hive, Spark, HBase, Sqoop, Impala, Kafka, Flume, Oozie, MapReduce etc</li> 	<li>Working experience on ETL tools like Oracle PLSQL, Informatica etc</li> 	<li>Deep understanding of the Hadoop ecosystem and strong conceptual knowledge in Hadoop architecture components</li> 	<li>Possess data management, data visualization and statistical analysis experience</li> 	<li>Self-starter who works with minimal supervision. Ability to work in a team of diverse skill sets</li> 	<li>Experience working in Agile development process and has good understanding of various phases of Software Development Life Cycle</li> 	<li>Good interpersonal with excellent communication skills -written and spoken English</li> </ul><p> </p><p>SKILLS</p><p><em>Required</em></p><ul> 	<li>Data Warehouse Technologies</li> 	<li>Hadoop Proficiency</li> 	<li>Proficient in Hive, Spark, HBase, Sqoop, Impala, Kafka, Flume, Oozie, MapReduce etc.</li> 	<li>Working experience on ETL tools like Oracle PLSQL, Informatica etc</li> 	<li>data management, data visualization and statistical analysis skills</li> </ul><p> </p><p><em>Desirable</em></p><ul> 	<li>Experience in working in Cloud environment</li> </ul><p> </p>"
0,senior data engineer,FINSURGE PTE. LTD.,Islandwide,Senior Management,Information Technology,Full Time,"$7,000","$8,500",Monthly,https://www.mycareersfuture.sg/job/senior-data-engineer-finsurge-2de8441eb1decb498fb94af1ad4645de,"<p>We are looking for a Senior Data Engineer who will join the Digital Technology Team as we are at an early developmental stage and planning for considerable growth over the next 12 months.<br> We need an experienced data engineer to design and develop data infrastructure.</p><p>As we are looking to build the data pipeline from scratch, you will have autonomy and the technical backing from our<br> engineering team in designing,developing and maintaining this infrastructure.<br> Contribute to key data pipeline architecture decisions and lead the implementation of major initiatives<br> Translating business requirements into technical specifications and documentation<br> Developing code standards, ETL architecture standards, and naming conventions<br> Designing, executing and documenting ETL testing plans<br> Optimizing performance of ETL jobs<br> Develop the team’s data capabilities - share knowledge, enforce best practices and encourage data-driven decisions.</p>","<p>Technical background in computer science, data science, machine learning, artificial intelligence, statistics or other quantitative and computational science<br> 5+ years of experience with a proven track record of building scalable and performant data infrastructure, implementing data<br> warehousing and business intelligence projects:<br> MS SQL Server, Oracle, MySQL, PostgreSQL<br> Delivering production ETL jobs using Informatica stack including:<br> Power Center, PowerExchange, Informatica Data Explorer<br> Experience with the following tools is a bonus:<br> Big Data Management, Big Data Streaming, Enterprise Data Integration, Enterprise Data Lake, Enterprise Data<br> Catalog, Customer 360<br> Experience with insert other Temasek ETL tools e.g. SSIS is a bonus<br> Experience implementing Data Quality (DQ) framework is a bonus:<br> Data profiling<br> DQ validation rules<br> Automatic cleansing<br> 3+ years of experience with Hadoop architecture and components including:<br> Hive<br> Spark<br> Kafka<br> Nifi<br> Sqoop<br> HDFS architecture<br> HBase<br> MapReduce<br> Experience with NoSQL databases is a bonus:<br> MongoDB, Cassandra, etc.<br> Experience building APIs is a bonus<br> Experience with the following languages:<br> SQL<br> Bash<br> HiveQL<br> Scala, SparkSQL, PySpark<br> Python<br> Java</p>"
0,"Senior Manager, Data Engineer",LAZADA SOUTH EAST ASIA PTE. LTD.,Central,Middle Management ...,Information Technology,Permanent,"$7,000","$10,500",Monthly,https://www.mycareersfuture.sg/job/senior-manager-data-engineer-lazada-south-east-asia-6ec839622a88378203648025875ad61a,"<p><u>Team Introduction</u></p><p>Lazada is the number one online shopping &amp; selling destination in Southeast Asia – present in Indonesia, Malaysia, the Philippines, Singapore, Thailand and Vietnam. Lazada helps more than 80,000 local and international sellers as well as 2,500 brands serve the 560 million consumers in the region through its marketplace platform, supported by a wide range of tailored marketing, data, and service solutions. Lazada offers an excellent customer experience through a wide network of logistics partners and its own first- and last-mile delivery arm.</p><p><u>Roles &amp; Responsibilities</u></p><ul> 	<li>Implementing working data projects based on given technical specifications</li> 	<li>Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations.</li> 	<li>Work closely with partner teams to establish the optimal technical solution to business problems</li> 	<li>Monitor &amp; manage data pipelines, ensuring accuracy and stability</li> </ul>",<ul> 	<li>Educational background in Computer Science / Electrical Engineering or similar</li> 	<li>Understanding of database concepts and distributed processing systems</li> 	<li>Experience with programming and understanding of basic algorithms</li> 	<li>Strong command of SQL and database concepts</li> 	<li>Preferred previous knowledge of Hadoop or NOSQL databases</li> 	<li>Excellent communication &amp; problem solving skills </li> </ul>
0,Data Engineer,ABAKUS (ASIA PACIFIC) PTE. LTD.,East,Executive ...,Banking and Finance ...,Permanent,"$4,000","$6,500",Monthly,https://www.mycareersfuture.sg/job/data-engineer-abakus-04089871f96f4fc0f3c88cdbe4930430,"<p>To reinvent an industry, you need to build an all-star team. Join Wecash if you want to leverage upon the power of big data and machine learning to develop and promote products that can provide businesses with better credit profiles of customers and underwrite loans between funding sources and consumers.</p><p>Founded in 2014, we are the first Chinese startup using big data and machine learning to evaluate consumer credit and detect fraud. Our company has raised more than US$200 million in financing over 4 rounds, acquired over 130 million users and have underwritten over Billions of USD loans to transform the lifestyle and credit worthiness of individuals over the past 4 years.</p><p>We are looking for a stellar technologist to drive our expansion in South Asia. If you can understand complex technology, navigate the fintech industry and thrive under ambiguous objectives, join us as our Senior/Lead Data Engineer for Southeast Asia, and help us grow.</p>","<ul> 	<li>Experience working on Big Data technologies such as Spark, Redshift etc</li> 	<li>Good working experience with Kubernetes or containers in cloud such as Docker or AWS</li> 	<li>Strong experience in resilient architecture (high availability, scalability)</li> 	<li>Experience in integrating and managing large volumes of Data while taking into account performance issues</li> 	<li>Skilled in Python, and experienced with packages related to machine learning and data science (e.g. pandas, numpy, matplotlib, scikit-learn)</li> 	<li>Strong foundation in computer science and software engineering, and ability to deliver and test production level code</li> 	<li>Bachelor in Computer Science or related technical discipline or equivalent practical experience</li> 	<li>At least 5 years of experience with highly scalable distributed systems and client-server architectures (clustering, partitioning, sharding, etc)</li> 	<li>Experience working with Data Scientists and finding solutions for them to work efficiently while manipulating high volume of data and be able to work with them and the teams to bring their algorithms at scale</li> 	<li>Passion in building tools, empower developers practicing Agile and DevOps approach, with operational experience in a fast pace and demanding environment.</li> </ul><p>We're building an amazing team and are constantly on the lookout for like-minded and motivated individuals to join our fast-paced and challenging environment, so as to contribute to our mission to improve financial inclusion and change the lives of Southeast consumers.</p>"
0,"Software Engineer, Data Services",HELIX LEISURE PTE. LTD.,Central,Senior Executive,Information Technology,Permanent,"$5,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/software-engineer-data-services-helix-leisure-877f6be3b659dddce49f867141e49e8c,"<p>Helix Leisure is a leading global supplier to the Out of Home Entertainment industry – locations outside the home people visit for entertainment and recreation. Across our core brands – Embed (revenue management systems, e-commerce), Booking Boss (Tours, Attractions and Activities), LAI Games (arcade games), The Locker Network (operating electronic lockers) and Matahari Leisure (equipment manufacturing) we service over 2,500 locations around the globe. Helix operates full service offices in Singapore, Perth, Sydney, Dallas, Dubai and Jakarta. The group enables our customers to create rich experiences for their visitors and guests through both technology and service.</p><p>As we embark on building the next generation platform for our software – a core consumer, supplier and distributor facing application, we are looking for highly motivated professionals who enjoy working in a fast paced, agile development environment. You will be working closely with product owners and UX designers to create and develop best-in-class data service solutions with the ability to use the latest in web development technology.</p><p><strong>Responsibilities:</strong></p><ul> 	<li>Design, develop, test, deploy, maintain and improve software</li> 	<li>Manage individual project priorities, deadlines and deliverables.</li> </ul>","<p><strong>Skills &amp; Qualifications:</strong></p><ul> 	<li>BS degree in Computer Science preferred, similar technical field of study or equivalent practical experience will be considered</li> 	<li>Strong Core Java Development Experience</li> 	<li>Experience working with three or more from the following: web application development, Unix/Linux environments, distributed and parallel systems, machine learning, information retrieval, natural language processing, networking, developing large software systems, and/or security software development</li> 	<li>Working proficiency and communication skills in verbal and written English</li> 	<li>Strong TSQL knowledge, able to optimise queries and understand unoptimised query plans</li> 	<li>Real Time, Multithreaded experience</li> 	<li>Experience with ORM tools such as hibernate</li> 	<li>Experience building high-volume file processing systems</li> 	<li>Experience with payments/transactions</li> 	<li>Experience in an Agile development environment.</li> 	<li>DBA experience</li> 	<li>Effective teamwork and good communication skills with the ability to mentor peers and provide peer code-reviews</li> 	<li>Ability to work effectively with software engineers to enhance test plans and automated testing framework</li> </ul>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-0a23bad0c7261de1a5faa7d8e5196ad9,"<p><strong><u>About the Institute for Infocomm Research (I²R)</u></strong><br> The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg</p><p>We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development.</p><p>Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs.</p><p> </p>","<ul>   <li>Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics</li>   <li>Possess minimum 1 year of relevant work experience</li>   <li>Ability to work independently to translate research ideas into programs with efficient coding</li>   <li>Basic knowledge on data analytics, machine learning, data mining</li>   <li>Proficient in Python, R, C++ or Java</li>   <li>Prior industry experience with engineering, financial services, healthcare, or urban development is a plus</li>   <li>Able to deliver under tight schedule</li>   <li>Good team player with both research and engineering ethics</li>   <li>Good interpersonal and communication skills</li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-890ee3257c7013bc35dfd3c0affdd907,"<p><strong><u>About the Institute for Infocomm Research (I²R)</u></strong><br> The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg</p><p>We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development.</p><p>Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs.</p><p> </p>","<ul>   <li>Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics</li>   <li>Possess minimum 1 year of relevant work experience</li>   <li>Ability to work independently to translate research ideas into programs with efficient coding</li>   <li>Basic knowledge on data analytics, machine learning, data mining</li>   <li>Proficient in Python, R, C++ or Java</li>   <li>Prior industry experience with engineering, financial services, healthcare, or urban development is a plus</li>   <li>Able to deliver under tight schedule</li>   <li>Good team player with both research and engineering ethics</li>   <li>Good interpersonal and communication skills</li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-7498a25a005b0c536731e67949a82865,"<p><strong><u>About the Institute for Infocomm Research (I²R)</u></strong><br> The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg</p><p>We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development.</p><p>Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs.</p><p> </p>","<ul>   <li>Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics</li>   <li>Possess minimum 1 year of relevant work experience</li>   <li>Ability to work independently to translate research ideas into programs with efficient coding</li>   <li>Basic knowledge on data analytics, machine learning, data mining</li>   <li>Proficient in Python, R, C++ or Java</li>   <li>Prior industry experience with engineering, financial services, healthcare, or urban development is a plus</li>   <li>Able to deliver under tight schedule</li>   <li>Good team player with both research and engineering ethics</li>   <li>Good interpersonal and communication skills</li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-8baf748caed9144a3fb5a41ad6b522e2,"<p><strong><u>About the Institute for Infocomm Research (I²R)</u></strong><br> The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg</p><p>We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development.</p><p>Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs.</p><p> </p>","<ul>   <li>Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics</li>   <li>Possess minimum 1 year of relevant work experience</li>   <li>Ability to work independently to translate research ideas into programs with efficient coding</li>   <li>Basic knowledge on data analytics, machine learning, data mining</li>   <li>Proficient in Python, R, C++ or Java</li>   <li>Prior industry experience with engineering, financial services, healthcare, or urban development is a plus</li>   <li>Able to deliver under tight schedule</li>   <li>Good team player with both research and engineering ethics</li>   <li>Good interpersonal and communication skills</li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Senior Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$3,400","$6,800",Monthly,https://www.mycareersfuture.sg/job/senior-research-engineer-i2r-astar-research-entities-b4659907b132bbf61179fb31803ecf39,"<p><strong><u>About the Institute for Infocomm Research (I²R)</u></strong></p><p>The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg</p><p>The project focuses on data management systems, data engineering solutions and deep learning systems for radiology applications. Candidate should have demonstrated interests or experience in:</p><p>1. Experience in the execution of translational projects focused on development, testing and deployment </p><p>2. Big data analytics and data engineering</p><p>3. Experience with biomedical datasets, in particular medical images</p><p>4. Business analysis skills and/or past work with/in clinical partner institutions</p><p> The position entails working in a multi-disciplinary business analytics translation group alongside machine learning and deep learning teams that are closely collaborating with clinical and industry partners on impactful projects that will translate research to deployed technology.</p>","<ul>   <li>Minimum bachelor degree in computer science, computer engineering, mathematics and statistics, data science intensive programs, with expertise in one or more of the following areas: data mining and management, machine learning, time-series data analytics, etc.</li>   <li>Minimum 2 years post completion of last degree</li>   <li>Experience in clinical research environments is a plus</li>   <li>Excellent knowledge of a programming language such as Node.js., java or C++ </li>   <li>Proficient in Python</li>   <li>Good knowledge on data analytics/ machine learning/ data mining and experience in solving real-world data science problems</li>   <li>Able to deliver under tight schedules</li>   <li>Good team player with both research and engineering ethics</li>   <li>Good interpersonal and communication skills</li>   <li>Prior experience with NLP is a big plus</li>   <li>Prior experience with medical image processing, clinical informatics systems and software platforms is a big plus</li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-5084cd98811850f9c05c81be702834ea,"<p><strong><u>About the Institute for Infocomm Research (I²R) </u></strong></p><p>The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualisation solutions. For more information about I²R, please visit www.i2r.a-star.edu.sg</p><p>We are looking for a capable and responsible engineer to work on and make contributions to a major big data R&amp;D project on fraud risk prediction. The work scope involves design and implementation of big data management, analytics and web applications. Successful candidate will work with other research team members to do part of system implementation, data pre-processing, analysis and visualization. Successful candidate will also have opportunities to be involved in other industry projects and/or research projects.</p><p> </p>","<ul>   <li>Minimum Bachelor Degree in computer science or other related fields</li>   <li> <p>Minimum 2 years experience in data analytics related projects</p> </li>   <li> <p>Well-versed in programming (Python, R, Java, J2EE, or C/C++), database (MySQL, NoSQL,MongoDB)</p> </li>   <li> <p>Experience in system development lifecycle</p> </li>   <li> <p>Familiarity with big data analytics toolkits/frameworks such as Spark/Hadoop/Cassandra/Mahout</p> </li>   <li> <p>Good team player, able to multitask and work independently</p> </li>   <li> <p>Good interpersonal and communication skills</p> </li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,South,Professional,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-i2r-astar-research-entities-f0e72022c7d6b0386e377ce08bfba62d,"<p><strong><u>About the Institute for Infocomm Research (I²R) </u></strong></p><p>The Institute for Infocomm Research (I²R) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapore’s largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualisation solutions. For more information about I²R, please visit www.i2r.a-star.edu.sg</p><p>The project focuses on development of machine learning, deep learning and artificial intelligence algorithms for applicants in precision medicine.</p><p>Candidates should have demonstrated interests or experience in one or more of the following:</p><ol>   <li>Analysis of large scale heterogeneous biomedical datastreams (genomics, EMR, imaging, lifestyle)</li>   <li>Projects involving biomarker identification, knowledge discovery, predictive analytics for patient outcomes, and/or clinical application.</li>   <li>R&amp;D for advanced algorithms.</li>  </ol><p>Core responsibilities include preprocessing of raw disparate biomedical datasets, development of automated knowledge extraction and feature engineering pipelines, and design of pilot studies/demos. The position entails working in a multi-disciplinary machine learning and deep learning team in close collaboration with bioinformatics experts, biologists, clinicians, as well as other leading academic and industry partners on impactful projects that have the potential to transform patient-care and deliver improved health outcomes.</p><p> </p>","<ul>   <li>Minimum Bachelor Degree with knowledge or exposure to Computer Science, Bioinformatics, Computational Biology, Statistics, or other Data Science intensive fields</li>   <li>Candidates should have particular experience in one or more of the following areas:    <ul>     <li> Large-scale data handling and/or databases</li>     <li>Experience with biomedical data analysis</li>     <li>Genomics/ Computational and Systems Biology</li>     <li>Medical Imaging</li>     <li>Biomedical informatics/ Healthcare Data Analytics</li>     <li>Knowledge extraction and feature engineering</li>     <li>Natural Language Processing/Text Mining</li>     <li>Exposure to machine learning and deep learning methods is highly encouraged</li>    </ul> </li>   <li>Experience in corporate or application oriented environments is a plus.</li>   <li>Ability to work independently and as part of a multidisciplinary team </li>   <li>Quick learner, willing to acquire the necessary domain knowledge </li>   <li>Good communication skills for proposals, reports, and publications</li>   <li>Proficiency in spoken and written English.</li>   <li>Experience with biomedical and healthcare datasets (EMR, medical imaging, genomics) is a plus.</li>   <li>Strong programming abilities (Eg: Python, R, MATLAB, C/C++, Java, Perl, Bash)</li>   <li>Familiarity with data preprocessing, data science and data visualization tools (Eg: SAS, Tableau, Knime, WEKA, Jupyter notebooks, deep learning, machine learning and visualization libraries)</li>   <li> <p>Bioinformatics applicants looking to switch into fields related to analytics and intelligent systems with significant domain expertise and strong programming skills will also be considered. </p> </li>  </ul><p><strong>The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified.</strong></p>"
0,Data Engineer,NTUC ENTERPRISE NEXUS CO-OPERATIVE LIMITED,Central,Professional,Engineering ...,Full Time,"$5,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-ntuc-enterprise-nexus-co-operative-625ef348b4ebce0c98cf5e41294f8533,"<p>NTUC Enterprise Co-operative Limited is the holding entity and single largest shareholder of the NTUC group of Social Enterprises. We aim to create a greater social force to do good by harnessing the capabilities of the social enterprises to meet pressing social needs in areas like health and eldercare, childcare, daily essentials, cooked food and financial services. Serving over two million customers, NTUC Enterprise wants to enable and empower all in Singapore to live better and more meaningful lives.</p><p>The NTUC Enterprise Centre of Excellence for Data, Digitalisation and Technology leads the transformation of the NTUC Social Enterprises by leveraging digital technologies to become more nimble, adaptable and innovative in today’s digital age. he NTUC Enterprise Centre of Excellence for Data, Digitalisation and Technology has been registered as NTUC Enterprise Nexus, a wholly owned subsidiary of NTUC Enterprise.</p><p>The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance. </p><p>As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&amp;B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture &amp; Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore. </p><p> </p><p>Responsibilities:</p><p>·       As a data engineer, you will be creating, writing and maintaining data transfer process and protocols for the data platform. </p><p>·       Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process. </p><p>·       Design, build, support and optimize new and existing data models and ETL processes.</p><p>·       Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies.</p><p>·       Develop and manage the various dashboards for management decision and data visualizations.</p><p>·       Define and manage SLA for all data processes and own data quality issues.  </p>","<p> </p><p>Preferred qualification and skills: </p><p>·       Advanced degree in computer science, computer engineering, or other technical fields.</p><p>·       6-10 years’ experience having developed data engineering capabilities for large and complex franchises.</p><p>·       Strong data modeling, schema design and SQL development skills </p><p>·       ETL/ELT implementation and data integration</p><p>·       Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc. </p><p>·       Big data platform development (Hadoop/Hive/Hbase/Spark, etc.)</p><p>·       REST/Web API development and management</p><p>·       Hands-on experience in any modern programming language (Python or Java preferred)</p><p>·       Design pattern, 12-factor app principle and modern cloud architecture</p><p>·       Self-motivated and proactive, willing to learn new things</p><p>·       Good communication skills and strong team player          </p>"
0,Data Engineer,NTUC LINK PRIVATE LIMITED,Central,Professional,Engineering ...,Full Time,"$5,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-ntuc-link-a0a7237670675de712423b8209df8127,"<p>The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance. </p><p> </p><p>As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&amp;B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture &amp; Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore. </p><p> </p><p>Responsibility:</p><p>·       As a data engineer, you will be creating, writing and maintaining data transfer process and protocols for the data platform. </p><p>·       Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process. </p><p>·       Design, build, support and optimize new and existing data models and ETL processes.</p><p>·       Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies.</p><p>·       Develop and manage the various dashboards for management decision and data visualizations.</p><p>·       Define and manage SLA for all data processes and own data quality issues.  </p>","<p>Preferred qualification and skills: </p><p>·       Advanced degree in computer science, computer engineering, or other technical fields.</p><p>·       6-10 years’ experience having developed data engineering capabilities for large and complex franchises.</p><p>·       Strong data modeling, schema design and SQL development skills </p><p>·       ETL/ELT implementation and data integration</p><p>·       Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc. </p><p>·       Big data platform development (Hadoop/Hive/Hbase/Spark, etc.)</p><p>·       REST/Web API development and management</p><p>·       Hands-on experience in any modern programming language (Python or Java preferred)</p><p>·       Design pattern, 12-factor app principle and modern cloud architecture</p><p>·       Self-motivated and proactive, willing to learn new things</p><p>·       Good communication skills and strong team player</p>"
0,Lead Data Engineer,JEWEL PAYMENTECH PTE. LTD.,East,Professional,Information Technology,Permanent ...,"$8,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/lead-data-engineer-jewel-paymentech-5ce040f4ff138ac4658c44ded16e1542,"<p>As a Data Engineer you will get to work on a wide range of problems using the cutting-edge technologies in Big Data and Data Science. You are required to translate Data Science and Machine learning based solutions into scalable code, and to develop innovative solutions to collect/cleanse/store/process data. In case you are very passionate about building high throughput, low latency, fault tolerant software then this position is for you. </p><p><strong>To be successful in this role, you will need to: </strong></p><p>Capture/Analyse requirements and lead the design/architecture of solutions to meet requirements. </p><p>Write code by using best software development practices/security standards. Lead projects end-to-end from conceptualisation to deployment.<br> Write clear &amp; concise documentation for solutions/code.<br> Contribute ideas within team to build better code. </p><p>Continuously improve knowledge on new technologies. Excellent in English, both written and spoken.</p>","<p><strong>Required Qualifications: </strong></p><p>10+ years of experience building highly scalable, low latency, fault tolerant systems.<br> B.Sc., Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.).<br> Hands on knowledge of at least 2 programming languages of Python/Java/Scala. In depth knowledge of at least 2 of Hadoop/Spark/Storm/Flink/Kafka.<br> In depth knowledge of at least two NoSQL database (HBase/Cassandra/DynamoDB/Neo4j/Mongo/MemcacheDB)<br> Good knowledge of at least some machine learning algorithms like logistic regression/ SVM/ Random Forests. </p><p>Knowledge of advanced data structures and algorithms.</p><p><strong>Preferred Qualifications</strong>:</p><p>Knowledge of large scale ML systems like Tensorflow/pytorch. Knowledge of advanced machine learning algorithms like CNN/RNN Knowledge of Cloud environments like AWS/GCP.<br> Knowledge of indexing systems like Elastic search/Solr/Lucene. </p><p>Proficient in using CI/CD and knowledge of Jenkins/SonarQube/Ansible.</p><p><strong>You’re a perfect fit us if you are </strong></p><ul> 	<li>A master problem solver, and able to use own initiative to develop suitable solutions. </li> 	<li>A strong communicator with the ability to convey information to others in a simple and unambiguous way. </li> 	<li>An innovative, original thinker approach to job responsibilities, methods and processes. </li> 	<li>An energetic person who can be trusted to get a job done. </li> </ul><p> </p>"
0,Data Engineer,HOOQ DIGITAL PTE. LTD.,Central,Manager,Engineering ...,Permanent,,,,https://www.mycareersfuture.sg/job/data-engineer-hooq-digital-951d3deac4969252c3ee86cb1284d396,"<p>We are looking for a Data Engineer to join our rapidly expanding Data &amp; Analytics team. You will help shape how we build and grow our service in the region. We look for self-starters who demand the best.</p><p><strong>Key Responsibilities:</strong></p><ul>   <li> Develop ETL/ELT jobs to integrate new data into the data warehouse or build new reporting schemas</li>  </ul><ul>   <li>Develop data pipelines, both bath and realtime from various platforms into the data lake</li>  </ul><ul>   <li>Manage various data platforms and seek out new technologies to improve efficiency</li>  </ul><ul>   <li>Develop advanced analytical models that help the business identify trends within customer base and behavior</li>  </ul><ul>   <li>Work closely with the business to understand data needs and create data sets to enable reporting and dashboards to monitor business performance</li>  </ul><ul>   <li>Ensure the data warehouse load jobs run as per schedule and data availability to the business is uninterrupted</li>  </ul><ul>   <li>Continuously improve the information management platforms of the company to leverage benefits</li>  </ul>","<p><strong>Desired Skills and Experience</strong></p><ul>   <li>Minimum 3 years of solid development experience within a data warehouse/information management team with strong understanding of programming languages like Java, Python, JavaScript and SQL.</li>  </ul><ul>   <li>Hands on experience in full-stack development, design and architecture. Experience in creating a REST API that can handle a production load (code + deploy).</li>  </ul><ul>   <li>Familiarity with AWS (DynamoDB, Redshift, S3, EC2, RDS, Lambda) (Will be an advantage but not mandatory)</li>  </ul><ul>   <li>Minimum 3 years development experience with ETL/ELT tools (preferably Pentaho DI, Informatica, Datastage or Talend)</li>  </ul><ul>   <li>Proven experience with Data Warehousing and Big Data technologies</li>  </ul><ul>   <li>Working knowledge of big Data Technologies like Hadoop, Hive, Spark and streaming/messaging services like Kafka,Spark streaming.</li>  </ul><ul>   <li>Solid understanding of some BI tools such as Cognos, QlikView or Tableau.</li>  </ul><ul>   <li>Comfortable working in dynamic fast paced environment with competing priorities. Self-starter and willing and able to learn on your own</li>  </ul><ul>   <li>Work well within a team environment and willing to accommodate task and duties that maybe outside of your JD for limited time periods</li>  </ul>"
0,Data Engineer,SENSORFLOW PTE. LTD.,Central,Senior Executive,Information Technology,Permanent,"$6,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-sensorflow-84b3983ff61718861b98b5db0dfea38f,"<p><em>At SensorFlow we are planning for considerable growth over the next 12 months and need a data engineer to design and develop SensorFlow’s data infrastructure. As we are looking to build the data pipeline from scratch, you will have full autonomy and the technical backing from our engineering team in designing, developing and maintaining this infrastructure.</em></p><p><strong>Job Roles &amp; Responsibilities</strong></p><ol>   <li> <p>Design, develop and maintain SensorFlow’s infrastructure for streaming, processing and storage of data. Build tools for effective maintenance and monitoring of the data infrastructure.</p> </li>   <li> <p>Contribute to key data pipeline architecture decisions and lead the implementation of major initiatives.</p> </li>   <li> <p>Work closely with stakeholders to develop scalable and performant solutions for their data requirements, including extraction, transformation and loading of data from a range of data sources.</p> </li>   <li> <p>Develop the team’s data capabilities – share knowledge, enforce best practices and encourage data-driven decisions.</p> </li>  </ol>","<p><strong>Skill Requirements</strong></p><ol>  <li>  <p>Solid Computer Science fundamentals, excellent problem-solving skills and a strong understanding of distributed computing principles.</p>  </li>  <li>  <p>At least 2 years of experience in a similar role, with a proven track record of building scalable and performant data infrastructure.</p>  </li>  <li>  <p>Expert SQL knowledge and deep experience working with relational and NoSQL databases (e.g. HBase, Cassandra).</p>  </li>  <li>  <p>Advanced knowledge of Apache Kafka and demonstrated proficiency in Hadoop v2, HDFS, MapReduce.</p>  </li>  <li>  <p>Experience with stream-processing systems (e.g. Storm, Spark Streaming), big data querying tools (e.g. Pig, Hive) and data serialization frameworks (e.g. Protobuf, Thrift, Avro).</p>  </li> </ol><p><strong>Tech Stack</strong></p><ol>  <li>Data storage: Amazon DynamoDB</li>  <li>Service Layer: Amazon Lambda, Amazon API Gateway</li>  <li>Service backend: JavaScript/TypeScript,</li>  <li>Node.js</li>  <li>Web frontend: Angular</li>  <li>Mobile: Ionic</li> </ol><p>For Interested candidates, please email us your full resume to: jobs@sensorflow.org.  We regret only shortlisted candidate will be notified.</p>"
0,Data Engineer,GUMI ASIA PTE. LTD.,Central,Professional ...,Information Technology,Full Time,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-gumi-asia-bf8174edbdaeab1602d40f6fa7afd0e6,"<ul>   <li>Design, develop, implement, and evolve data pipelines powering core data sets and key business and performance metrics</li>   <li>Identify, troubleshoot, and resolve any performance, system or data related issues, and work to ensure data consistency and integrity</li>   <li>Work with Product and Marketing teams on data requirements. </li>   <li>Work with various game teams on data set and data flow to ensure that data requirements are met.</li>   <li>Ensure the quality, accuracy, and timeliness of analytical data</li>  </ul>","<ul>   <li>Min. 5 years working in a large analytical data ecosystem</li>   <li>Strong technical understanding of data modelling, design, architecture principles, and techniques to take business requirements from concept to implementation</li>   <li>Strong knowledge of relational databases and SQL.</li>   <li>Knowledge of Python, PHP, Java, Linux architecture and scripting</li>   <li>Extensive background extracting and transforming complex data sets. i.e. ETL </li>   <li>Experience with database design and star schema data warehouse theory</li>  </ul>"
0,Senior Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Central,Senior Executive,Information Technology,Permanent,"$8,300","$15,000",Monthly,https://www.mycareersfuture.sg/job/senior-level-data-engineer-traveloka-services-b0cb80230dcbaa180a9009d484df9ae5,"<p>Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience.</p><p>What you do will be mixed of software engineering, system architecture design, and operation:</p><ul>   <li>You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running</li>   <li>Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.</li>   <li>Explore/learn new technologies that can complement or replace our current stack to improve it.<br>  </li>  </ul>","<ul> 	<li>Passion in big data, software engineering, and systems.</li> 	<li>Excellent analysis and reasoning of system behaviors</li> 	<li>8+ years hands-on experience</li> 	<li>Uphold best practices and principle around clean code, testing, continuous integration</li> 	<li>Strong team player and collaborator</li> 	<li>Having high level of responsibility and resilience in dealing with issues</li> 	<li>Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.</li> 	<li>Familiar with Java/JVM. Python is added advantage </li> 	<li>Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.</li> 	<li>Having systems operational experience is a bonus, but not required.<br> 	 </li> </ul>"
0,Mid -  Senior Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Central,Executive,Information Technology,Permanent,"$6,100","$10,700",Monthly,https://www.mycareersfuture.sg/job/mid-senior-level-data-engineer-traveloka-services-9dadd0b7466285dd52264503a3893a77,"<p>Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience.</p><p>What you do will be mixed of software engineering, system architecture design, and operation:</p><ul>   <li>You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running</li>   <li>Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.</li>   <li>Explore/learn new technologies that can complement or replace our current stack to improve it.<br>  </li>  </ul>","<ul> 	<li>Passion in big data, software engineering, and systems.</li> 	<li>Excellent analysis and reasoning of system behaviors</li> 	<li>6+ years hands-on experience</li> 	<li>Uphold best practices and principle around clean code, testing, continuous integration</li> 	<li>Strong team player and collaborator</li> 	<li>Having high level of responsibility and resilience in dealing with issues</li> 	<li>Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.</li> 	<li>Familiar with Java/JVM. Python is added advantage </li> 	<li>Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.</li> 	<li>Having systems operational experience is a bonus, but not required.<br> 	 </li> </ul>"
0,Mid Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Central,Executive,Information Technology,Permanent,"$4,300","$7,600",Monthly,https://www.mycareersfuture.sg/job/mid-level-data-engineer-traveloka-services-25d8051597693057fd4fc7eb55143515,"<p>Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience.</p><p>What you do will be mixed of software engineering, system architecture design, and operation:</p><ul> 	<li>You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running</li> 	<li>Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.</li> 	<li>Explore/learn new technologies that can complement or replace our current stack to improve it.<br> 	 </li> </ul>","<ul> 	<li>Passion in big data, software engineering, and systems.</li> 	<li>Excellent analysis and reasoning of system behaviors</li> 	<li>3+ years hands-on experience</li> 	<li>Uphold best practices and principle around clean code, testing, continuous integration</li> 	<li>Strong team player and collaborator</li> 	<li>Having high level of responsibility and resilience in dealing with issues</li> 	<li>Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.</li> 	<li>Familiar with Java/JVM. Python is added advantage </li> 	<li>Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.</li> 	<li>Having systems operational experience is a bonus, but not required.<br> 	 </li> </ul>"
0,Junior - Mid Level Data Engineer,TRAVELOKA SERVICES PTE. LTD.,Central,Fresh/entry level,Information Technology,Permanent,"$3,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/junior-mid-level-data-engineer-traveloka-services-32e223ac87c140e00e2bec31f5d7eb29,"<p>Data Engineers at Traveloka are passionate on designing, building, and maintaining our growing big data platform. We collect millions of events everyday to our data lake for insights, and to our real time pipeline for enabling many data-driven features such as personalized user experience.</p><p>What you do will be mixed of software engineering, system architecture design, and operation:</p><ul> 	<li>You will be designing, building, supporting and scaling our data infrastructure. Including monitoring, alerting and debugging infrastructure that is streaming millions of events per hour with thousands of pipelines running</li> 	<li>Collaborate and coordinate with other departments (product, etc) to solve their use case using data technology; state of the art big data stack such as Kafka, Pubsub, Spark, DataFlow, BigQuery, Airflow, etc. on hundreds of terabytes data.</li> 	<li>Explore/learn new technologies that can complement or replace our current stack to improve it.<br> 	 </li> </ul>","<ul> 	<li>Passion in big data, software engineering, and systems.</li> 	<li>Excellent analysis and reasoning of system behaviors</li> 	<li>Fresh Graduate to 4 years hands-on experience</li> 	<li>Uphold best practices and principle around clean code, testing, continuous integration</li> 	<li>Strong team player and collaborator</li> 	<li>Having high level of responsibility and resilience in dealing with issues</li> 	<li>Preferably familiar with big data infrastructure (such as Kafka, Spark, etc.), cloud based infrastructure, varying databases, security concerns would be an advantage.</li> 	<li>Familiar with Java/JVM. Python is added advantage </li> 	<li>Experience working with data infrastructure will be valuable, but your desire to learn data infrastructure is more important.</li> 	<li>Having systems operational experience is a bonus, but not required.<br> 	 </li> </ul>"
0,Data Engineer,JEWEL PAYMENTECH PTE. LTD.,East,Professional,Information Technology,Permanent ...,"$4,000","$5,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-jewel-paymentech-b5ed42b992f59a193bacf860079ba10f,"<p>As a Data Engineer you will get to work on a wide range of problems using the cutting-edge technologies in Big Data and Data Science. You are required to translate Data Science and Machine learning based solutions into scalable code, and to develop innovative solutions to collect/cleanse/store/process data. In case you are very passionate about building high throughput, low latency, fault tolerant software then this position is for you.</p><p><strong>To be successful in this role, you will need to:</strong></p><ul>   <li>Analyze requirements and deliver solutions that meet requirements.</li>   <li>Write code by using best software development practices.</li>   <li>Produce code that meets security standards.</li>   <li>Estimate timelines and deliver solutions within agreed timeline.</li>   <li>Write clear &amp; concise documentation for solutions/code.</li>   <li>Contribute ideas within team to build better code.</li>   <li>Continuously improve knowledge on new technologies.</li>   <li>Excellent in English, both written and spoken.</li>  </ul>","<ul>   <li>B.Sc., Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.).</li>   <li>Knowledge in the use and application of Python to develop complex software.</li>   <li>General machine learning techniques and technologies (e.g., Bayesian classifiers, regression techniques, graphical models, working with unbalanced data-sets) as well as applications (e.g., predictive analytics).</li>   <li>NoSQL Database Programming/Development.</li>   <li>Manipulation of various types of data; data cleaning, filtering, and pre-processing for example with text/images.</li>   <li>Knowledge and experience in the use of cloud computing platforms (AWS/Azure/GCP/etc).</li>   <li>SQL familiarity and database technologies (e.g., row versus column stores, in-memory DB, DB clustering, HA for DB).</li>   <li>Familiarity and experience with Linux environments.</li>   <li>Understanding batch (e.g., Apache Hadoop / Map Reduce) and stream processing approaches / frameworks (e.g., Apache Spark).</li>  </ul><p> </p><p><strong>You’re a perfect fit us if you are</strong></p><ul>   <li>A master problem solver, and able to use own initiative to develop suitable solutions.</li>   <li>A strong communicator with the ability to convey information to others in a simple and unambiguous way.</li>   <li>An innovative, original thinker approach to job responsibilities, methods and processes.</li>   <li>An energetic person who can be trusted to get a job done.</li>  </ul>"
0,L1 Desktop Engineer - Scotts Road - OS Backup & Server’s Data Backup (A1),THE SUPREME HR ADVISORY PTE. LTD.,Islandwide,Senior Executive,Information Technology,Full Time,"$1,800","$2,100",Monthly,https://www.mycareersfuture.sg/job/l1-desktop-engineer-scotts-road-os-backup-server%E2%80%99s-data-backup-supreme-hr-advisory-a13f8fd321d4437ec06552b3f6e51849,<p>location: Scotts Road <br>  </p>,"<p>MAIN ROLES AND RESPONSIBILITIES<br> • OS Backup &amp; Server’s Data Backup<br> • Network, VOIP &amp; Server Administration<br> • PC’s Installation &amp; Configuration<br> • OS &amp; Software Installation &amp; Configuration<br> • Troubleshooting PC’s, Notebook’s, Printer’s &amp; Network Equipment<br> • Troubleshooting OS &amp; Software issues<br> • Create/ Manage computer &amp; notebook Asset List</p>"
0,"Data Engineer, Modeling & Onboarding",EYEOTA PTE. LTD.,East,Middle Management,Information Technology,Full Time,"$8,000","$15,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-modeling-onboarding-eyeota-1bff565c5baa88783a0f179db8b9058a,"<p>Eyeota is looking for an exceptional Data Engineer who can contribute to building a world-class big data engineering stack that will be used to fuel our Machine Learning product pipeline. This person will be contributing to the architecture, operation, and enhancement of:</p><ol> 	<li> Our petabyte-scale data platform with a key focus on finding solutions that can support the Machine Learning product roadmap. This platform ingests terabytes of data daily which need to be made available to a variety of Machine Learning use cases.</li> 	<li>Our bespoke Machine Learning pipelines. This will also provide opportunities to contribute to the prototyping, building, and deployment of Machine Learning models.</li> </ol><p>The candidate should have significant experience in developing and operating a modern data pipeline platform and should have a keen interest in Machine Learning and Data Science</p>","<p><strong>You:</strong></p><ul> 	<li>Minimum 4 years</li> 	<li>Experience working with petabyte-scale data</li> 	<li>Experience architecting, developing, and operating data warehouses, big data analytics platforms, and high-velocity data pipelines</li> 	<li>Exposure to modern Big Data tech: Cassandra/Scylla, Kafka, Ceph, the Hadoop Stack, Spark, Flume, Hive, Druid etc… while at the same time understanding that certain problems may require completely novel solutions</li> 	<li>Exposure to one or more modern ML tech stacks: Spark ML-Lib, Tensorflow, Keras, GCP ML Stack, AWS Sagemaker</li> 	<li>Deep technical understanding of Golang and/or Java</li> 	<li>Production experience with Python is a plus</li> 	<li>Exposure to configuration management tools such as Ansible or Salt</li> 	<li>Exposure to IAAS platforms such as AWS, GCP, Azure…</li> 	<li>Strong buyer of Agile/Lean values</li> 	<li>Experience with supporting and troubleshooting large systems</li> </ul>"
0,Data Engineer (Python / Central),PEOPLE PROFILERS PTE. LTD.,Central,Junior Executive,Information Technology,Permanent,"$4,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-people-profilers-c751566bb80319a39400f1f21ffd396b,"<ul>   <li><strong>Join a fast-expanding and highly-specialised tech company</strong></li>   <li><strong>Good exposure in data analytics projects</strong></li>   <li><strong>Central location</strong></li>   <li><strong>Great company culture &amp; working environment</strong></li>  </ul><p> </p><p><strong>Requirements</strong></p><ul>   <li>Make enhancements to data collection, structure &amp; delivery</li>   <li>Use automated methods for data compilation</li>   <li>Build robust batch &amp; streaming pipelines</li>   <li>Write clear and high-quality code (including in Python)</li>   <li>Work well in a team</li>  </ul>","<p><strong>Requirements</strong></p><ul>   <li>Degree in a technical/quantitative discipline e.g. Mathematics/Computer Science</li>   <li>Ideally at least 1 year of relevant experience</li>   <li><strong>Experience in Python programming, web crawling</strong></li>   <li>Knowledge of AWS platforms</li>  </ul><p> </p><ul>   <li>Helpful:</li>  </ul><p>-Familiarity with ETL design &amp; database management</p><p>-Familiarity with NoSQL database</p><p>-Knowledge of machine learning techniques</p><p> </p><p>Successful candidates can expect a very competitive salary package with comprehensive benefits. Interested applicants may wish to email your resume in a detailed Word format to <strong>ruth.gan@peopleprofilers.com. Please include last drawn and expected salaries and notice period.</strong></p><p>We regret that only shortlisted candidates will be notified.</p><p> </p><p><strong>Gan Huiru  Recruitment Consultant </strong></p><p><strong>Tel: +65 6594 9897 Fax +65 6835 7890 </strong></p><p> Address: 100 Beach Road #33-06 Shaw Tower Singapore 189702</p><p>Email: ruth.gan@peopleprofilers.com</p><p>EA License Number: 02C4944</p><p>Registration Number: R1768917</p>"
0,Senior Engineer  /  Engineer - Data Management,INFINEON TECHNOLOGIES ASIA PACIFIC PTE LTD,Central,Executive,Engineering ...,Permanent ...,"$3,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/senior-engineer-engineer-data-management-infineon-technologies-asia-pacific-3403f6d4103cc4c5d37c0675be210fbc,"<p>You are responsible to support the automated / productivity projects which are relevant to Automated Test Equipment (ATE), and improve data handling towards automation.</p><p>In your new role you will:</p><ul> 	<li><strong>Support automated / productivity projects</strong> relevant with Automated Test Equipment (ATE) &amp; <strong>data handling</strong></li> 	<li><strong>Improve data clarity</strong> with scripting towards yield improvement</li> 	<li><strong>Drive &amp; improve data relevant KPI</strong> (data quality, process time) towards data automation</li> 	<li>Responsible for <strong>production of automated computer hardware and software</strong> for test equipment</li> 	<li><strong>I</strong><strong>nstall and configure, investigate, diagnose</strong> and solve ATE computer software and hardware issues</li> </ul>","<p>You are best equipped for this task if you have:</p><ul> 	<li>Bachelor's Degree in Engineering / Information Technology</li> 	<li>Good knowledge on <strong>computer hardware, and standard application support</strong></li> 	<li>Good <strong>communication &amp; analytical </strong>problem-solving skills</li> 	<li>Previous experience in the<strong> semiconductor testing field</strong> will be advantageous</li> 	<li>Candidate must be comfortable working on both <strong>Windows and Linux environmen</strong><strong>t</strong></li> 	<li>Good Understanding of Programming / Query languages / Visualisation software such as <strong>Python,Perl, Javascript, C / C++, SQL,Tableau</strong></li> </ul><p>Please apply via https://www.infineon.com/cms/en/careers/jobsearch/jobsearch/32237-Senior-Engineer---Engineer-Data-Management/ </p>"
0,Lead Electrical Engineer (Data Centre),PM ASIA PROJECT SERVICES PTE. LTD.,West,Senior Executive,Engineering,Permanent ...,"$7,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/lead-electrical-engineer-pm-asia-project-services-670e2d8df5923f0e81e3b39995f7038f,"<p><strong>Overview:</strong></p><ul> 	<li>Lead the <strong>Electrical Design</strong> of large scale, high end industrial facilities. </li> 	<li>Have knowledge and experience in designing Electrical systems for Data Centres, including Medium Voltage, Low Voltage Power Systems, Emergency Power Systems, ELV’s (CCTV, Interlocks, Fire Alarm, Power Monitoring System)</li> 	<li>Work in a multi-disciplinary design office environment for global clients.</li> 	<li>Display a personal commitment to safety, hold safety as a core value and provide safety leadership in the performance of all work activities</li> 	<li>Be quality focussed, producing well engineered designs to the highest standards in an ISO9000 Quality System environment</li> </ul><p> </p>","<ul> 	<li>Degree in Electrical Engineering, Chartered Engineer preferred</li> 	<li>At least 10 years’ of experience of relevant experience </li> 	<li>Experience within the Data Centre/ Pharmaceutical / Food &amp; Nutriton industry preferred</li> </ul>"
0,Big Data Engineer (287102),SIEMENS PTE. LTD.,Central,Professional ...,Information Technology,Permanent ...,"$4,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/big-data-engineer-siemens-b60dbaf7939bcf609cb9866708a184ac,"<p><strong>What are my responsibilities?</strong></p><ul> 	<li>Responsible for the integration of large, structured and unstructured data volumes into the existing cloud platforms</li> 	<li>Development of scalable end-to-end data pipelines for batch and stream processing</li> 	<li>Execution of the data integration activities (ETL /ELT) for populating the data lake and integrating diverse data sources</li> 	<li>Execution an further development of the physical implementation of the logical data model into a physical implementation in the data lake</li> 	<li>Implementation of solutions for reference data and master data management within the context of the mobility data business</li> 	<li>Execution of data quality measurements and implementation of data quality improvement</li> </ul>","<p><strong>What do I need to qualify for this job?</strong></p><ul> 	<li>University degree in an appropriate area (e.g.informatics)</li> 	<li>At least 2 years of relevant work experience</li> 	<li>Experience with modern big data technologies like Hadoop, MapReduce, Kafka, Hive, Presto, Spark, etc.</li> 	<li>Experience with cloud solutions like AWS</li> 	<li>Experience with programming languages like SQL, Scala, Python, Java</li> 	<li>Experience with enterprise application integration</li> </ul>"
0,High-Performance Data Engineer,NIOMETRICS (PTE.) LTD.,East,Professional,Information Technology,Permanent,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/high-performance-data-engineer-niometrics-66d8658e3e2ccf132df50b9b94f43931,"<p><strong>WHAT WE DO</strong></p><p>We invite you to be part of our ambitious, close-knit team creating systems for large customers who need to crunch through Tbps of data in real-time. Our approach is relentless performance-oriented software engineering vs. server sprawl in our customers' datacentres.</p><p>You will use the latest high-end hardware and continuously devise ways to push the envelope of software performance.</p><p>We build in-house systems if we must. We had to for indexing 1M 60-column rows/s, for aggregating high throughput event streams over hundreds of combinations of dimensions, and for pattern matching 5M patterns at 100Gb/s per 2RU. We use these to solve real customer problems.</p><p>You will experiment wildly. For example we implemented network monitoring using a GPU, and we tested 4-socket machines with 2T RAM. Our current favourite platform is a 2-socket system with E5-2699v4 CPUs (88 lcores in total), 4x40Gbps NICs and 1T RAM, which we use to process 160Gbps.</p><p>You will help us build a successful software platform for the long run. We invest a lot in flexibility, such as with our extensible rule engine and declarative aggregation system that empowers our analysts and helps us minimise the C code we have to write for supporting disparate use-cases.</p><p>We know the devil is in the details. You will improve performance through better memory allocation systems and better data structures, all while ensuring that they are integrated with Address Sanitizer and fully tested using unit tests and end-to-end regression tests.</p><p>We work end-to-end. You will implement data engineering solutions that are both efficient and secure for handling events from 500 million users, and to extract insight without leaking individual information.</p><p>We want to show off. To attract the best programmers we plan to showcase our technology. You can be part of our effort to open-source interesting pieces of our technology stack.</p><p> </p><p><strong>YOUR ROLE AS HIGH-PERFORMANCE DATA ENGINEER</strong></p><p>As a High-Performance Data Engineer, you will create and maintain tools, mainly in C, for crunching large amounts of data in files or streams.</p><p>You will have to think both big, in terms of overall architecture, and small, in terms of low-level optimisations, to deliver solutions that are reusable, and match the performance of the best hardware.</p><p>Every capability you add directly translates to new offerings made possible. Every percent of performance improvement directly translates to large cost savings. At the same time, the correctness and reliability of your work will be the cornerstone to our customers’ trust.</p>",<p><strong>WHAT WE VALUE</strong></p><ul>   <li>Bachelor’s or Higher Degree in Computer Science or equivalent</li>   <li>Software craftsmanship</li>   <li>Attention to reliability and successful delivery</li>   <li>Experience with large C code bases and high-performance C programming</li>   <li>Familiarity with shared memory data structures and parallel algorithms</li>   <li>Proficiency with Linux system &amp; development tools</li>  </ul>
0,Data Center (System) Engineer,CAPITA PTE. LTD.,Islandwide,Junior Executive,Information Technology,Contract ...,"$2,500","$3,000",Monthly,https://www.mycareersfuture.sg/job/data-center-engineer-capita-55edf1efb48a58087f2beab5fe483a24,"<p>​<strong>Responsibility </strong></p><ul>   <li>Monitoring of ESX, OS</li>   <li>Batch Monitoring</li>   <li>Service Request Execution</li>   <li>Coordinate with Appointed vendor for Offsite tape archival</li>   <li>Restoration of VM/s</li>   <li>Batch execution and monitoring, batch output &amp; event handling, batch incident identification, escalation &amp; reporting</li>   <li>Tape backups, media handling, tape library operations and off-site storage</li>   <li>Server health checks</li>   <li>Start-up, shutdown, reboot/restart systems &amp; services</li>   <li>Generate daily/ weekly/ monthly/ yearly/ ad-hoc reports and dispatch reports to users &amp; customers</li>   <li>Adhere to all operational &amp; physical security procedures</li>   <li>Provide operational support during DR Exercises at DR sites</li>   <li>Work towards acceptable audit rating</li>  </ul>","<p><strong>Requirements:</strong></p><ul>   <li>Minimum 1 year of experience in Data Center</li>   <li>Experience in monitoring of servers and network</li>   <li>Tape management, facility checks</li>  </ul><p>Interested candidates, please click the Äpply Now"" below<br> Only shortlisted applicants will be notified by our consultants.</p><p> </p><p>CAPITA PTE LTD | EA License No : 08C2893<br> Tan Chin Yin | REG No : R1762272</p>"
0,Data Development Engineer,Company Undisclosed,Central,Professional,Banking and Finance,Full Time,"$6,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-development-engineer-38aad66c1a08506f4012e0c235d5b40c,"<p>WorldQuant develops and deploys systematic financial strategies across a variety of asset classes and global markets. We seek to produce high-quality predictive signals (Alphas) through our proprietary research platform to employ financial strategies focused on exploiting market inefficiencies. Our teams work collaboratively to drive the production of Alphas and financial strategies – the foundation of a sustainable, global investment platform.</p><p> </p><p>Technologists at WorldQuant research, design, code, test and deploy projects while working collaboratively with researchers and portfolio managers. Our environment is relaxed yet intellectually intense. Our teams are lean and agile, which means rapid prototyping of products with immediate user feedback. We seek people who think in code, aspire to solve undiscovered computer science challenges and are motivated by being around like-minded people. In fact, of the 600 employees globally, approximately 500 of them code on a daily basis.</p><p> </p><p>WorldQuant’s success is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Great ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess a mindset of continuous improvement. That’s a key ingredient in remaining a leader in any industry.   </p><p> </p><p>Our goal is to hire the best and the brightest. We value intellectual horsepower first and foremost, and people who demonstrate an exceptional talent. There is no roadmap to future success, so we need people who can help us create it. Our collective intelligence will drive us there.</p><p> </p><p><strong>The Role:</strong> In this role, candidate will implement and maintain software towards creation of new datasets. Data sets will be consumed internally by researchers and utilized by internal quantitative models. Candidate will design efficient algorithms for collection, analysis, processing and filtering of data.</p><p> </p><ul> 	<li>Work with the global team in designing and implementing data retrieval software for various data sets</li> 	<li>Implement the rules and procedures that ensure integrity in data sets</li> 	<li>Collect and analyze statistics on market data applications and devise approaches to improve the relevant processes</li> 	<li>Develop and enhance monitoring tools to detect various types of errors in data</li> </ul>","<p><strong>What You’ll Bring:</strong></p><p> </p><ul> 	<li>Background in Computer Science, Engineering, Math or Physics, with minimum Bachelor’s degree. Proof of good academic record (such as GPA and other relevant test scores)</li> 	<li>Effective problem-solving skills both independently and as member of a team</li> 	<li>Good communication skills: must be fluent in English, spoken and written</li> 	<li>Experience working under Linux environment, familiar with vi or emacs for editing files</li> 	<li>Interested in applying technology to real world situation, comfortable working in fast paced work environment, detail oriented and capable performing tasks under time pressure</li> 	<li>Experience with programming in C/C++, familiar with common algorithms and data structures (binary tree, sorting, etc), Object Oriented programming and design patterns. Familiarity with compilers, debuggers under Linux (gcc, g++, gdb).</li> 	<li>Experience with scripting languages, such as Perl, Python, and shell scripting</li> 	<li>Knowledge of basic statistics/probability, familiar with concepts such as correlation, standard deviation and how to compute</li> 	<li>Familiarity with databases (such as MySQL)</li> </ul>"
0,MCT Big Data Engineer,Company Undisclosed,North,Non-executive,Engineering ...,Permanent ...,"$3,400","$6,800",Monthly,https://www.mycareersfuture.sg/job/mct-big-data-engineer-d7f534d77330aac893279fc384dca2bd,"<p>Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?</p><p> </p><p>If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.</p><p> </p><p>As an MCT Data Engineer at company, you will:</p><p> </p><p>* Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&amp;D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc.</p><p>* Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data</p><p>* Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs</p><p>* Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals</p><p>* In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.</p><p> </p><p>Responsibilities and Tasks include, but not limited to:</p><p> </p><p>* Understanding business needs and strategy to develop data science solutions</p><p>* Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments</p><p>* Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem.</p><p>* Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc.</p><p>* Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics</p><p>* Creating intuitive user interface for interactive data visualization to explain insights from data</p><p>* Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions</p><p>* Documenting the train of thoughts used to design and implement solutions along with managed source code</p><p>* Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites</p>","<p>Qualifications and Experience:</p><p>* B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work </p><p>* Minimum 2 years of experience working in big data and data science projects and teams</p><p>* Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must</p><p>* Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must</p><p>* Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus</p><p>* Good grasp of statistical and scientific programming packages in Python, R, etc.</p><p>* Good grasp of data science concepts with emphasis on machine learning techniques is a plus</p><p>* Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus</p><p>* Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.)</p><p>* Strong communication skills (written, verbal and presentation)</p><p>* Willing to do international travel</p>"
0,IT - BIG DATA ENGINEER,Company Undisclosed,North,Non-executive,Engineering ...,Permanent ...,"$3,400","$6,800",Monthly,https://www.mycareersfuture.sg/job/-big-data-engineer-8e55a4d0f381865a40d9d1930e36d367,"<p>Responsibilities:</p><p>Be part of a DevOps team that design, build and maintain innovative Smart Manufacturing solutions and Big Data platform.</p><p><br> Participate in Agile development lifecycle for software &amp; solution related to Smart Manufacturing and Big Data platform.</p><p> </p><p>Work with Data Science within company to develop, automate and maintain reliable data analytic and mining solutions for Smart Manufacturing and Big Data platform.</p><p><br> Ability to assess current IT environments and make recommendations to increase capacity needs.</p><p><br> Communicate, collaborate and coordinate on Smart Manufacturing and Big Data related activities to various level of stakeholders and senior management.</p>","<p>Requirements:</p><p>Bachelor’s or Master’s degree Computer Science, Electrical &amp; Electronics/Computer/Software Engineering, Information Systems or related fields.</p><p> </p><p>Fresh graduates are welcome to apply and for those with good understanding and hands-on experience in the following areas will be advantageous.</p><p> </p><p><br> Hadoop based technologies such as HDFS, MapReduce, Hive, MongoDB, HBase, Spark etc.</p><p><br> Data warehousing solutions and latest (NoSQL) database technologies.</p><p><br> Programming or scripting languages like Java, Linux, Matlab, C#/C++, Python, Perl and/or R on Linux/Windows platforms.</p><p><br> Big Data visualization and reporting software like Tableau. </p><p>ETL/BI solutions using Microsoft SSIS, Informatica or having DB programming experience (TSQL, PLSQL).</p><p> </p><p><br> Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job.</p>"
0,MCT Big Data Senior Engineer,Company Undisclosed,North,Non-executive,Engineering ...,Permanent ...,"$5,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/mct-big-data-senior-engineer-a6442261f905654e89c7c81a0633461f,"<p>Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?</p><p> </p><p>If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.</p><p> </p><p>As an MCT Data Engineer at company, you will:</p><p> </p><p>* Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&amp;D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc.</p><p>* Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data</p><p>* Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs</p><p>* Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals</p><p>* In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.</p><p> </p><p>Responsibilities and Tasks include, but not limited to:</p><p> </p><p>* Understanding business needs and strategy to develop data science solutions</p><p>* Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments</p><p>* Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem.</p><p>* Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc.</p><p>* Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics</p><p>* Creating intuitive user interface for interactive data visualization to explain insights from data</p><p>* Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions</p><p>* Documenting the train of thoughts used to design and implement solutions along with managed source code</p><p>* Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites</p>","<p>Qualifications and Experience:</p><p>* B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work </p><p>* Minimum 2 years of experience working in big data and data science projects and teams</p><p>* Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must</p><p>* Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must</p><p>* Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus</p><p>* Good grasp of statistical and scientific programming packages in Python, R, etc.</p><p>* Good grasp of data science concepts with emphasis on machine learning techniques is a plus</p><p>* Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus</p><p>* Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.)</p><p>* Strong communication skills (written, verbal and presentation)</p><p>* Willing to do international travel</p>"
0,MCT QE Engineer (Data Specialist),Company Undisclosed,North,Non-executive,Engineering ...,Permanent ...,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/mct-qe-engineer-8904f86cd01b51bb85ec6a26fa44e23b,"<p>Responsibilities<br> •As a Manufacturing Central Team Quality Engineer at company, you will be a member of the worldwide Quality Team responsible for QDRs, reducing variation and deviations for all company's Fabs.<br> •Specific to your role as Data Specialist, your work will encompass the responsibilities of an architect, a designer and a developer/administrator. You need to have an in-depth understanding of database and structure and use those skills and knowledge to maintain their stability and reliability.<br> •You will work with SMEs to identify their needs and to design and implement reporting dashboard and data structure to meet their requirements for quality improvement; your work will also extend to recommend improvements to meet the demands of swiftly changing interface technology; you will also be in charge of performing backups procedures to protect the data.</p>","<p>Requirements:<br> •A Computer Science degree or related disciplines.<br> •A solid and wide-reaching foundation in programming and database structures is required. (SQL, Perl, C++, PHP)<br> •A good knowledge of Tableau or related software that able to present data in a meaningful manner to enable SMEs to perform analysis.<br> •In addition to possessing technical know-how and being communication savvy, data specialists must also be creative problem solvers</p>"
0,Senior Data Engineer,KPLER PTE. LTD.,Central,Senior Executive,Information Technology,Full Time,"$7,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/senior-data-engineer-kpler-dedd2bb8800198d1af9afdc64ca90870,"<p><strong>Who are we ?</strong></p><p> </p><p>Kpler is an intelligence company providing transparency solutions in energy markets. We develop proprietary technologies that systematically aggregate data from hundreds of sources ranging from logistical and commercial, to governmental and shipping databases. By connecting the dots across fragmented information landscapes, we are able to provide our clients with unique, real-time market coverage.</p><p> </p><p>We rely on intelligent people to build intelligent software. Our team is composed of individuals of various backgrounds, with diversified skill sets and international experiences. Our clients are players across the energy market spectrum, with offices from Houston to Singapore.</p><p> </p><p><strong>Role Purpose</strong></p><p> </p><p>We are looking for a <strong>Senior Data Engineer</strong> to join our software engineering team in Singapore to work on our <strong>data pipelines</strong> (collect, manage, data lake storage), <strong>data algorithms</strong> (based on either business rules, constraint programming, ML, etc.) and be a <strong>technical referent</strong> in <strong>Python and/or Scala</strong>.</p><p>Our future team member will have a <strong>good understanding</strong> of <strong>data collection</strong> and <strong>management of complex B2B business rules</strong>. Also, you will take <strong>ownership of large features</strong> from technical design through completion.</p><p>At Kpler, the Senior Data Engineer is at the centre of our research delivery and will have a key role in <strong>defining architecture, helping identify and implement areas for improvement</strong> within our data methodologies and technologies used.</p><p>Based in Singapore, you will also interact with the Paris engineering team; being able to communicate efficiently in <strong>English</strong> (<strong>mandatory</strong>, we have more than 15 nationalities at Kpler!) and <strong>work with remote team members</strong> is key.</p><p> </p><p><strong>Also, you will:</strong></p><ul>  <li><strong>Coach</strong> and work on <strong>code review</strong> with more junior engineers</li>  <li>Ensure integrity of data through creative, robust and sustainable <strong>quality control methods</strong></li>  <li>Participate in <strong>operations/support</strong> of the real-time platforms</li>  <li>Participate in <strong>defining coding standards, specifications and development processes</strong></li>  <li>Translating technical concepts to/from non-technical language</li> </ul>","<p><strong>Knowledge &amp; Experience</strong><br>  </p><p><strong>Must Have</strong></p><p> </p><ul> 	<li>At least <strong>5 years of experience</strong> in similar roles working <strong>Python and/or Scala</strong> and cloud infrastructure (<strong>Amazon AWS</strong>) on linux servers</li> 	<li>Experience with <strong>SQL</strong> (PostgreSQL or equivalent)</li> 	<li>Proficiency developing <strong>automated unit</strong> and <strong>integration tests</strong> and <strong>continuous integration</strong></li> 	<li> 	<p>Ability to <strong>learn quickly</strong> and <strong>deliver high quality code</strong> in a fast-paced, dynamic team environment</p> 	</li> </ul><p> </p><p><strong>Nice to have</strong></p><p> </p><ul> 	<li>Knowledge of <strong>SqlAlchemy, Scala Play2, ElasticSearch, Heroku</strong></li> 	<li>Experience of <strong>data management lifecycles</strong> (collection, cataloguing, ETL design)</li> 	<li>Experience with <strong>geographic information systems</strong> (PostGIS for instance)</li> 	<li>Experience of <strong>LEAN methodologies and approaches to process optimisation</strong></li> </ul>"
0,Global Technology Infrastructure Data Center Operations Engineer I - Analyst,"JPMORGAN CHASE BANK, N.A.","East, Central",Professional,Information Technology,Permanent ...,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/global-technology-infrastructure-data-center-operations-engineer-analyst-jpmorgan-chase-bank-na-bed3f247755e2133360f5f735799f692,"<p>As a Data Center Operations Engineer I, your mission is to support the day-to-day technology operations of JPMorgan Chase mission critical data centers. The purpose of this role is to maintain operational stability and handle customer requests while working on shifts and on calls to support the 24x7 operation. You will be responsible for installing and configuring enterprise class technology hardware, troubleshooting hardware and network issues, maintain change control process in the data center, and support 3rd party vendor activities. This position is full-time, working with team members on a rotating basis.</p><p> </p>","<p>This role requires a wide variety of strengths and capabilities, including:</p><p> </p><ul> 	<li>Understanding of information technology concepts in a working or academic environment</li> 	<li>General knowledge of a physical IT infrastructure (server, networking, storage)</li> 	<li>Some understanding of network concepts (switching, routing, perimeter security)</li> 	<li>Some understanding of operating systems (Windows, Linux, AIX)</li> 	<li>A mindset that challenges rather than simply understands and accepts</li> 	<li>Passionate about technology, innovation and continuous learning</li> 	<li>Ability to integrate well into a team, connect and collaborate effectively with the wider organization</li> 	<li>Being obsessed about our customers’ experience</li> 	<li>Flexibility to work non-business hours that may include weekends and/or holidays</li> 	<li>Ability to support frequent standing, walking, pushing, pulling, bending, reaching, and lifting up to 50lbs</li> 	<li>Willingness for occasional travel between sites</li> </ul><p> </p><p> </p><p> </p><p> </p><p>Our Global Technology Infrastructure group is a team of innovators rewarded with innovators who love technology as much as you do. Together, you will use a disciplined, innovative and a business focused approach to develop a wide variety of high-quality products and solutions. You will work in a stable, resilient and secure operating environment where you—and the products you deliver—will thrive.</p><p> </p><p>When you work at JPMorgan Chase &amp; Co., you are not just working at a global financial institution. You are an integral part of one of the world’s biggest tech companies. In 14 technology hubs worldwide, our team of 40,000+ technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $9.5B+ annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry, but also change the world. </p><p> </p><p>At JPMorgan Chase &amp; Co. we value the unique skills of every employee, and we’re building a technology organization that thrives on diversity.  We encourage professional growth and career development, and offer competitive benefits and compensation.  If you are looking to build your career as part of a global technology team, tackling big challenges that impact the lives of people and companies all around the world, we want to meet you.</p><p> </p><p> </p><p> </p>"
0,Data Quality Engineer,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,Central,Executive,Information Technology,Contract,"$9,000","$12,000",Monthly,https://www.mycareersfuture.sg/job/data-quality-engineer-allegis-group-singapore-0314d2030cb171e97a3b626d602a8f4b,"<p>This is a new initiative of the bank within a pioneer team to bring data quality into operations. The primary work comprises of ETL tool programming, data quality implementation, data governance and change &amp; release management.</p><p> </p>","<p>Data quality implementation experience 2) Preferably with Infomatica Data Quality tool OR other DQ tools like Trilium, IBM QualityStage or Microsoft data quality services(DQS) 3) Change and release management experience Experience with data warehousing and data mart development will be a good to have.</p><p>Skills &amp; Competencies: (free text)</p><p>Technical skills refer to job-specific knowledge,</p><p>skills and abilities (e.g. programming, 3D</p><p>modelling, marketing, etc),</p><p>Generic skills refer to skills that can be</p><p>transferred from one job to another (e.g.</p><p>communication, problem-solving). 1) Data quality implementation experience; 2) Preferably with Infomatica Data Quality tooling experience OR other DQ tools like Trilium, IBM QualityStage or Microsoft data quality services(DQS) 3) Strong change and release management experience Experience with data warehousing and data mart development will be a good to have.</p>"
0,Data Quality Engineer,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,Central,Executive,Information Technology,Contract,"$5,000","$9,000",Monthly,https://www.mycareersfuture.sg/job/data-quality-engineer-allegis-group-singapore-da13bc3e09061498bdcc9263e243ea86,"<p>This is a new initiative of the bank within a pioneer team to bring data quality into operations. The primary work comprises of ETL tool programming, data quality implementation, data governance and change &amp; release management.</p><p> </p>","<p>Data quality implementation experience 2) Preferably with Infomatica Data Quality tool OR other DQ tools like Trilium, IBM QualityStage or Microsoft data quality services(DQS) 3) Change and release management experience Experience with data warehousing and data mart development will be a good to have.</p><p>Skills &amp; Competencies: (free text)</p><p>Technical skills refer to job-specific knowledge,</p><p>skills and abilities (e.g. programming, 3D</p><p>modelling, marketing, etc),</p><p>Generic skills refer to skills that can be</p><p>transferred from one job to another (e.g.</p><p>communication, problem-solving). 1) Data quality implementation experience; 2) Preferably with Infomatica Data Quality tooling experience OR other DQ tools like Trilium, IBM QualityStage or Microsoft data quality services(DQS) 3) Strong change and release management experience Experience with data warehousing and data mart development will be a good to have.</p>"
0,"Senior Associate, DevOps Engineer, Group Consumer Banking and Big Data Analytics Tech (180004DY)",DBS BANK LTD.,East,Senior Executive,Banking and Finance,Permanent ...,"$5,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/senior-associate-devops-engineer-group-consumer-banking-big-data-analytics-tech-dbs-bank-4a3a66a54557b6de2aa9a5978bb99f4e,"<p><strong>Job Purpose </strong><br> The role forms part of the Insurance and Investment Platform technology team. Develop and deliver technology solutions relating to web and mobile applications across wealth customer segments.<br> <br> <br> <strong>Key Accountabilities</strong></p><ul> 	<li>Engineer CI/CT/CD pipeline that is optimized to run within minutes</li> 	<li>Enforce best practices in code quality and release/deployment process to achieve near zero production incidents</li> </ul><p><br> <br> <strong>Responsibilities</strong></p><ul> 	<li>Architect, build and maintain continuous integration, testing and deployment (CI/CT/CD) pipeline for web and mobile apps</li> 	<li>Collaborate with architects, development engineers and system administrators to provision and maintain the platform infrastructure both on premise as well as cloud (for development, test and production environments)</li> 	<li>Build and maintain system and application health check and house-keeping jobs</li> 	<li>Troubleshoot system and connectivity errors and follow up with administrators, vendors or other teams for timely resolution</li> 	<li>Develop, maintain and document best practices in source control management and infrastructure as code </li> 	<li>Track, maintain and renew infrastructure, web and mobile application key-stores and profiles</li> 	<li>Track, enforce and maintain code quality, security and performance reports</li> 	<li>Identify improvement areas and engage the required stakeholders to successful implement the changes</li> 	<li>Keep track of evolving technologies and perform proof of concept integrations for successful platform integrations as per roadmap</li> 	<li>Maintain platform collaboration tools such as JIRA and Confluence</li> </ul>","<ul> 	<li>Experience and exposure to other DevOps related infrastructure software (such as ZABBIX, Puppet, Graphite, ELK stack, Kickstart, tcp wrappers, iptables, yum/apt-get) for classic sys admin functions (building hosts, monitoring, alerting, account management, releasing software, and security.</li> 	<li>Oracle, or MySQL 5.X, IBM DB2 (Any), SqLite (for Mobile devices), mariadb</li> 	<li>Build Tool: Ant, Maven, Gradle (Any)</li> 	<li>Version Control: CVS, SVN, GIT</li> 	<li>WebSphere Administration</li> 	<li>WebSphere MQ administration.</li> 	<li>DevOps – Jenkins/Bamboo, SonarCube, HP Fortify.</li> 	<li>Atlasian tools: Bitbuket, JIRA, Confluence, Bamboo and SharePoint</li> 	<li>Mobile application tools – Kony IDE, XCode, Android Studio, Ant, Maven, Gradle </li> 	<li>AIX/Unix Administration</li> 	<li>Tomcat/IBM HTTP Server administration</li> </ul>"
0,Data Engineer,GOVERNMENT TECHNOLOGY AGENCY,,,Information Technology ...,Permanent,,,,https://www.mycareersfuture.sg/job/data-engineer-government-technology-agency-8580bddf71991ce3f59d7459c8c0451f,"<p>The Government Digital Services team is seeking an accomplished Data Engineer. We are a team in GovTech that aims to design and develop software applications that help government agencies to better serve the needs of Singaporeans. We adopt an Agile development approach and work towards adopting tech best practices and cutting edge tools.</p><p>We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.</p><p>The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.</p><p><strong>What To Expect:<br></strong></p><ul>
<li>Create and maintain optimal data pipeline architecture.</li>
<li>Assemble large, complex data sets that meet functional / non-functional business requirements.</li>
<li>Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.</li>
<li>Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies.</li>
<li>Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.</li>
<li>Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.</li>
<li>Keep our data separated and secure through multiple data centers.</li>
<li>Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.</li>
<li>Work with data and analytics experts to strive for greater functionality in our data systems.</li>
</ul><p><strong>How To Succeed:</strong></p><ul>
<li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li>
<li>Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.</li>
<li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.</li>
<li>Strong analytic skills related to working with unstructured datasets.</li>
<li>Build processes supporting data transformation, data structures, metadata, dependency and workload management.</li>
<li>A successful history of manipulating, processing and extracting value from large disconnected datasets.</li>
<li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.</li>
<li>Experience supporting and working with cross-functional teams in a dynamic environment.</li>
<li>We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Preferably with the experience of using the following software/tools:
<ul>
<li>Experience with big data tools: Hadoop, Spark, Kafka, RabbitMQ etc.</li>
<li>Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.</li>
<li>Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.</li>
<li>Experience with AWS cloud services: EC2, EMR, RDS, Redshift</li>
<li>Experience with stream-processing systems: Storm, Spark-Streaming, etc.</li>
<li>Experience with either of these languages: Python, Java.</li>
</ul>
</li>
</ul>",
0,"AVP  /  Senior Associate, Data Engineer, IBG Digital, Institutional Banking Group (1800044U)",DBS BANK LTD.,East,Manager ...,Banking and Finance,Permanent ...,"$5,500","$11,000",Monthly,https://www.mycareersfuture.sg/job/avp-senior-associate-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-54bb338074df251516356bf7fb7992ca,"<p><strong>Job Purpose </strong></p><p>The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.</p><p><strong>Responsibilities</strong></p><ul>   <li>Create and maintain optimal data pipeline architecture;</li>   <li>Assemble large, complex data sets that meet functional / non-functional business requirements;</li>   <li>Identify, design, and implement internal process improvements: automating manual processes,</li>   <li>Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC);</li>   <li>Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs;</li>   <li>Build processes supporting data transformation, data structures, dependency and workload management</li>  </ul>","<ul>   <li>Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment</li>   <li>Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc)</li>   <li>Strong in transactional SQL, Enterprise Data Warehouse</li>   <li>Experience with Graph Database, NoSQL databases</li>   <li>Experience with Feature Engineering</li>   <li>Experience with Master Data Management</li>   <li>Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc</li>  </ul>"
0,Data Engineer,MOKA TECHNOLOGY SOLUTIONS PTE. LTD.,North,Professional,Engineering,Permanent ...,"$5,000","$7,500",Monthly,https://www.mycareersfuture.sg/job/data-engineer-moka-technology-solutions-9a2882ca74c6e52d5a8f33fbc7a5a572,"<p>Do you have a passion for data? Are you looking to push the frontiers of innovation and build the Next Big Data Product?</p><p>We are looking for excellent Data Engineers who are keen to help us manage the end-to-end data pipeline and drive big data solutions. </p><p><strong>You will:</strong></p><ul> 	<li>Design, implement and manage end to end data pipelines (ETL, data streaming and warehousing) so as to make data easily accessible for analysis.</li> 	<li>Integrate with third party APIs for accessing external data.</li> 	<li>Create and maintain data warehouses for reporting or analysis.</li> 	<li>Consult and partner with engineering and product teams to execute data-related product initiatives.</li> 	<li>Ability to quickly resolve performance and systems incidents.</li> 	<li>Evaluate the latest monitoring and automation tools.</li> </ul>","<p><strong>You have:</strong></p><ul> 	<li>BS (MS preferred) in Computer Science or Computer Engineering.</li> 	<li>Excellent software engineering skills and proven track record (4+ years experience) in building automated, scalable and robust data processing systems.</li> 	<li>Proficiency in SQL, bash scripts and Python (or similar languages).</li> 	<li>Intermediate understanding of database technologies.</li> 	<li>Experience with data warehouse systems (e.g. Redshift) and batch/semi-online building blocks (e.g. MapReduce, Spark etc).</li> 	<li>Demonstrated expertise in working with large scale quantitative data.</li> 	<li>Excellent attention to detail and team player.</li> </ul>"
0,Data Engineer (Python developer),NTT DATA SINGAPORE PTE. LTD.,East,Executive ...,Information Technology,Contract,"$5,000","$7,500",Monthly,https://www.mycareersfuture.sg/job/data-engineer-ntt-data-singapore-f652dac9e4485a097f8ae664ee69eb15,"<ul>   <li>Own, develop and enhance the prototype cost allocation model for Singapore    <ul>     <li>Taking over the existing model and making further modifications / enhancements as required</li>    </ul> </li>   <li>Customise the prototype as required for rolling out the new cost allocation design to other countries    <ul>     <li>Implementing modifications / enhancements to the prototype as required for each country</li>    </ul> </li>  </ul>","<p>We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Information Systems.</p><p>The candidate should also have experience using the following software/tools:</p><ul>   <li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.</li>   <li>Experience building and optimizing 'big data' pipelines, data architectures and data sets.</li>   <li>Experience with big data tools: Hadoop, Spark.</li>   <li>Experience with object-oriented function scripting languages: Python, C++</li>   <li>Experience with statistical computer languages (Python, SQL, R) to manipulate data and draw insights from large data sets.</li>   <li>Experience with common data science toolkits, such as NumPy, Pandas. R, etc.</li>   <li>Knowledge of machine learning techniques and algorithms, such as K-NN, Naive Bayes, SVM, Decision Forests, etc.</li>   <li>Experience with data visualisation tools, such as D3.js, GGplot, QlikView, etc.</li>  </ul>"
0,Mobile Network & Data Support Engineer,CHANDLER MACLEOD GROUP PTE. LTD.,Central,Senior Executive,Information Technology,Contract,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/mobile-network-data-support-engineer-chandler-macleod-group-4aa227ac50f5f52ac797165b5726a72b,"<p>A well-established global brand is looking for a high calibre Mobile Network and Data Support Engineer in Singapore. This role is responsible providing technical support to improve customer’s experience with front-line support team. Ideally you should have experience helping users to troubleshoot network connectivity issues, experience with NOC and highly knowledgeable with IP networking.  </p><p><strong>Responsibilities:</strong></p><ul> 	<li>Deliver technical support inline with a set of departmental service levels through a scaled ticketing systems</li> 	<li>Perform product integrations with mobile operators remotely, involving traffic zero rating</li> 	<li>Work with the mobile infrastructure engineering team, finding or escalating issues (TCP/IP, VPN, SMPP, SS7)</li> 	<li>Analysing protocol logs, add new IP address and network traces</li> 	<li>Troubleshooting networking and service issues on Linux based operating systems</li> 	<li>Liaise with carrier / operator partners on technical issues around connectivity</li> </ul>","<p><strong>Requirements:</strong></p><ul> 	<li>Bachelor degree in Telecommunications or related technical field  </li> 	<li>2+ to 5 years’ relevant experience in network engineering or telecommunications support environment</li> 	<li>Experience working in NOC environment</li> 	<li>Vast experience in IP networking, mobile networking, traffic analysis and troubleshooting   </li> 	<li>Ability to communicate effectively with a demonstrated ability to build valuable relationships</li> </ul><p>If this sounds like your next challenge get in touch -for a confidential discussion, please contact Naveen.Vasudevan@chandlermacleod.com</p><p>Interested parties please click <strong>""Apply Now""</strong> or contact <strong>Naveen Vasudevan</strong> (EA Reg. No. R1330844) on +65 6429 3218 for more information.</p><p>Chandler Macleod Group Pte Ltd, EA Licence: 11C3837</p>"
0,DATA CENTER ENGINEER,Company Undisclosed,West,Senior Executive,Engineering,Permanent,,,,https://www.mycareersfuture.sg/job/data-center-engineer-1c61c2fecf9b58213b4cdb9d273848ff,"<p>As a Data Center Engineer in the Technical Operations group, the ideal candidate will have the knowledge and experience to work in a fast-paced Data Center environment. They will be responsible for the day-to-day operations and projects to ensure the continued success.</p><ul>   <li> <p>Conduct all day-to-day operations for the Data Center</p> </li>   <li> <p>Install all racks and enclosures for equipment</p> </li>   <li> <p>Prepare all equipment to be installed in racks and other enclosures</p> </li>   <li> <p>Update cable the management system as changes are made to the data center cable plant</p> </li>   <li> <p>Update asset management system as equipment is added and removed from the Datacenter</p> </li>   <li> <p>Define tasks for each project and work with all TechOps teams to meet project timelines</p> </li>   <li> <p>Provide status to team members and management on the completion of all tasks</p> </li>   <li> <p>Provide all information to assist with Data Center capacity planning for space and power</p> </li>   <li> <p>Manage all vendor resources to complete tasks as defined in SOWs</p> </li>   <li> <p>Research new Data Center infrastructure equipment advancements and recommend changes as needed</p> </li>   <li> <p>Conduct all audits as required by company policies</p> </li>   <li> <p>Coordinate with the warehouse the delivery and shipping of all equipment</p> </li>  </ul><p> </p>","<p><strong>Basic Requirements:</strong></p><p> </p><ul> 	<li> 	<p>3+ years in Data Centers managing hardware assets</p> 	</li> 	<li> 	<p>Familiar with Linux</p> 	</li> 	<li> 	<p>Demonstrable project management experience with the ability to manage tasks under tight deadlines</p> 	</li> 	<li> 	<p>Extensive experience as a data center engineer working within large heterogeneous environments</p> 	</li> 	<li> 	<p>Extensive experience with rack and stack of server and network equipment installations</p> 	</li> 	<li> 	<p>Solid day-to-day experience working data centers and co-location environments</p> 	</li> 	<li> 	<p>Experienced working fast paced engineering data center environments</p> 	</li> 	<li> 	<p>Solid experience managing teams of onsite infrastructure build-out engineers and vendors</p> 	</li> 	<li> 	<p>Experience with a large variety of different vendor hardware such as servers, storage, and network equipment.</p> 	</li> 	<li> 	<p>Familiar with the processes of pulling, terminating and testing copper and fiber network cabling</p> 	</li> 	<li> 	<p>Experience in contributing to detailed project plans for programs involving cross-functional teams and challenging requirements</p> 	</li> 	<li> 	<p>Ability to multitask and manage multiple projects</p> 	</li> 	<li> 	<p>Demonstrated ability to coordinate issue resolution across departmental teams</p> 	</li> 	<li> 	<p>Coordinating vendors, scheduling RMA's and on-site repairs as needed</p> 	</li> 	<li> 	<p>Experience with Asset Management Systems</p> 	</li> 	<li> 	<p>Experience in managing inventory of all cable, power cords and other infrastructure items.</p> 	</li> 	<li> 	<p>Solid understanding of disaster recovery and business continuance methodology</p> 	</li> 	<li> 	<p>Strong sense of methodology, process, and metrics</p> 	</li> </ul><p> </p><p><strong>Preferred Requirements:</strong></p><ul> 	<li> 	<p>Bachelor's degree or equivalent work experience preferred</p> 	</li> 	<li> 	<p>Proven track record of success and delivering results</p> 	</li> 	<li> 	<p>Strong interpersonal and relationship building skills conducive to team development</p> 	</li> 	<li> 	<p>Excellent communication skills, both verbal and written</p> 	</li> 	<li> 	<p>Physical work Ability to lift at least 50-70 lbs on a regular basis</p> 	</li> </ul>"
0,"VP / AVP, Senior Data Engineer, Group Consumer Banking and Big Data Analytics Technology (180003L2)",DBS BANK LTD.,East,Middle Management ...,Banking and Finance,Permanent ...,"$7,000","$14,000",Monthly,https://www.mycareersfuture.sg/job/vp-avp-senior-data-engineer-group-consumer-banking-big-data-analytics-technology-dbs-bank-41369aada853ab1d604a4bd218031943,"<ul> 	<li>Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud. </li> 	<li>Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics. </li> 	<li>Analyze source data and data flows, working with structured and unstructured data.</li> 	<li>Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends</li> 	<li>Analyze and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely.</li> 	<li>Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms.</li> 	<li>Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products.</li> 	<li>Build and optimize classifiers using machine learning techniques and enhance data collection procedures that is relevant for building analytic systems.</li> 	<li>Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL.</li> 	<li>Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat.</li> 	<li>Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders.</li> </ul>","<ul>   <li>Experience in big data and machine learning</li>   <li>The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles.</li>   <li>Development experience in Java/Scala and pride in producing clean, maintainable code</li>   <li>Practical experience in clustering high dimensionality data using a variety of approaches</li>   <li>Real world experience in solving business problems by deploying one or more machine learning techniques</li>   <li>Experience creating pipelines to analyze data, extracted features and updated models in production.</li>   <li>Independence and self-reliance while being a pro-active team player with excellent communication skills.</li>   <li>Hands-on development with key technologies including Scala, Spark, and other relevant distributed computing languages, frameworks, and libraries. </li>   <li>Experience with distributed databases, such as Cassandra, and the key issues affecting their performance and reliability. </li>   <li>Experience using high-throughput, distributed message queueing systems such as Kafka.</li>   <li>Familiarity with operational technologies, including Docker (required), Chef, Puppet, ZooKeeper, Terraform, and Ansible (preferred). </li>   <li>An ability to periodically deploy systems to on-prem environments. </li>   <li>Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools. </li>   <li>Experience with Teradata SQL, Exadata SQL, T-SQL</li>   <li>Strong experience in graph and stream processing</li>   <li>Experience in migrating SQL from traditional RDBMS to Spark and BigData technologies</li>   <li>Experience in building language parsers using ANTLR, query optimizers and automatic code generation</li>   <li>In-depth knowledge of database internals and Spark SQL Catalyst engine</li>  </ul>"
0,Senior Database Consultant - Big Data Engineer,PALO IT SINGAPORE PTE. LTD.,Central,Professional,Information Technology,Permanent ...,"$6,000","$12,000",Monthly,https://www.mycareersfuture.sg/job/senior-database-consultant-big-data-engineer-palo-singapore-0967c08bb2ea80dd96344490bdbe3da3,"<p>Your profile &amp; role on the project<br> YOU:</p><ul>   <li>Thrive on challenge. When was the last time you failed?</li>   <li>Are curious &amp; always learning. What are you up to right now?</li>   <li>Can deal with constant change. When were you last surprised?</li>   <li>Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?</li>  </ul><p>YOU AGAIN:<br> The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure<br> and apply DevOps practices and solutions. The person will also implement cloud-related and<br> DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond<br> to consultant requests when required will be expected.</p><ul>   <li>Install, maintain, and support on-premises and off-premises cloud stack.</li>   <li>Configure, maintain, and support the cloud-related infrastructures.</li>   <li>Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud.</li>   <li>Ability to develop solutions and self-learn new tools and technologies.</li>   <li>Document, and share knowledge on developed DevOps solutions.</li>  </ul><p>STILL YOU:</p><ul>   <li>Unix / Linux / Bash knowledge</li>   <li>Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.)</li>   <li>Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.)</li>   <li>2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.)</li>   <li>1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner)</li>   <li>1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.)</li>   <li>1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.)</li>   <li>1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk)</li>   <li>Experience with developing and implementing processes to handle releases from</li>   <li>Development to Operations while respecting internal rules, and offering solutions for rollback)</li>   <li>Experience with designing an architecture to implement development-to-production workflows.</li>   <li>Knowledge of SRE, Containers, Kubernetes, Openshift is a plus.</li>   <li>Good understanding of microservice architecture and DevOps practices that support.</li>   <li>Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.</li>  </ul><p>Your role at PALO IT<br> You will be invited to take part in R&amp;D works done within our Practices. You will have the<br> chance to assist or be a speaker at must-attend international IT conferences. You will have the<br> opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT,<br> you will present our offers and take an active role in the development of the company.<br> <br> Your technical environment<br> # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud)<br> # DevOps practices<br> # Linux OS, Shell Scripting, SQL<br> # Agile and scrum environment</p>","<p>✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science</p><p>✔     You are just graduated or have less than 3 years of working experience</p><p>✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing</p><p>✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR)</p><p>✔     Experience with batch &amp; ETL jobs to ingest and process data from multiple data sources</p><p>✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch)</p><p>✔     Experience with querying tools (e.g Hive, Spark SQL, Impala)</p><p>✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming</p><p>✔     You are passionate about technology and continuous learning comes naturally to you</p><p> </p>"
0,"VP / AVP, Machine Learning Engineer, Group Consumer Banking and Big Data Analytics Tech (180003YE)",DBS BANK LTD.,East,Middle Management ...,Banking and Finance,Permanent ...,"$7,000","$14,000",Monthly,https://www.mycareersfuture.sg/job/vp-avp-machine-learning-engineer-group-consumer-banking-big-data-analytics-tech-dbs-bank-b3fa00eab03bc7ee01a600fd70041e2d,"<p><strong>Job Purpose </strong><br>  </p><p>Build and improve machine learning and analytics platform. Work with data scientists to create, optimize and productionize of machine learning models for various business units within the organization. Keep innovating and optimizing data and machine learning workflow to enable data-driven business activities at large scale. <br> <br> <br> <strong>Responsibilities </strong></p><ul>   <li>Build and improve machine learning and analytics platform.<br>      <ul>     <li>Apply cutting edge technologies and tool chain in big data and machine learning to build machine learning and analytics platform.</li>     <li>Keep innovating and optimizing the machine learning workflow, from data exploration, model experimentation/prototyping to production.</li>     <li>Provide engineering solution and framework to support machine learning and data-driven business activities at large scale.</li>     <li>Perform R&amp;D on new technologies and solutions to improve accessibility, scalability, efficiency and us abilities of machine learning and analytics platform.<br>  </li>    </ul> </li>   <li>Work with data scientists to build end-to-end machine learning and analytics solution to solve business challenges.<br>      <ul>     <li>Turn advanced machine learning models created by data scientists into end-to-end production grade system.</li>     <li>Build analytics platform components to support data collection, exploratory, and integration from various sources being data API, RDBMS, or big data platform.</li>     <li>Optimize efficiency of machine learning algorithm by applying state-of-the-art technologies, i.e. distributed computing, concurrent programming, or GPU parallel computing. <br>  </li>    </ul> </li>   <li>Establish, apply and maintain best practices and principles of machine learning engineering.<br>      <ul>     <li>Study and evaluate the state of the art technologies, tools, and frameworks of machine learning engineering.</li>     <li>Contribute in creation of blueprint and reference architecture for various machine learning use cases.</li>     <li>Support the organization in transformation towards a data driven business culture.</li>    </ul> </li>  </ul><p><br> <strong>Work Relationships</strong></p><ul>   <li>Internal <br>      <ul>     <li>Work closely with data scientists, business team, and project managers to provide machine learning and data-driven business solution. </li>     <li>Collaborate with other technology teams to build platform and framework to enable machine learning and data analytics activities at large scale<br>  </li>    </ul> </li>   <li>External <br>      <ul>     <li>Maintain engineering principles and best practices of machine learning framework and technologies.</li>    </ul> </li>  </ul>","<ul>   <li>PhD/Masters/Bachelors in Computer Science, Computer Engineering, Statistics, Applied Mathematics, or related disciplines. </li>   <li>Excellent understanding of software engineering principles and design patterns.</li>   <li>Excellent programming skills in either Python, Scala, or Java.</li>   <li>In-depth understanding of data science and machine learning technologies and methodologies.</li>   <li>Good working knowledge of high performance computing, parallel data processing, and big data stack, e.g. Spark and Hadoop/Yarn.</li>   <li>Experience to one or more commercial / open source data warehouses or data analytics systems, e.g. Teradata, is a big plus.</li>   <li>Experience to one or more NoSQL databases is a big plus.</li>   <li>Hands-on experience in Cloud platforms, e.g. AWS, or containerization/ virtualization platforms, e.g. Docker/Kubernetes, is a big plus.</li>   <li>Experience to any data science or machine learning platform, e.g. IBM Data Science Experience or Cloudera Data Science Workbench, is a big plus.</li>   <li>Exposure to mainframe system is a plus.</li>   <li>Passion about machine learning and data-driven intelligence system.</li>   <li>Excellent communication and presentation skills in English.</li>   <li>Team player, self-starter, ability to work on multiple projects in parallel is necessary.</li>   <li>2+ years of experience in machine learning system or data science research</li>   <li>5+ years of experience in software engineering or DevOps automation or data engineering</li>   <li>Experience working in multi-cultural environments</li>  </ul>"
0,Data Centre Facilities Management Engineer,ENGIE ITS  PTE. LTD.,East,Junior Executive,Engineering,Permanent,"$2,300","$4,000",Monthly,https://www.mycareersfuture.sg/job/data-centre-facilities-management-engineer-engie-2f3848b3d78deee74eb96b79156e9b45,"<p><strong>Responsibilities:</strong></p><p>Manage data centre operations and facilities Plan and implement predictive and preventive programmes Manage sub-contractors to carry out maintenance works Project manage facility development Provide engineering/technical expertise and value engineering to customers Respond to service call and ensure resolution of the problems Prepare weekly reports, incident reports and O&amp;M procedures Ensure critical system availability to meet SLA.</p>","<p><strong>Requirements:</strong></p><ul>   <li>Diploma / ITC Cert in Information Technology, Building Services, Electrical or Mechanical Engineering</li>   <li>At least 1 years experience with Facility Management or M&amp;E facilities maintenance, preferably in data centre environment</li>   <li>Service-oriented with strong analytical and problem-solving skills</li>   <li>Resourceful, dynamic, highly motivated and able to work independently</li>   <li>Good interpersonal skills with ability to interact with people at different levels</li>   <li>Willing to work overtime including weekends and public holidays when necessary</li>  </ul><p><strong>Personal Attributes</strong></p><ul>   <li>Meticulous and have an eye for details with positive working attitude</li>   <li>Organized and details-oriented, with a strong focus on accuracy</li>   <li>Able to work under pressure and tight deadline</li>  </ul><p><strong>Other Information:</strong></p><ul>   <li>Job Type: Full Time, Permanent</li>   <li>Work week: 5 days</li>   <li>Work location : Various location</li>  </ul>"
0,Big Data Engineer,Company Undisclosed,Central,Professional,Information Technology,Contract,"$6,500","$9,000",Monthly,https://www.mycareersfuture.sg/job/big-data-engineer-4cdf4a619b8c129fd5fa853a8f405a61,"<p>• Evaluate and renew implemented big data architecture solutions to ensure their relevance and effectiveness in supporting business needs and growth.</p><p>• Design, develop and maintain data pipelines, with a focus on writing scalable, clean, and fault-tolerant code to handle disparate data sources, process large volume of structured / unstructured data from various sources.</p><p>• Understand business requirements and solution designs to develop and implement solutions that adhere to big data architectural guidelines and address business requirements</p><p>• Support and maintain previously implemented big data projects, as well as provide guidance and consultation on other projects in active development as needed</p><p>• Drive optimization, testing and tooling to improve data quality</p><p>• Document and communicate technical complexities completely and clearly to team members and other key stakeholders</p>","<p>Required to work European time zone (4pm-1am)</p><p>• Degree qualified in Business management, IT, Computer Systems, software or computer engineering fields or equivalent.</p><p>• Minimum 6 years of experience in data warehousing / big data environments.</p><p>• Experience with big data processing </p><p>• Experience in designing and developing data models, integrating data from multiple sources, building ETL pipelines, and other data wrangling tools in big data environments</p><p>• Understanding of structured and unstructured data design/modeling</p><p>• Experience using software engineering best practices in programming, testing, version control, agile development, etc.</p><p> </p><p> </p><p><strong>Technical competency:</strong></p><p>• Hadoop / Big Data knowledge and experience</p><p>• Design &amp; Development based on Hadoop platform and it’s components</p><p>• Big Data Platform based on Cloudera on Hadoop</p><p>• Python / Spark / Scala / Java</p><p>• HIVE / HBase / Impala / Parquet</p><p>• Sqoop, Kafka, Flume</p><p>• SQL</p><p>• Relational Database Management System (RDBMS)</p><p>• NOSQL database</p><p>• Data warehouse platforms or equivalent</p><p> </p><p><strong>Essential skill set:</strong></p><p>• Highly organized, self-motivated, pro-active, and able to plan.</p><p>• Ability to analyze and understand complex problems.</p><p>• Ability to explain technical information in business terms.</p><p>• Ability to communicate clearly and effectively, both verbally and in writing.</p><p>• Strong in User Requirements Gathering, Maintenance and Support.</p><p>• Agile experience in a Scrum setting</p><p>• Data Architecture, Data Modeling of BI Applications / Data Warehouse / Big Data</p>"
0,Data Engineer,INTELLECT MINDS PTE. LTD.,Central,Executive,Information Technology,Full Time,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-intellect-minds-5aefdcde0bb0f359967a5fdc27f414dd,"<p><strong>Company Overview</strong></p><p>Intellect Minds is a Singapore-based company since 2008, specializing in talent acquisition, application development, and training. We serve BIG MNCs and well-known clients in talent acquisition, application development, and training needs for Singapore, Malaysia, Brunei, Vietnam and Thailand.</p><p>Our client is an establish company a, leader within their industry, is now looking for a <strong>Data Engineer</strong> to join their esteemed organization.</p><p><strong>Job Descriptions:</strong></p><p><em>Responsibilities</em></p><p>• Create and maintain optimal data pipeline architecture.<br> • Assemble large, complex data sets that meet functional / non-functional business requirements.<br> • Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Cassandra, Hadoop and other Big Data Technologies.<br> • Build data pipeline on premise and on Google Cloud Platform.<br> • Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.<br> • Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.<br> • Work with data and analytics experts to strive for greater functionality in our data systems.</p>","<p><em>Qualifications</em></p><p>• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.<br> • Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.<br> • Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.<br> • Strong analytic skills related to working with unstructured datasets.<br> • Build processes supporting data transformation, data structures, metadata, dependency and workload management.<br> • A successful history of manipulating, processing and extracting value from large disconnected datasets.<br> • Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.<br> • Experience supporting and working with cross-functional teams in a dynamic environment.<br> • We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:<br> • Experience with big data tools: Hadoop, Spark, Kafka, etc.<br> • Experience with Google Cloud Platform esp. Google Pub-Sub, Big Query, Data Proc, Data Flow, Cloud Storage.<br> • Experience with IoT &amp; Time series data.<br> • Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.<br> • Experience with stream-processing systems: Storm, Spark-Streaming, etc.<br> • Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.</p><p><strong>All successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits.</strong></p><p><strong>Interested Candidates please submit your detailed resume online.</strong></p><p><strong>To your success!</strong></p><p><strong>The Recruitment Team</strong></p><p><strong>Intellect Minds Pte Ltd (Singapore)</strong></p>"
0,Data Engineer,AIA SINGAPORE PRIVATE LIMITED,Central,Executive,Information Technology,Full Time,"$3,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-aia-singapore-3e1790961b746514efe3771041fa1aba,"<ul>  <li>You will be designing, developing and testing ETL Mappings, Mapplets, Workflows and Worklets</li>  <li>You will be developing data pipelines to extract, transform and aggregate data that can scale to petabytes, elastically, with low latency and high availability.</li> </ul>","<ul> 	<li>A background in Computer Science, Engineering, Mathematics or Statistics.</li> 	<li>1 to 2 years of experience building complex data pipelines for data integration from enterprise wide applications/systems into centralised big data lakes/warehouses</li> 	<li>Open to fresh graduates who possess strong programming skill in java / python, SQL and Shell scripting</li> </ul>"
0,Data Platform Engineer,SILOT PTE. LTD.,West,Professional,Sciences / Laboratory / R&D,Full Time,"$4,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-platform-engineer-silot-11009083bc1a531502b38288c19fbe5a,"<p>Role</p><p> </p><p>As data engineer at Silot, you design and implement distributed backend services that processes data in real-time, with focus on scalability, data quality and integration of machine learning.</p><p> </p><p>You feel natural at extracting information out of heterogeneous data from many sources. You can plan, build and maintain distributed, service-oriented and event-driven data platform for real-time processing. You like delivering accurate data components that people rely on. You optimize architecture and processes for performance and stability.</p><p> </p><p>To visualize what this position is like, think ""building systems,"" not ""processing data"" (even though your day will involve aspects of both).</p>","<p>Skills &amp; Qualifications</p><p> </p><p>Requirements:</p><ul>   <li>Excellent computer science knowledge</li>   <li>Working experience in designing and building big data platforms (distributed filesystems, distributed databases, batch processing frameworks, stream processing frameworks, message queues, job scheduling)</li>   <li>Expert knowledge of scalable architecture for real-time processing</li>   <li>Experience ensuring data quality and compliance</li>   <li>Experience with DevOps and continuous integration</li>   <li>Experience in agile practices, test-driven development</li>   <li>Fluent written and spoken English</li>  </ul><p>Good to have:</p><ul>   <li>Good documentation skills</li>   <li>Experience in Fintech</li>   <li>Experience with machine learning</li>  </ul>"
0,Senior Data Engineer,TITANSOFT PTE. LTD.,Central,Executive,Professional Services,Permanent,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/senior-data-engineer-titansoft-7ce2e0a5c4ed7a640e372253970f72e5,"<p>If you believe data makes the world go round, we believe we have found the one we are looking for. Our data and research team are the ultimate magicians of data. They throw data in the system, wave their hands around the keyboard, and pull out a never-ending stream of business value.</p><p>Our team have opportunities to build efficient and reliable data pipelines that move data across systems.</p><p>Our team are part mathematician, part computer scientist, and part interpreters- magicians of data. If you are interested to work some magic with our data, drop us an owl.</p><p><strong>What a Senior Data Engineer does in Titansoft</strong></p><ul> 	<li>Partner with internal stakeholders to understand business requirements</li> 	<li>Work with cross-functional data and product teams to build efficient and scalable data solutions</li> 	<li>Design, build, optimize, launch and support new and existing data models in production</li> 	<li>Build scalable solutions of real-time data streaming and static analysis</li> 	<li>Setup network for deploy cluster and troubleshooting</li> 	<li>Write Linux script programming to assist in auto deploy and system health monitoring</li> 	<li>Design and build reliable Hadoop system</li> </ul>","<p><strong>What we are looking for in a Senior Data Engineer</strong></p><p><strong>Qualifications</strong></p><ul> 	<li>BA / BS in Computer Science, Electronics or Electrical Engineering, Information Technology or other relevant fields</li> </ul><p><strong>Experience</strong></p><ul> 	<li>3+ years of experience in Unix / Linux operation systems (e.g. file systems, inodes, system calls) or networking (e.g. TCP / IP, routing, network topologies and hardware, SND)</li> 	<li>2+ years of hands-on experience in the data warehouse space, custom ETL design, implementation and maintenance</li> 	<li>3+ years of hands-on experience in SQL or similar languages and development experience in at least one scripting language (Python preferred)</li> 	<li>Experience with large data sets, Hadoop, and data visualization tools</li> </ul><p><strong>Skills</strong></p><ul> 	<li>Strong data architecture, data modeling, schema design</li> 	<li>Effective project management skills in leading data driven projects from definition to interpretation and execution</li> 	<li>Ability to initiate and drive projects, and communicate data warehouse plans to internal clients / stakeholders</li> </ul><p><strong>What makes a (Super!) Senior Data Engineer in Titansoft</strong></p><ul> 	<li>Expertise in designing and analyzing large-scale distributed systems (e.g. Hadoop, Kafka, Hive)</li> 	<li>Systematic problem-solving approach</li> 	<li>Ability to debug and optimize code and automate routine tasks</li> </ul>"
0,Data Engineer,WOODPECKER ASIA TECH PTE. LTD.,Central,Professional,Information Technology,Permanent,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-woodpecker-asia-tech-33b8c0dff334c40cbd610e489ebf4e98,"<p>Our Data Engineer (in the analytics team) is the person responsible for enhancing our analytics and performance management framework. You’ll be building our data infrastructure - like databases and large-scale data processing tools -  on the Google Cloud Platform.  You’ll be a perfect fit in this role if you’re an eager learner, have prior experience in quantitative domains, and if you’re keen to be a team player in a dynamic start-up.</p><p><strong>You’ll get to:</strong></p><ul>   <li>Design, construct, install, test and maintain highly scalable data management systems</li>   <li>Employ a variety scripting languages and tools to marry systems together</li>   <li>Make sure our systems meet business requirements and industry practices</li>   <li>Research opportunities for data acquisition and new uses for existing data</li>   <li>Develop data set processes for data modelling, mining and production</li>   <li>Integrate new data management technologies and software engineering tools into existing structures</li>   <li>Create custom software components and analytics applications</li>   <li>Install and update disaster recovery procedures</li>   <li>Recommend ways to improve data reliability, efficiency and quality</li>   <li>Collaborate with data architects, modelers and IT team members on project goals</li>   <li>Build high-performance algorithms, prototypes, predictive models and proof of concepts</li>  </ul>","<p><strong>Skills:</strong></p><ul>   <li>2-3 years of working experience as a Data Engineering or as a developer</li>   <li>Bachelor’s or Master’s degree in Computer Science</li>   <li>Proficient in Java and in one of the scripting languages such as Python, JavaScript, Ruby or PHP</li>   <li>Proficient with No-SQL databases like HBase or MongoDB</li>   <li>Proficient in ETL processes and programming models on Apache Beam</li>   <li>Proficient in cloud computing systems management services such as Stackdriver</li>   <li>Familiar with cloud services such as MS Azure, Google Cloud Platform or AWS</li>   <li>Familiarity with Machine Learning and Statistical techniques for data mining will be beneficial</li>   <li>Familiarity with Google Analytics and Google Tag Manager will be an advantage</li>   <li>Proficient in oral and written communication in English, as well as effective interpersonal skills</li>  </ul>"
0,Data Engineer,TITANSOFT PTE. LTD.,Central,Executive,Professional Services,Permanent,"$3,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-titansoft-348181dcee42ac1c3b45c394fa314a43,"<p>If you believe data makes the world go round, we believe we have found the one we are looking for. Our data and research team are the ultimate managers of data. Others see meaningless figures but they see value.</p><p>Our team are part of mathematician, part of computer scientist, and part of interpreters. Of data.</p><p><strong>What a Data Engineer does in Titansoft</strong></p><p>Manage data warehouse with plans for a business vertical or a group of business verticals</p><p>Generate and manage all allocated data sets including ensuring its quality based on requirements</p><p>Work with our Data Infrastructure team to triage and resolve infrastructure issues</p><p>Manage the delivery of high impact dashboards and data visualisation diagrams</p>","<p><strong>What we are looking for in a Data Engineer</strong></p><p><strong>Qualifications</strong></p><p>BA/BS in Computer Science, Electronics or Electrical Engineering, Information Technology or other qualified achievement</p><p><strong>Experience</strong></p><p>Hands-on experience in SQL or similar languages and development experience in at least one scripting language (Python preferred)</p><p>Understand data architecture, data modeling and schema design</p><p><strong>What makes a (Super!) Data Engineer in Titansoft</strong></p><p>Patience to clean up huge amounts of data</p><p>Passion to research domain knowledge</p><p>Experience with large data sets, Hadoop, and data visualisation tools</p><p>Interest in cloud computing and service (GCP, AWS, Azure)</p><p>Interest in AI/ Machine-Learning product</p>"
0,Data Engineer,BLUE STAR INFOSTACK SOLUTIONS PTE. LTD.,Central,Executive,Information Technology,Contract,"$3,500","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-blue-star-infostack-solutions-5bf603c975eef55f408defd7b6da76dd,"<p><strong>Data Engineer  </strong>– Location Singapore</p><p> </p><ul> 	<li>6+ years Experience in ETL / BI Technologies</li> 	<li>Hands on experience of writing complex SQL queries</li> 	<li>Experience with Amazon Kinesis, Hadoop, DynamoDB, Hive, and/or Spark a plus</li> 	<li>Understanding of data warehousing &amp; databases is critical</li> 	<li>Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)</li> 	<li>Experience with data visualization tools (Tableau)</li> 	<li>Experience in requirement analysis, system design, development and testing</li> 	<li>Able to perform independent code reviews and execute unit tests on modules developed by self &amp; other junior team members on the project.</li> 	<li>Expertise in coding, system testing, implementation and maintenance, performance tuning, go-live support and post-production support.</li> 	<li>Ensure the data is secure by creating and updating profiles, rules and Business reports timely.</li> 	<li>Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs  </li> </ul>","<ul> 	<li>6+ years Experience in ETL / BI Technologies</li> 	<li>Hands on experience of writing complex SQL queries</li> 	<li>Experience with Amazon Kinesis, Hadoop, DynamoDB, Hive, and/or Spark a plus</li> 	<li>Understanding of data warehousing &amp; databases is critical</li> 	<li>Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)</li> 	<li>Experience with data visualization tools (Tableau)</li> 	<li>Experience in requirement analysis, system design, development and testing</li> 	<li>Able to perform independent code reviews and execute unit tests on modules developed by self &amp; other junior team members on the project.</li> 	<li>Expertise in coding, system testing, implementation and maintenance, performance tuning, go-live support and post-production support.</li> 	<li>Ensure the data is secure by creating and updating profiles, rules and Business reports timely.</li> 	<li>Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs  </li> </ul>"
0,"Manager (Data Engineer), Decision Science, Credit Cards & Personal Financing",CIMB BANK BERHAD,Central,Manager,Information Technology,Permanent,"$5,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/manager-decision-science-credit-cards-personal-financing-cimb-bank-berhad-33c003e1efee0089e56ee31524c47877,"<ul> 	<li>Design, implement, and optimize the data pipelines from various channels using the latest technologies.</li> 	<li>Deploy dimensional data model to support functional and analytical business requirements.</li> 	<li>Partner with data analysts, business subject-matter experts and cross-functional technology teams to deliver end-to-end analytics solutions.</li> 	<li>Determine reporting needs to be integrated with business intelligence visualization tools and manage reports distribution via content management tools.</li> 	<li>Research, evaluate, and recommend technical solutions for data collection, processing, and reporting.</li> 	<li>Data cleansing, scraping unstructured data and converting them into structured/usable data.</li> </ul>","<ul> 	<li>Bachelor Degree / Diploma in Computer Science, Information System or related studies.</li> 	<li>Minimum 5 years of experience in a data processing role.</li> 	<li>Consistent track record of designing and implementing scalable, performant data pipelines, data services, and data products.</li> 	<li>Proven ability to work well independently and within a fast-paced, collaborative environment.</li> 	<li>Excellent debugging, critical thinking and communication skills.</li> 	<li>Programming experience in building high quality data applications. Skills such as Java, Python or ASP.NET are preferred.</li> 	<li>Proficient in SAS, MS Excel and SQL Programming.</li> 	<li>Strong aptitude for learning new technologies related to Data Management and Data Science.</li> </ul><p>Please send detailed resume, including salary expectation and contact number to sg.enquiries@cimb.com.<br> We regret that only shortlisted candidates will be notified.</p>"
0,Data Engineer,INFOGAIN PTE. LTD.,Central,Executive,Information Technology,Contract,"$3,500","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-infogain-4ddd284c9d10ef1c1072cc6a0c72aa15,"<p><strong>Data Engineer  </strong>– Location Singapore</p><ul> 	<li>6+ years Experience in ETL / BI Technologies</li> 	<li>Hands on experience of writing complex SQL queries</li> 	<li>Experience with Amazon Kinesis, Hadoop, DynamoDB, Hive, and/or Spark a plus</li> 	<li>Understanding of data warehousing &amp; databases is critical</li> 	<li>Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)</li> 	<li>Experience with data visualization tools (Tableau)</li> 	<li>Experience in requirement analysis, system design, development and testing</li> 	<li>Able to perform independent code reviews and execute unit tests on modules developed by self &amp; other junior team members on the project.</li> 	<li>Expertise in coding, system testing, implementation and maintenance, performance tuning, go-live support and post-production support.</li> 	<li>Ensure the data is secure by creating and updating profiles, rules and Business reports timely.</li> 	<li>Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs  </li> </ul>","<p><strong>  </strong>– Location Singapore</p><p> </p><ul> 	<li>6+ years Experience in ETL / BI Technologies</li> 	<li>Hands on experience of writing complex SQL queries</li> 	<li>Experience with Amazon Kinesis, Hadoop, DynamoDB, Hive, and/or Spark a plus</li> 	<li>Understanding of data warehousing &amp; databases is critical</li> 	<li>Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)</li> 	<li>Experience with data visualization tools (Tableau)</li> 	<li>Experience in requirement analysis, system design, development and testing</li> 	<li>Able to perform independent code reviews and execute unit tests on modules developed by self &amp; other junior team members on the project.</li> 	<li>Expertise in coding, system testing, implementation and maintenance, performance tuning, go-live support and post-production support.</li> 	<li>Ensure the data is secure by creating and updating profiles, rules and Business reports timely.</li> 	<li>Strong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs </li> </ul>"
0,Data Engineer,DATASPARK PTE. LTD.,Central,Executive ...,Information Technology,Permanent,"$3,500","$10,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-dataspark-e2b15cf3851973954e5d49b8515e1a38,"<p><strong>Responsibilities</strong></p><ul>   <li>design and implement scalable and robust software platform for ingesting and transforming telco network datasets in (near) real-time using a variety of open-source and proprietary Big Data technologies</li>   <li>recommend and implement ways to improve data reliability, efficiency and quality</li>   <li>collaborate with product management, sales and marketing, and solution delivery teams to support the objectives that customer requirements are well managed and reflected in product releases</li>   <li>support the deployment of DataSpark software within clients' IT environment</li>   <li>working closely with stakeholders to ensure high standards of data governance during implementation</li>   <li>serve as technical subject matter expert in latest big data technologies</li>  </ul>","<p><strong>Requirements</strong></p><ul>   <li>7+ years of superior software development experience building commercial large-scale software systems and database systems</li>   <li>Excellence in algorithms, data structure, discrete math, data base and data warehousing</li>   <li>Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data</li>   <li>Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills</li>   <li>Experience of data warehouses in excess of 10TB</li>   <li>Experience of Web UI, middle tier, and data back end development</li>   <li>Production coding experience in choice of programming languages and development frameworks</li>   <li>Proven professional experience in processing large-scale commercial data. Experience with telco data a plus.</li>   <li>Superior and proactive communications skills, including verbal, written, and presentation.</li>   <li>A proven team player and contributor.</li>   <li>Self-directed, ability to work independently and research innovative solutions to business problems</li>   <li>Aptitude of working on multiple projects in parallel</li>   <li>Attention to details and data accuracy</li>   <li>MS or BS degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent is required for this position.</li>  </ul>"
0,Lead Data Engineer,DATASPARK PTE. LTD.,Central,Executive ...,Information Technology,Permanent,"$3,500","$10,000",Monthly,https://www.mycareersfuture.sg/job/lead-data-engineer-dataspark-4abea20ccd88d913146ec6ecbd387a27,"<p><strong>Responsibilities</strong></p><ul>   <li>design and implement scalable and robust software platform for ingesting and transforming telco network datasets in (near) real-time using a variety of open-source and proprietary Big Data technologies</li>   <li>recommend and implement ways to improve data reliability, efficiency and quality</li>   <li>collaborate with product management, sales and marketing, and solution delivery teams to support the objectives that customer requirements are well managed and reflected in product releases</li>   <li>support the deployment of DataSpark software within clients' IT environment</li>   <li>working closely with stakeholders to ensure high standards of data governance during implementation</li>   <li>serve as technical subject matter expert in latest big data technologies</li>  </ul>","<p><strong>Requirements</strong></p><ul> 	<li>10+ years of superior software development experience building commercial large-scale software systems and database systems</li> 	<li>Excellence in algorithms, data structure, discrete math, data base and data warehousing</li> 	<li>Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data</li> 	<li>Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills</li> 	<li>Experience of data warehouses in excess of 10TB</li> 	<li>Experience of Web UI, middle tier, and data back end development</li> 	<li>Production coding experience in choice of programming languages and development frameworks</li> 	<li>Proven professional experience in processing large-scale commercial data. Experience with telco data a plus.</li> 	<li>Superior and proactive communications skills, including verbal, written, and presentation.</li> 	<li>A proven team player and contributor.</li> 	<li>Self-directed, ability to work independently and research innovative solutions to business problems</li> 	<li>Aptitude of working on multiple projects in parallel</li> 	<li>Attention to details and data accuracy</li> 	<li>MS or BS degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent is required for this position.</li> </ul>"
0,Senior Data Engineer,DATASPARK PTE. LTD.,Central,Executive ...,Information Technology,Permanent,"$3,500","$9,000",Monthly,https://www.mycareersfuture.sg/job/senior-data-engineer-dataspark-afaa4ad5870b05c31d2738918ce5177c,"<p><strong>Responsibilities</strong></p><ul>   <li>design and implement scalable and robust software platform for ingesting and transforming telco network datasets in (near) real-time using a variety of open-source and proprietary Big Data technologies</li>   <li>recommend and implement ways to improve data reliability, efficiency and quality</li>   <li>collaborate with product management, sales and marketing, and solution delivery teams to support the objectives that customer requirements are well managed and reflected in product releases</li>   <li>support the deployment of DataSpark software within clients' IT environment</li>   <li>working closely with stakeholders to ensure high standards of data governance during implementation</li>   <li>serve as technical subject matter expert in latest big data technologies</li>  </ul>","<p><strong>Requirements</strong></p><ul>   <li>7+ years of superior software development experience building commercial large-scale software systems and database systems</li>   <li>Excellence in algorithms, data structure, discrete math, data base and data warehousing</li>   <li>Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data</li>   <li>Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills</li>   <li>Experience of data warehouses in excess of 10TB</li>   <li>Experience of Web UI, middle tier, and data back end development</li>   <li>Production coding experience in choice of programming languages and development frameworks</li>   <li>Proven professional experience in processing large-scale commercial data. Experience with telco data a plus.</li>   <li>Superior and proactive communications skills, including verbal, written, and presentation.</li>   <li>A proven team player and contributor.</li>   <li>Self-directed, ability to work independently and research innovative solutions to business problems</li>   <li>Aptitude of working on multiple projects in parallel</li>   <li>Attention to details and data accuracy</li>   <li>MS or BS degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent is required for this position.</li>  </ul>"
0,Data Quality Engineer,ALPHATECH BUSINESS SOLUTIONS PTE. LTD.,East,Senior Executive,Information Technology,Permanent,"$6,000","$7,800",Monthly,https://www.mycareersfuture.sg/job/data-quality-engineer-alphatech-business-solutions-397e27060c6ed0fcabb3f578caac8432,<ul> 	<li>Evaluate and recommend solutions via data analysis regarding issues related to the improvement of product qua;oty and resolving of customer feedback</li> 	<li>Apply software and programming abilities to manage and analyse data from a variety of sources</li> </ul>,"<p> </p><ul> 	<li>Must know JAVA8 and SPARK</li> 	<li>Experience in distributed data architecture</li> 	<li>Have working knowledge of SQL, Python, Airflow Scala, Hadoop, SPARK</li> 	<li>Good to know CI/CD Experience (Jenkins Github), AWS, Kubernetes, Docker</li> 	<li>Preferred to have banking domain experience</li> </ul>"
0,"Research Engineer (Big Urban Data), IHPC",A*STAR RESEARCH ENTITIES,South,Non-executive,Sciences / Laboratory / R&D,Contract ...,"$2,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/research-engineer-ihpc-astar-research-entities-8b98f5f89638750fc0375acb68fd332e,<p>He/She will mainly work on data preprocessing and preliminary analysis for dengue risk modeling research in this project. He/She will also be responsible for database construction and maintenance in this project and assist research scientist to fulfil the research tasks and deliverables.</p>,"<ul> 	<li>Master/Bachelor Degree in mathematics, engineering and electronics</li> 	<li>Good programming experiences and capabilities in python, c sharp, R and Java</li> 	<li>Experience in data analysis, parallel computing, optimization, agent-based simulation, and/or visualization is an added advantage</li> </ul>"
0,Data Security Engineer (Ref 22641),Company Undisclosed,East,Executive,Information Technology,Contract ...,"$3,000","$6,000",Monthly,https://www.mycareersfuture.sg/job/data-security-engineer-e295250f4414c6bd07151ddc2e6ea469,"<p>- Integration experience with backend product and booking engines</p><p>- Creating complex applications, transforming user experience and enterprise</p><p>- Working with some of the latest tools and techniques </p><p>- Hands-on coding, initially solely responsible developing services that construct applications front to back ie from UX to data acquisition and repositories </p><p>- Working in highly collaborative teams and building quality code</p><p>- Working with senior business and technical colleagues to rapidly deliver solutions</p><p>- Collaborating with and working under the direction of senior technical colleagues</p><p>- Contributing to the technical design and architecture, particularly in service / microservice decomposition </p><p>- Knowledge in lots of different domains, programming languages and client environments</p><p>- Furnish the business domain deeply and working closely with business stakeholders</p>","<p>- Degree in Information System or Computer Science related </p><p><strong>- Must have knowledge in Protegrity and/or Blue Talon software </strong></p><p>- 3 to 4 years of experience in banking environment </p><p>- Preferably trained in Agile methodology </p><p>- Proficient in Jira </p><p>- 3+ years of hands on experience in distributed data architectures is a must</p><p>- 3+ years of Core Java or Scala or Python is a must </p><p>- Working knowledge of Apache Spark is a must </p><p>- CI/CD experience (Jenkins, Github) is a must </p><p>- Working knowledge of Bash scripts is a must </p><p>- AWS experience is nice to have </p><p>- Kubernetes or Docker experience is nice to have</p><p>- Strong communication skills </p><p>- Previous work experience in Big Data environment is a plus</p><p>- Understand Agile and full data warehouse flow</p><p>- Understand database languages for analysing data out of data warehouse</p><p> </p><p>Licence No: 12C6060</p>"
0,Assistant Manager - Data Engineer,DAIMLER SOUTH EAST ASIA PTE. LTD.,West,Professional,Information Technology,Full Time,"$6,000","$13,000",Monthly,https://www.mycareersfuture.sg/job/assistant-manager-data-engineer-daimler-south-east-asia-30160a980e2c75182c6e3bded6c6c8a1,"<p>• Responsible for managing data sources, Data Ingest and Data Preparation processes including Metadata Management</p><p>• Responsible for design of data models and to ensure they are in alignment with headquarter and global data models and scalable to other regions</p><p>• Participate in Data Requirements Gathering and Analysis meetings with Team Members, Internal Customers, and Stakeholders.</p><p>• Develop, maintain, test, and troubleshoot data solutions, including Database Development, ETL / Data Migration Development, and Big Data Development.</p><p> </p><p>1. IT Solutions Delivery</p><p>• Analyse complex, high-volume, high-dimensionality data from varying sources using a variety of ETL and data analysis techniques.</p><p>• Responsible for managing data sources, Data Ingest and Data Preparation processes including Metadata Management</p><p>• Responsible for design of data models and to ensure they are in alignment with headquarter and global data models and scalable to other regions</p><p>• Participate in Data Requirements Gathering and Analysis meetings with Team Members, Internal Customers, and Stakeholders.</p><p>• Develop, maintain, test, and troubleshoot data solutions, including Database Development, ETL / Data Migration Development, and Big Data Development.</p><p>• Understanding and support of Regional overseas Data Lake and analytics engine and platform</p><p>• Assist with enabling “Next best action / Offer and data insights” solutions that are scalable and transferable for regional markets</p><p>• Investigation and understanding data landscape for the respective markets</p><p>• Ability to recognize/analyse highly complex processes, interdependencies and gaps and to develop new approaches to solutions</p><p>• Supports and troubleshoots the data movement processes and the data warehouse environment</p><p>• Promote synergies and reuse within and across projects and platforms in order to maximize rapid yet responsible delivery</p><p> </p><p>2. IT Strategy and Strategic Supplier Management (SSM)</p><p>• Support in lean implementation and managing run costs downwards.</p><p>• Support in sourcing and supplier management, liaise with ITx on SSM</p><p>• Sharing and collaboration of solution across all regions</p><p>• Ensure that standardized solutions are delivered</p><p>• Ensure consistency of the overall Overseas IT landscape</p><p>• Conduct post-implementation assessment to ensure that required value was delivered</p><p> </p><p>3. Coordination &amp; Communication</p><p>• Management reporting and provide training on the platform architecture and strategy topics</p><p>• Build-up and strengthen relationship with all stakeholders in the region, headquarter and the markets to effectively perform the necessary tasks within the function</p><p>• Ability to explain complex processes clearly and precisely to different target groups and to explain the specific benefits of solution approaches</p><p> </p>","<p>• Bachelor’s Degree in Business or IT Qualification</p><p>• 2+ years’ relevant experience, minimum 5 years of working experience</p><p>• Specific knowledge: People Management knowledge; IT knowledge; Process knowledge      </p><p>• Experience with Azure Data Lake, Azure Data Lake Analytics, Azure Data factory, HDInsights.</p><p>• Experience with design and implementation of HDInsights with Spark, Kafka clusters.</p><p>• Experience with SQL Server Integration Services, Reporting Services and Analytic Services.</p><p>• Familiar with Microsoft Azure data storage, ingestion, computation services &amp; APIs.</p><p>• Understands the common data movement architectures (like ETL, ELT, etc.)</p><p>• Strong experience with Metadata Management, establish sourcing and access patterns for enterprise reference data.</p><p>• Experience with data extraction and manipulation, and ad-hoc query tools</p><p>• Highly motivated independent worker with minimum guidance required;</p><p>• Readiness to travel; (20% of travel)</p><p>• Ability to work in an international and intercultural context</p><p>• Excellent communication skills in both written and spoken. Multi-linguistic abilities would be an added advantage.</p>"
0,"Data, Analytics & Marketing Technology Engineer",FOX NETWORKS GROUP SINGAPORE  PTE. LTD.,Islandwide,Manager,Information Technology,Permanent,,,,https://www.mycareersfuture.sg/job/data-analytics-marketing-technology-engineer-fox-networks-group-singapore-e7d8281e9c60c1456b8efe30459eaf61,"<p><strong><u>The Role:</u></strong></p><p>We are looking for a DevOps Engineer (Data, Analytics &amp; Marketing Technology) that will work on the integration &amp; improvement of our Analytics, Business Intelligence, and Customer Marketing platforms. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.</p><p> </p><p><strong><strong><u>Reporting To:</u></strong>  </strong>Head of Product, FOX+ (Asia)</p><p> </p><p><strong><u>Key Responsibilities:</u></strong> </p><ul>   <li>Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities</li>   <li>Working with the Business Intelligence team to develop &amp; maintain solutions for data consolidation, surfacing, and visualisation of Analytics &amp; Data</li>   <li>Translating business requirements from Marketing, Content, Product &amp; Business Intelligence teams into technical specifications for implementation by relevant engineering teams</li>   <li>Managing implementation &amp; integration of analysis &amp; visualisation tools</li>   <li>Owning the technical definition &amp; best practice for Analytics &amp; tracking implementation into a suite of applications incl. Mobile, web &amp; leanback.</li>   <li>Implementing ETL process</li>   <li>Monitoring performance and advising any necessary infrastructure changes</li>   <li>Defining data retention policies</li>  </ul><p> </p>","<p><strong><u>Must-haves</u></strong></p><ul>   <li>Minimum 3 years working knowledge with any scripting language (i.e. Javascript/Node, Python, Go)</li>   <li>Minimum 3 years working knowledge of any RDS such as PostgreSQL, MySQL.</li>   <li>Understands various network transport protocols, and data file formats.</li>   <li>Experience with implementing Client SDKs in a mobile environment.</li>   <li>Experience with Implementing Database infrastructures in AWS using RDS, elasticache, redshift, and aurora.</li>   <li>Proficient understanding of distributed computing principles</li>   <li>Experience with the Implementation &amp; Management of Amazon Redshift</li>   <li>Working knowledge of ETL in a Data Warehousing Context</li>   <li>Experience with the concept of analytics aggregation, or operation of tools such as Segment.com</li>   <li>Experience with at least one of these tools: PowerBI, Tableau, Google Analytics, or New Relic Insights.</li>   <li>Experience with the implementation &amp; Management of Marketing platforms, e.g. Braze, Adobe, Oracle</li>  </ul><p> </p><p><strong><u>Ideal &amp; Preferred</u></strong></p><ul>   <li>Certification in any enterprise RDS programmes.</li>   <li>Experience with NoSQL databases such as HBase, Cassandra, or MongoDB</li>   <li>Working knowledge of AWS Lambda.</li>   <li>Proficiency with Implementing and Maintaining Hadoop v2, MapReduce, or HDFS</li>   <li>Experience in Spark, Pig, Hive, or Impala</li>   <li>Experience with various messaging systems, such as Kafka or RabbitMQ</li>   <li>Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming</li>   <li>Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O</li>   <li>Experience with Cloudera/MapR/Hortonworks</li>  </ul>"
0,Data Center Engineer,Company Undisclosed,Central,Middle Management ...,Engineering ...,Full Time,"$3,000","$4,500",Monthly,https://www.mycareersfuture.sg/job/data-center-engineer-cbc6715f9ec705687a0e5ebab573d710,"<ul>   <li>knowledge/familiar in Network device/cabling /server/cabinet/rackesponsible for designing, setting up, and managing information/network systems</li>   <li>monitoring systems operations and administering IT solutions to ensure servers, hard drives, and other data center equipment function efficiently.</li>   <li>carry out performance-tuning operations on data center storage systems to ensure high level of data quality, availability, and security.</li>  </ul>",<p> </p><ul>   <li> at least diploma with min. 2years experience in Data Center</li>   <li> 3 rotating shifts</li>  </ul>
0,"Manager, Data Engineer",LAZADA SOUTH EAST ASIA PTE. LTD.,Central,Manager,Information Technology,Permanent,"$5,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/manager-data-engineer-lazada-south-east-asia-422f4112d8c3919982385233d71ff070,<p>We are looking for a Data Engineer that will be responsible to gather public information from the different players in the e-Commerce industry and consolidate them into a dashboard to get insights. You will be conducting strategic analysis to improve the products that are promoted on Lazada.</p><p><strong>What you will do:</strong></p><ul> 	<li>You will work with Big Data information - structuring different inputs into a dashboard that is understandable for local category teams to action on</li> 	<li>You will work with APIs and bots technology</li> 	<li>You will be the middleman between Business requirements and implementation</li> 	<li>You will improve the Lazada platform to get information from different websites and social networks</li> </ul>,<ul> 	<li>Bachelor’s Degree in Computer Science/Information Engineering or relevant technical field experience</li> 	<li>Minimum of 3 years of related professional work experience</li> 	<li>A great communicator</li> 	<li>Love code and open to learn new technologies</li> 	<li>Understand how Big Data databases works and how to get the information from it in a efficient way</li> 	<li>A decision maker. You will work in a environment with many stakeholders and you will have to understand and make decision in based of tradeoffs </li> </ul>
0,Data Sciences & Analytics Engineer,SINGAPORE AIRLINES LIMITED,East,Professional ...,Information Technology,Permanent,"$4,000","$8,000",Monthly,https://www.mycareersfuture.sg/job/data-sciences-analytics-engineer-singapore-airlines-bd7e3e2c924ad2085f77bfbcd9721c05,"<p>SIA has multiple positions for junior and senior data scientists to drive our business analytics, data science and AI initiatives. Responsibilities include the following:</p><ul> 	<li>Member of an in-house data analytics and AI development team that works on machine learning (including NLP, image recognition, recommender system, deep learning), experimental design, and optimization.</li> 	<li>Oversee the technical work and provide datasets to external technology partners to deliver products/services in data analytics, data science and AI. Support business users in the assessment/validation of partner-supplied prediction models and in their deployment to production.</li> 	<li>Help business units create Tableau dashboards with relevant datasets. Extract insights through data visualization.</li> 	<li>Work closely with application development teams to operationalize and integrate analytics/machine learning capabilities into production systems using RESTful-API microservices.</li> </ul>","<ul> 	<li>BS in Computer Science, Mathematics, Statistics, Physics or related discipline is required. Advanced degree related to analytics, machine learning or AI is preferred.</li> 	<li>Intermediate or advanced programming skills in Python. Conversant with algorithm design, data structure and SQL. Functional/object-oriented software development experience using Java or Scala is a plus.</li> 	<li>At least 2 years of relevant industry experience in two or more of the following areas: 	<ul> 		<li>Hands-on skills in shallow machine learning, AI, or information retrieval. Experience in GPU-accelerated deep learning frameworks (such as Keras, TensorFlow, PyTorch) is a plus.</li> 		<li>Knowledge and working experience in workflow, map-reduce or stream processing systems such as Spark and Kafka.</li> 		<li>Knowledge in statistics, especially Bayesian statistics and inference.</li> 		<li>Knowledge and working experience with data visualization tools like Tableau, PowerBI and Qlik.</li> 	</ul> 	</li> 	<li>Experience with Agile/Scrum/Kanban methodologies is a plus.</li> 	<li>Hands-on experience with AWS, GCP or similar public cloud environment is a plus.</li> 	<li>Excellent interpersonal &amp; communication skills to work with non-technical business users.</li> 	<li>Proven ability as a problem-solver. </li> </ul>"
0,Data Engineer - MSBI Stack,ITCAN PTE. LIMITED,Islandwide,Professional,Information Technology,Full Time,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-msbi-stack-itcan-93351a0bf0e614e714dedb5d1250e2c0,"<p>1. Designs and creates information store / data warehouse and all related extraction, transformation and load of data functions</p><p>2. Experts at taking a big-picture view of a company's data situation</p><p>3. Proficient in able to read, analyze and digest what a business wants to accomplish with its data, understand data models and translate them into the best possible design of Databases and ETL processes</p><p>4. Executes basic and advanced transformation activities such as normalization, cleansing, aggregation, summarizing, and integration</p><p>5. Designs automation processes to control data access, transformation and movement; ensures source system data availability and update accessibility, data integrity, restorability and appropriately handles errors in a timely manner</p><p>6. Develops logical and physical data flow models for ETL applications. Translates data access, transformation and movement requirements into functional requirements and mapping designs</p><p>7. Plans and conducts ETL unit and development tests; monitors results and takes corrective action, when necessary</p><p>8. Plans, coordinates and implements security measures to safeguard data in information store / datawarehouse against accidental or unauthorized damage, modification or disclosure</p><p>9. Analysis of business requirements document created by Data Architect team</p><p>10. Create SSIS packages based on mapping document</p><p>11. Unit test &amp; optimize SSIS package according to business needs</p><p>12. Document technical details of ETL project in Excel &amp; word documents</p><p>13. Code maintenance in TFS (Branching/Merging)</p><p>14. Contact Data Architects for any queries/confusions/design changes for IS</p>","<p>. Bachelor’s degree or equivalent in relevant discipline.</p><p>2. Minimum 5 yrs. exp. working on MSBI Stack (SSAS, SSIS, SSRS)</p><p>3. Minimum 5 yrs. exp. working on SQL Server, DB2, Oracle databases</p><p>4. Working knowledge of modeling tools (Erwin, Embarcadero, EA Sparx etc.) in addition to hands-on experience with business intelligence tools</p><p>5. Mandatory Technical expertise in:</p><ul> 	<li>MS SQL Server 2008 R2 - FastTrack Data Warehouse</li> 	<li>Databases - DB2, SQL Server, Oracle (Must be able to write complex queries against these DBs)</li> 	<li>SQL Server Integration Services (Writing efficient SSIS packages)</li> 	<li>Any data replication tool (preferred: MS SQL Server, DT Share)</li> 	<li>Writing complex &amp; efficient Stored Procedures, Views, Functions in MS SQL Server</li> 	<li>Optimizing complex SQL queries for optimum performance</li> 	<li>Setting up schedule jobs using Windows Scheduler or SQL Agent</li> 	<li>Any Data Quality Tools - Preferred: TIBCO Trillium, MS DQS</li> 	<li>Any Master Data Management Tools - Preferred: TIBCO MDM, MS MDS</li> </ul><p>6. Technical expertise in the following areas are a plus:</p><ul> 	<li>ETL experience with SAS Enterprise Guide</li> </ul>"
0,Data Centre Operations Engineer,HCL SINGAPORE PTE. LTD.,Central,Professional,Information Technology,Permanent,"$4,500","$5,000",Monthly,https://www.mycareersfuture.sg/job/data-centre-operations-engineer-hcl-singapore-62dbbb34399b6d8a59ef894555a48b65,"<p>The Data center hands and feet engineer will Perform day to day activities, users, visitors and subscriber’s co-ordination. Co-ordinate with visitors visiting the DC for activities</p><p>Will co-ordinate with respective teams with in a project</p><p>Will be responsible for handling issues pertaining to operations and production</p><p>Will be responsible to manage incidents during the shift</p><p>Will be part of DC hands and feet operation team to work for customer on different DC member sites (Singapore) in the project and performing equipment Installation and Decommission, troubleshooting. Travel to different sites for INC/Planned activities</p><p>Will be installing and decommissioning equipment’s, servers racking and stacking in the Datacentre</p><p>Will be performing DC Cabling, labelling, patching</p><p>Daily DC server health checks, walkthroughs, reporting, printing, remedy and email queue management</p><p>Must have DC Cabling and equipment hardware troubleshooting knowledge</p><p>Should have basic understanding of DC facilities, environment and standards</p><p>Receiving the material deliveries, maintaining the inventory store room</p><p>Maintaining visitor records &amp; access logs</p><p>24*7 environment, shift rotation</p><p>Flexibility per team rotation requirement</p><p>Professional in 24/7 operational team availability</p><p> </p>",<p>Hands on with DC infrastructure environment</p><p>Good Experience in DC 24*7 Operation process &amp; procedures</p><p>DC racking and stacking &amp; structured cabling understanding</p><p>GOOD to HAVE</p><p>Any Technical certification</p><p>DC Certification</p><p>Technical / Professional Skills</p><p>Experience working with external Vendors</p><p>Good communication and interpersonal skills</p><p>Non-Technical / Soft Skills</p><p>Excellent team player</p><p>flexibility in 24*7 environment</p><p>Maximum availability for operational requirements</p><p> </p>
0,Data Center Engineer,ITCAN PTE. LIMITED,West,Executive,Information Technology,Contract ...,"$2,500","$4,500",Monthly,https://www.mycareersfuture.sg/job/data-center-engineer-itcan-bc2dcbf70c1b0339a2c55059d0dc24ad,"<p>1.       To take care of the function of the external service of the server room, which includes floor plan and layout of the server room, electrical equipment access management including UPS, MDB and DB, and on-site service management of the server room;</p><p>2.       Responsible for the daily operation and maintenance of power supply and all the cabling of the server room, and ensure a stable operation environment through implementation and management of strict and standard daily operation and maintenance on site.</p><p>3.       Responsible for capacity management of the server room, including floor plan and rack layout, ensuring optimal estate space usage of the server room;</p><p>4.       Responsible for coming up with the standard operating procedures for server room service management, and implementing the work quality management internally according to the standard to ensure improvement of work quality, timeliness and satisfaction;</p><p>5.       Responsible for daily operation and maintenance information management of the server room, identifying and providing server room space, power analysis report regularly, resolving all issues both existing and future.</p><p>6.       Serve as the duty leader, responsible for all work and personnel during the shift, and ensure the quality of work.</p>","<ol>  <li>One year and more working experience in server room operation and maintenance is preferred.</li>  <li>Related knowledge of computer foundation, server room operation, infrastructure and strong and weak current. </li>  <li>Have data analysis and report generating skills </li>  <li>Willing to work base on shift </li> </ol>"
0,Data Engineer,PROPERTYGURU PTE. LTD.,Central,Professional ...,Engineering ...,Permanent ...,"$5,000","$7,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-propertyguru-82e462a13cadc477f93d57ad6812d1d1,"<p>Our websites attract more than 100 million monthly page-views which result in non-stop massive click-stream for behaviour data with around 130 million of users. As a result, PropertyGuru has the most comprehensive data for property supply and demand in Southeast Asia.</p><p>Our Data Science team is empowered to build unique and compelling user experiences using machine learning and data. </p><p>Your work will be to design, develop, support and maintain our existing infrastructure and democratizing data access within and outside the company. Your work will support the following areas:</p><ul> 	<li>Real time streaming infrastructure: 	<ul> 		<li>Enable teams to move quickly and get accurate information to the right people with minimum delay would be the key focus of the data engineering team</li> 		<li>Advance our streaming platform which allows easy development of the streaming applications</li> 	</ul> 	</li> 	<li>Interactive Data Analytics: 	<ul> 		<li>Query the data and compute the aggregates on various dimensions to support the various decisions made on the data and machine learning products that are built around it</li> 	</ul> 	</li> 	<li>Infrastructure management: 	<ul> 		<li>Help manage multiple terabyte-scale clusters, easy-to-use systems to handle security and replication are in development</li> 	</ul> 	</li> 	<li>Data workflow management: 	<ul> 		<li>Use Airflow and Azkaban to schedule data related workflows supporting various analytical and machine learning workloads</li> 	</ul> 	</li> 	<li>Machine learning infrastructure: 	<ul> 		<li>Develop <strong><u>the end-to-end platform</u></strong> that will allow us to develop and deploy various machine learning models into the PropertyGuru websites and apps with ease</li> 		<li>Data engineers play a very big role in this platform development and has the potential to significantly cut down the development time of the machine learning models</li> 	</ul> 	</li> </ul>","<ul> 	<li>Bachelor’s degree in IT or relevant field. Alternatively, lesser qualifications with strong experience in machine learning will also be considered </li> 	<li>2+ years of industry experience in working with terabyte scale datasets</li> 	<li>Working knowledge of relational databases and query authoring (SQL)</li> 	<li>Experience with data workflow management tools such as Azkaban, Airflow</li> 	<li>Ability to write high performance quality code</li> 	<li>Experience in Python is a must. Other equivalent languages like C++, Java, Go, Scala is a plus.</li> 	<li>Experience with open source technologies like Kafka, Presto and Spark would be a plus </li> 	<li>Awareness of various cloud-based solutions such as AWS Redshift, Google Big Query, Qubole is a plus</li> </ul><p>Visit us at: htps://www.propertygurugroup.com/</p>"
0,Data Engineer,PROPERTYGURU PTE. LTD.,Central,Professional ...,Engineering ...,Permanent ...,"$7,000","$9,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-propertyguru-763708ca5a581db4389a766ef71654a0,"<p>Our websites attract more than 100 million monthly page-views which result in non-stop massive click-stream for behaviour data with around 130 million of users. As a result, PropertyGuru has the most comprehensive data for property supply and demand in Southeast Asia.</p><p>Our Data Science team is empowered to build unique and compelling user experiences using machine learning and data. </p><p>Your work will be to design, develop, support and maintain our existing infrastructure and democratizing data access within and outside the company. Your work will support the following areas:</p><ul>   <li>Real time streaming infrastructure:    <ul>     <li>Enable teams to move quickly and get accurate information to the right people with minimum delay would be the key focus of the data engineering team</li>     <li>Advance our streaming platform which allows easy development of the streaming applications</li>    </ul> </li>   <li>Interactive Data Analytics:    <ul>     <li>Query the data and compute the aggregates on various dimensions to support the various decisions made on the data and machine learning products that are built around it</li>    </ul> </li>   <li>Infrastructure management:    <ul>     <li>Help manage multiple terabyte-scale clusters, easy-to-use systems to handle security and replication are in development</li>    </ul> </li>   <li>Data workflow management:    <ul>     <li>Use Airflow and Azkaban to schedule data related workflows supporting various analytical and machine learning workloads</li>    </ul> </li>   <li>Machine learning infrastructure:    <ul>     <li>Develop <strong><u>the end-to-end platform</u></strong> that will allow us to develop and deploy various machine learning models into the PropertyGuru websites and apps with ease</li>     <li>Data engineers play a very big role in this platform development and has the potential to significantly cut down the development time of the machine learning models</li>    </ul> </li>  </ul>","<ul>   <li>Bachelor’s degree in IT or relevant field. Alternatively, lesser qualifications with strong experience in machine learning will also be considered </li>   <li>2+ years of industry experience in working with terabyte scale datasets</li>   <li>Working knowledge of relational databases and query authoring (SQL)</li>   <li>Experience with data workflow management tools such as Azkaban, Airflow</li>   <li>Ability to write high performance quality code</li>   <li>Experience in Python is a must. Other equivalent languages like C++, Java, Go, Scala is a plus.</li>   <li>Experience with open source technologies like Kafka, Presto and Spark would be a plus </li>   <li>Awareness of various cloud-based solutions such as AWS Redshift, Google Big Query, Qubole is a plus</li>  </ul><p>Visit us at: htps://www.propertygurugroup.com/</p>"
0,Data Engineer,NEURONCREDIT PTE. LTD.,Central,Executive,Information Technology,Full Time,"$5,000","$9,000",Monthly,https://www.mycareersfuture.sg/job/data-engineer-neuroncredit-0f8b1db000a42e246f0c42e728953f8f,"<p><strong>Job Responsibilities </strong></p><p>The Senior Data Engineer role requires maintaining data platforms, data pipeline and ETL, implementing AI models, and integrate our internal services. You will work with data scientists and back-end engineers in the team.</p>","<p><strong>Job Requirements</strong></p><ul> 	<li>B.Sc./M.Sc. in Computer Science or a related field</li> 	<li>At least 3-year experience as a Data Engineer or Backend Developer</li> 	<li>Hands-on development experience in python, Java and Scala</li> 	<li>Familiar with MySQL/Mariadb, MongoDB, and Redis.</li> 	<li>Hands-on experience of building applications and infrastructure.</li> 	<li>Hadoop/Spark eco-system or any other big data technologies is a plus</li> 	<li>Experience in Docker and K8s is a plus.</li> 	<li>Meticulous, responsible, a strong team player</li> </ul>"
0,Senior Data Engineer,ZUZU HOSPITALITY SOLUTIONS PTE. LTD.,South,Professional,Engineering,Full Time,"$6,000","$10,000",Monthly,https://www.mycareersfuture.sg/job/senior-data-engineer-zuzu-hospitality-solutions-4e3584148bdf0237093b107030de7abd,"<p>Join a visionary team with tremendous experience in the travel industry focused on delivering a product that will revolutionize the way hotels organize their business processes. If you are committed to the highest levels of achievement in cutting-edge engineering, we welcome you to help write the next chapter of our history.</p><p>We're currently looking to hire an experienced Data Engineer  to join our team. The ideal candidate will handle a wide range of exciting tasks from prototyping new techniques and technologies, to implementing real world, customer-focused cloud-based solutions in markets that are ripe for picking</p><p>As an early-stage start-up, the role will be very dynamic.  As such we need someone smart, quick-minded, ambitious, and flexible.  The role will grow as you grow!</p><p> </p>","<p>Responsibilities:</p><p>We are looking for a Sr. Data Engineer  to work on cloud and SaaS technologies. You will be responsible for the following:</p><ul> 	<li> 	<p>Work on the collecting, storing, processing, and analyzing of huge sets of data.</p> 	</li> 	<li> 	<p>Choose optimal solutions leveraging existing big data frameworks, then implement the infrastructure and  ETL processes, maintain and monitor them</p> 	</li> 	<li> 	<p>Integrate these solutions with the existing architecture</p> 	</li> 	<li> 	<p>Integrate these solutions with the existing CI/CD pipeline and automation</p> 	</li> 	<li> 	<p>Propose architecture changes to handle the creation and consumption of big data.</p> 	</li> 	<li> 	<p>Define data retention policies</p> 	</li> 	<li> 	<p>Maintain high quality code</p> 	</li> 	<li> 	<p>Investigate and, if necessary, prototype technologies relating to the task</p> 	</li> </ul><p> </p><p>Qualifications:</p><ul> 	<li> 	<p>5-7 years of software development and data engineering experience</p> 	</li> 	<li> 	<p>Proficient understanding of Big Data principles</p> 	</li> 	<li> 	<p>Experience with integrating data from multiple sources and building Data Warehouses/ Data Lakes</p> 	</li> 	<li> 	<p>Experience building stream processing systems leveraging Apache Storm, AWS Kinesis or Spark Streaming</p> 	</li> 	<li> 	<p>Experience with Spark</p> 	</li> 	<li> 	<p>Experience building and managing Hadoop clusters and proficient MapReduce and HDFS</p> 	</li> 	<li> 	<p>Experience with NoSQL databases like MongoDB, DynamoDB , HBase or Cassandra</p> 	</li> 	<li> 	<p>Knowledge of ETL techniques and frameworks like Flume or AWS Glue</p> 	</li> 	<li> 	<p>Experience with  task schedulers like Airflow</p> 	</li> 	<li> 	<p>Experience with ML toolkits like SparkML or H2O</p> 	</li> 	<li> 	<p>Good understanding of Serverless Architecture</p> 	</li> 	<li> 	<p>Ability to design and develop reusable and robust components and services</p> 	</li> 	<li> 	<p>Experience with CI/CD using Jenkins is a plus</p> 	</li> 	<li> 	<p>Team player with Agile development experience</p> 	</li> 	<li> 	<p>BS or MS in Computer Science or related technical field</p> 	</li> </ul>"
0,"Software Engineer, Data Services",HELIX LEISURE PTE. LTD.,Central,Senior Executive,Information Technology,Permanent,"$5,000","$9,000",Monthly,https://www.mycareersfuture.sg/job/software-engineer-data-services-helix-leisure-9c20bde69b3f7d47ff97b3ac298ac59f,"<p>Helix Leisure is a leading global supplier to the Out of Home Entertainment industry – locations outside the home people visit for entertainment and recreation. Across our core brands – Embed (revenue management systems, e-commerce), Booking Boss (Tours, Attractions and Activities), LAI Games (arcade games), The Locker Network (operating electronic lockers) and Matahari Leisure (equipment manufacturing) we service over 2,500 locations around the globe. Helix operates full service offices in Singapore, Perth, Sydney, Dallas, Dubai and Jakarta. The group enables our customers to create rich experiences for their visitors and guests through both technology and service.</p><p>As we embark on building the next generation platform for our software – a core consumer, supplier and distributor facing application, we are looking for highly motivated professionals who enjoy working in a fast paced, agile development environment. You will be working closely with product owners and UX designers to create and develop best-in-class data service solutions with the ability to use the latest in web development technology.</p><p><strong>Responsibilities:</strong></p><ul> 	<li>Design, develop, test, deploy, maintain and improve software</li> 	<li>Manage individual project priorities, deadlines and deliverables</li> </ul>","<p><strong>Skills &amp; Qualifications:</strong></p><ul> 	<li>BS degree in Computer Science preferred, similar technical field of study or equivalent practical experience will be considered</li> 	<li>Strong Core Java Development Experience</li> 	<li>Experience working with three or more from the following: web application development, Unix/Linux environments, distributed and parallel systems, machine learning, information retrieval, natural language processing, networking, developing large software systems, and/or security software development</li> 	<li>Working proficiency and communication skills in verbal and written English</li> 	<li>Strong TSQL knowledge, able to optimise queries and understand unoptimised query plans</li> 	<li>Real Time, Multithreaded experience</li> 	<li>Experience with ORM tools such as hibernate</li> 	<li>Experience building high-volume file processing systems</li> 	<li>Experience with payments/transactions</li> 	<li>Experience in an Agile development environment.</li> 	<li>DBA experience</li> 	<li>Effective teamwork and good communication skills with the ability to mentor peers and provide peer code-reviews</li> 	<li>Ability to work effectively with software engineers to enhance test plans and automated testing framework</li> </ul>"
